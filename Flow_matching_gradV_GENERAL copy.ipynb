{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import flow_matching\n",
    "from flow_matching.path.scheduler import CondOTScheduler\n",
    "from flow_matching.path import AffineProbPath\n",
    "from flow_matching.solver import Solver, ODESolver\n",
    "from flow_matching.utils import ModelWrapper\n",
    "from Distributions2 import *\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from models.model_configs import instantiate_model\n",
    "from matplotlib import cm\n",
    "from flow import build_ttf_m\n",
    "from network import MLP,MLP_TailParam,MLP_TailParam2,MLP2,BigTimeConditionalNet,TimeToVecNet,FullConnectedScoreModel,FullConnectedScoreModel_time\n",
    "from torch.autograd.functional import jacobian\n",
    "from torch.distributions import Independent, Normal\n",
    "from extreme_transforms import TailAffineMarginalTransform_SeparateNetParam2   \n",
    "from scaler_grad import NativeScalerWithGradNormCount as NativeScaler\n",
    "# To avoide meshgrid warning\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "approach=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "    print('Using gpu')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('Using cpu.')\n",
    "torch.manual_seed(42)\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_test_split(data, test_ratio=0.5, seed=None):\n",
    "    \"\"\"\n",
    "    Splits BxD data into train and test sets in a 9:1 ratio by default.\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): Input array of shape (B, D).\n",
    "        test_ratio (float): Proportion of the data to use for the test set.\n",
    "        seed (int, optional): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        train_data (np.ndarray), test_data (np.ndarray)\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    B = data.shape[0]\n",
    "    indices = np.random.permutation(B)\n",
    "    test_size = int(B * test_ratio)\n",
    "    test_indices = indices[:test_size]\n",
    "    train_indices = indices[test_size:]\n",
    "    \n",
    "    return data[train_indices], data[test_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset=\"studentT\"#studentT,one,pareto,Bike,queue,stock,gmm,hrrr\n",
    "option=\"simpletail\"\n",
    "option_model='simplemodel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dof_og=1\n",
    "# n_hidden_layers=2\n",
    "# full_data,objectz=samplestudentT_4(50,dof_og,40000) #40000 x 2\n",
    "# full_data.max(),full_data.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distribution_DLIM import sample_grid_gmm\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# weight=[\n",
    "#         0.01,\n",
    "#         0.1,\n",
    "#         0.3,\n",
    "#         0.2,\n",
    "#         0.02,\n",
    "#         0.15,\n",
    "#         0.02,\n",
    "#         0.15,\n",
    "#         0.05\n",
    "#     ]\n",
    "# d=sample_grid_gmm(320,1.7,3,0.1,3,weight,'cpu',False,True,False,1)\n",
    "\n",
    "# plt.scatter(d[:,0],d[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13218.0273) tensor(-8026.5181)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:54<00:00, 27.26s/it]\n"
     ]
    }
   ],
   "source": [
    "#PRINT MIX OF STUDENT-T\n",
    "from generate_splits import generate_data_split\n",
    "if Dataset==\"studentT\": #perfect\n",
    "    dof_og=1\n",
    "    n_hidden_layers=2\n",
    "    full_data,objectz=samplestudentT_4(50,dof_og,40000) #40000 x 2\n",
    "    print(full_data.max(),full_data.min())\n",
    "    Data_Splt=generate_data_split('gppg', seed, 'dummy',full_data)\n",
    "    trn_ix = Data_Splt[\"split\"][\"trn\"]\n",
    "    val_ix = Data_Splt[\"split\"][\"val\"]\n",
    "    tst_ix = Data_Splt[\"split\"][\"tst\"]\n",
    "    full_data_train =full_data[trn_ix]   \n",
    "    full_data_test =full_data[tst_ix] \n",
    "    full_data_val=full_data_train#full_data[val_ix]\n",
    "    x_lim=y_lim=80\n",
    "    iterations=800*2\n",
    "    hidden_dim=512\n",
    "    batch_size = 4096\n",
    "    # full_data_train,full_data_test=train_test_split(full_data,seed=seed,test_ratio=0.5)\n",
    "    dimension=2\n",
    "elif Dataset==\"pareto\": #perfect\n",
    "    iterations=800*4\n",
    "    dimension=20\n",
    "    full_data = np.load('c:\\\\Users\\\\adity\\\\OneDrive\\\\Desktop\\\\mscThesis\\\\Code3\\\\Thesis_FLow\\\\heavy_tail_diffusion-main\\\\data\\\\pareto\\\\pareto_20d_data.npy').reshape(-1,20)[0:30000,0:dimension] #(100000, 20)\n",
    "    full_data_train,full_data_test=train_test_split(full_data,seed=seed)\n",
    "    full_data_val=full_data_train\n",
    "    print(full_data_train.shape)\n",
    "    hidden_dim=256\n",
    "    n_hidden_layers=2\n",
    "    x_lim=y_lim=8\n",
    "    batch_size = 4096*2\n",
    "elif Dataset=='funnel':\n",
    "    dimension=2\n",
    "    n_hidden_layers=2\n",
    "    full_data=sample_funnel(30000)\n",
    "    full_data_train,full_data_test=train_test_split(full_data,seed=seed)\n",
    "    full_data_val=full_data_train\n",
    "    print(full_data_train.shape)\n",
    "    x_lim=20\n",
    "    y_lim=20\n",
    "    iterations=1600\n",
    "    hidden_dim=512\n",
    "    batch_size = 4096*2\n",
    "        \n",
    "elif Dataset=='queue':\n",
    "    dimension=20\n",
    "    full_data = np.load('c:\\\\Users\\\\adity\\\\OneDrive\\\\Desktop\\\\mscThesis\\\\Code3\\\\Thesis_FLow\\\\heavy_tail_diffusion-main\\\\data\\\\queue\\\\queue_data_20d.npy')[0:90000,0,0:dimension]\n",
    "    full_data_train,full_data_test=train_test_split(full_data,seed=seed)\n",
    "    full_data_val=full_data_train\n",
    "    \n",
    "    print(full_data_train.shape)\n",
    "    x_lim=y_lim=200\n",
    "    iterations=1200\n",
    "    hidden_dim=256  #128 for 12\n",
    "    n_hidden_layers=6\n",
    "elif Dataset==\"Stock\":\n",
    "    full_data_train = np.load('c:\\\\Users\\\\adity\\\\OneDrive\\\\Desktop\\\\mscThesis\\\\Code3\\\\Thesis_FLow\\\\heavy_tail_diffusion-main\\\\data\\\\stock\\\\stock_data_train_20.npy').reshape(-1,20)# 1200,20\n",
    "    full_data_test = np.load('c:\\\\Users\\\\adity\\\\OneDrive\\\\Desktop\\\\mscThesis\\\\Code3\\\\Thesis_FLow\\\\heavy_tail_diffusion-main\\\\data\\\\stock\\\\stock_data_test_20.npy').reshape(-1,20)# 282,20\n",
    "    full_data_val=full_data_train\n",
    "    dimension=20\n",
    "    print(full_data_train.shape)\n",
    "    x_lim=y_lim=20\n",
    "    iterations=1800\n",
    "    hidden_dim=128\n",
    "    n_hidden_layers=2\n",
    "elif Dataset=='gmm':\n",
    "    full_data=sample_grid_gmm(48000,1.7,3,0.1,3,weight,'cpu',False,True,False,1)\n",
    "    dimension=2\n",
    "    full_data_train,full_data_test=train_test_split(full_data,seed=seed)\n",
    "    full_data_val=full_data_train\n",
    "    x_lim=y_lim=200\n",
    "    iterations=1600\n",
    "    hidden_dim=128\n",
    "elif Dataset=='hrrr':\n",
    "    full_data_train =  torch.tensor(np.load('hrr_train_32.npy')[:,:,5:10,8:10])\n",
    "    full_data_test = torch.tensor(np.load('hrr_test_32.npy')[:,:,5:10,8:10])\n",
    "    xz=full_data_train\n",
    "\n",
    "    full_data_test=full_data_test.reshape(full_data_test.shape[0],-1)\n",
    "    full_data_train=full_data_train.reshape(full_data_train.shape[0],-1)\n",
    "    \n",
    "    full_data_train = ((full_data_train[:,:]-full_data_train.mean(0).unsqueeze(0)))/(full_data_train.std(0).unsqueeze(0))\n",
    "    full_data_test = ((full_data_test[:,:]-full_data_test.mean(0).unsqueeze(0)))/(full_data_test.std(0).unsqueeze(0))\n",
    "\n",
    "\n",
    "    \n",
    "    print(full_data_train.shape,full_data_test.shape)\n",
    "    full_data_val=full_data_train\n",
    "    dimension=20\n",
    "    print(full_data_train.shape)\n",
    "    x_lim=y_lim=20\n",
    "    iterations=800*4\n",
    "    hidden_dim=128\n",
    "    n_hidden_layers=2\n",
    "    batch_size=4096\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-7542.4233), tensor(-2635.1338))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data_train[:,0].min(),full_data_test[:,0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x17bfcb60760>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ylim((-1*y_lim,y_lim))\n",
    "plt.xlim((-1*x_lim,x_lim))\n",
    "plt.scatter(full_data_train[:,0],full_data_train[:,1],c=\"blue\")\n",
    "# full_data.max(),full_data.min()\n",
    "# plt.hist(full_data_train[:,0],label='aa',bins=100)\n",
    "# plt.hist(full_data_test[:,0],label='a',bins=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xz.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate some 2D data\n",
    "# x=torch.tensor(full_data_train)\n",
    "# x = ((full_data_train[:,:]-full_data_train.mean(0).unsqueeze(0)))/(full_data_train).std(0).unsqueeze(0)\n",
    "# x=x.reshape(x.shape[0],2,5,2)\n",
    "# print(x.shape)\n",
    "# print(full_data_test.min(),full_data_test.max())\n",
    "# y = full_data_test[:,1]\n",
    "# # plt.xlim((-1*0.1,0.1))\n",
    "\n",
    "# plt.hist(y,histtype='step',density=True,bins=100)\n",
    "# plt.hist(xz[:,0,2,1].reshape(xz.shape[0],-1),bins=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(6212.2803), tensor(3213.1848))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data_train.max(),full_data_test.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the  Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simplemodel\n",
      "simple\n"
     ]
    }
   ],
   "source": [
    "if option_model=='simplemodel':\n",
    "    print(\"simplemodel\")\n",
    "    # model=BigTimeConditionalNet(input_dim=dimension, time_dim=dimension, hidden_dim=hidden_dim).to(device)\n",
    "    # model=MLP2(input_dim=dimension, time_dim=1, hidden_dim=hidden_dim).to(device) #PREVECTOR FIELD\n",
    "    model=MLP(input_dim=dimension, time_dim=1, hidden_dim=hidden_dim).to(device) #best of StudentT ,cone\n",
    "    # model=FullConnectedScoreModel(dimension,hidden_dim,n_hidden_layers).to(device)#best for pareto\n",
    "else:\n",
    "    model = instantiate_model(\n",
    "        architechture='studentT',\n",
    "        is_discrete=False,\n",
    "        use_ema=True,\n",
    "    ).to(device)\n",
    "\n",
    "\n",
    "if option=='simpletail':\n",
    "    # Tail_paramNet=TimeToVecNet(1,hidden_dim,4*dimension).to(device)\n",
    "    # Tail_paramNet=MLP_TailParam2(time_dim=1, hidden_dim=hidden_dim//2,output_dim=4*dimension).to(device) #LAMBDA +,- , MEAN , SCALE  #best of StudentT,Pareto\n",
    "    Tail_paramNet=MLP_TailParam2(time_dim=1, hidden_dim=hidden_dim//2,output_dim=4*dimension).to(device) #LAMBDA +,- , MEAN , SCALE   ,cone\n",
    "\n",
    "    # Tail_paramNet=MLP_TailParam2(time_dim=1, hidden_dim=hidden_dim//2,output_dim=4*dimension).to(device) #LAMBDA +,- , MEAN , SCALE #\n",
    "    # Tail_paramNet=FullConnectedScoreModel_time(dimension,hidden_dim//2,n_hidden_layers//2).to(device)\n",
    "    print(\"simple\")\n",
    "else:\n",
    "    Tail_paramNet=instantiate_model(\n",
    "    architechture=Dataset+'_tail',   #CHANGE MAYBE\n",
    "    is_discrete=False,\n",
    "    use_ema=True,\n",
    "        ).to(device)\n",
    "noise2data=TailAffineMarginalTransform_SeparateNetParam2(dimz=dimension).to(device)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(torch.randn(5,1,20),torch.randn(5),extra=[]).shape,Tail_paramNet(torch.randn(5,1,20),torch.randn(5),extra=[]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise2data(torch.zeros(6,2),torch.zeros(6,8)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "\n",
    "print_every = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_26300\\4294779823.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_dataset = TensorDataset(torch.tensor(full_data_train))\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TensorDataset(torch.tensor(full_data_train))\n",
    "\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\OneDrive\\Desktop\\mscThesis\\Code3\\Thesis_FLow\\scaler_grad.py:35: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self._scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "jo=0 #counter\n",
    "path = AffineProbPath(scheduler=CondOTScheduler())\n",
    "\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=1e-3)\n",
    "optim2=torch.optim.Adam(Tail_paramNet.parameters(), lr=lr,weight_decay=1e-3)#,weight_decay=1e-3)\n",
    "loss_scaler = NativeScaler()\n",
    "# scheduler = torch.optim.lr_scheduler.LinearLR(optim, start_factor=lr, end_factor=0.0, total_iters=iterations*len(train_loader))\n",
    "# scheduler2 = torch.optim.lr_scheduler.LinearLR(optim2, start_factor=lr, end_factor=0.0, total_iters=iterations*len(train_loader))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=dimension\n",
    "dimx=dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from torch import nn, Tensor\n",
    "\n",
    "def jvp(f,x, v) -> tuple[Tensor, ...]:\n",
    "    return torch.autograd.functional.jvp(\n",
    "        f, x, v, \n",
    "        create_graph=torch.is_grad_enabled()\n",
    "    )\n",
    "\n",
    "\n",
    "def t_dir(f, t) -> tuple[Tensor, ...]:\n",
    "    return jvp(f, t, torch.ones_like(t))\n",
    "\n",
    "\n",
    "def get_t_dir(dimension,noise2data,Model, x: Tensor, t: Tensor) -> tuple[tuple[Tensor, Tensor], tuple[Tensor, Tensor]]:\n",
    "    def flow(Xz,timez):\n",
    "        # print(\"XZ_t\",Xz.shape,timez.shape)\n",
    "        param_tail_eps=Model(timez.unsqueeze(1))\n",
    "        dummy_tail_param2=param_tail_eps.reshape(param_tail_eps.shape[0],4,dimension)\n",
    "        _unc_pos_tail2,_unc_neg_tail2,shift2,_unc_scale2, = dummy_tail_param2[:,0,:],dummy_tail_param2[:,1,:],dummy_tail_param2[:,2,:],dummy_tail_param2[:,3,:]\n",
    "\n",
    "        D1=noise2data.pos_tail(_unc_pos_tail2)\n",
    "        D2=noise2data.neg_tail(_unc_neg_tail2)\n",
    "        D3=shift2\n",
    "        D4=noise2data.scale(_unc_scale2)   \n",
    "\n",
    "        valuez=torch.cat([D1,D2,D3,D4],1)\n",
    "\n",
    "        return(valuez)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def f(x_in):\n",
    "        def f_(t_in):\n",
    "            return flow(x_in, t_in)\n",
    "        return f_\n",
    "\n",
    "    return t_dir(f(x), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class combined(nn.Module):\n",
    "    def __init__(\n",
    "        self,tail_param_net,PreVFnet,NOISE2DATA\n",
    "    ):\n",
    "        # self.features = features\n",
    "        super(combined, self).__init__()\n",
    "        self.tail_param_net=tail_param_net\n",
    "        self.PreVFnet=PreVFnet\n",
    "        self.NOISE2DATA=NOISE2DATA\n",
    "    def forward(self, x_t,time_t):\n",
    "        time_t=time_t.reshape(-1).expand(x_t.shape[0])\n",
    "        lol=None\n",
    "        if approach==1:\n",
    "            if option_model=='simplemodel':\n",
    "                prefinal_vf=self.PreVFnet(x_t,time_t)\n",
    "            else:\n",
    "                prefinal_vf=self.PreVFnet(x_t.unsqueeze(1),time_t,extra=[])\n",
    "            prefinal_vf=prefinal_vf.reshape(prefinal_vf.shape[0],-1)\n",
    "        if approach==2:        \n",
    "        # print(\"x\",x_t.shape,\"timt=\",time_t,time_t.shape,time_t.unsqueeze(1).shape)\n",
    "            if option=='simpletail':\n",
    "                param_tail=self.tail_param_net(time_t.unsqueeze(1)) #BX80\n",
    "\n",
    "                True_timederiv=get_t_dir(dim,self.NOISE2DATA,self.tail_param_net,x_t,time_t)\n",
    "                param_grad=True_timederiv[1] #time derive\n",
    "\n",
    "            else:\n",
    "                ones=torch.zeros(x_t.shape).to(device)+time_t.unsqueeze(1) #B X 20\n",
    "                param_tail=self.tail_param_net(ones.unsqueeze(1),time_t,extra=[])  # B X 4 X 20 Generating Parameters of Tail net for each time step\n",
    "\n",
    "            param_tail=param_tail.reshape(param_tail.shape[0],-1)\n",
    "            param_tail_pre_eps=param_tail\n",
    "            # print(\"param_tail\",param_tail.shape)\n",
    "\n",
    "            # print(\"LETSGO\",x_t.shape,param_tail.shape)\n",
    "            phi_t=self.NOISE2DATA.inverse(x_t,param_tail,False,None,None)\n",
    "            if option_model=='simplemodel':\n",
    "                prefinal_vf=self.PreVFnet(phi_t,time_t)\n",
    "            else:\n",
    "                prefinal_vf=self.PreVFnet(phi_t,time_t,extra=[])\n",
    "            prefinal_vf=prefinal_vf.reshape(prefinal_vf.shape[0],-1)\n",
    "\n",
    "            jacobian_phi=self.NOISE2DATA.fwd_dTTF_dz(phi_t, param_tail)\n",
    "            jacobian_param_tail=self.NOISE2DATA.dTTF_dtailparam(phi_t, param_tail)\n",
    "\n",
    "            '''\n",
    "            if option=='simpletail':\n",
    "                param_tail_eps=self.tail_param_net(time_t.unsqueeze(1)+epsilon) \n",
    "            else:\n",
    "                param_tail_eps=self.tail_param_net(ones.unsqueeze(1)+epsilon,time_t+epsilon,extra=[])\n",
    "            \n",
    "            param_tail_eps=param_tail_eps.reshape(param_tail_eps.shape[0],-1)\n",
    "            \n",
    "\n",
    "            dummy_tail_param=param_tail_pre_eps.reshape(param_tail_pre_eps.shape[0],4,dimension)\n",
    "            _unc_pos_tail,_unc_neg_tail,shift,_unc_scale =dummy_tail_param[:,0,:],dummy_tail_param[:,1,:],dummy_tail_param[:,2,:],dummy_tail_param[:,3,:]\n",
    "\n",
    "            # _unc_pos_tail,_unc_neg_tail,shift,_unc_scale, = param_tail_pre_eps[:,0:dimx],param_tail_pre_eps[:,dimx:2*dimx],param_tail_pre_eps[:,2*dimx:3*dimx],param_tail_pre_eps[:,3*dimx:4*dimx]\n",
    "            # _unc_pos_tail2,_unc_neg_tail2,shift2,_unc_scale2, = param_tail_eps[:,0:dimx],param_tail_eps[:,dimx:2*dimx],param_tail_eps[:,2*dimx:3*dimx],param_tail_eps[:,3*dimx:4*dimx]\n",
    "\n",
    "\n",
    "            dummy_tail_param2=param_tail_eps.reshape(param_tail_eps.shape[0],4,dimension)\n",
    "            _unc_pos_tail2,_unc_neg_tail2,shift2,_unc_scale2, = dummy_tail_param2[:,0,:],dummy_tail_param2[:,1,:],dummy_tail_param2[:,2,:],dummy_tail_param2[:,3,:]\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            D1=(self.NOISE2DATA.pos_tail(_unc_pos_tail2)-self.NOISE2DATA.pos_tail(_unc_pos_tail))/epsilon\n",
    "            D2=(self.NOISE2DATA.neg_tail(_unc_neg_tail2)-self.NOISE2DATA.neg_tail(_unc_neg_tail))/epsilon\n",
    "            D3=(shift2-shift)/epsilon\n",
    "            D4=(self.NOISE2DATA.scale(_unc_scale2)-self.NOISE2DATA.scale(_unc_scale))/epsilon\n",
    "\n",
    "            param_grad=torch.cat([D1,D2,D3,D4],1)\n",
    "            '''\n",
    "            # print(\"param_grad\",param_grad.shape)\n",
    "            # print(\"HOLA\",jacobian_param_tail.shape,param_grad.shape)\n",
    "            first_part=param_grad[:,0:dim]*jacobian_param_tail[0]+param_grad[:,dim:2*dim]*jacobian_param_tail[1]+param_grad[:,2*dim:3*dim]*jacobian_param_tail[2]+param_grad[:,3*dim:4*dim]*jacobian_param_tail[3]\n",
    "            second_part=torch.bmm(jacobian_phi,prefinal_vf.unsqueeze(2)).squeeze(2)\n",
    "            # velocity_field=torch.bmm(jacobian_param_tail,param_grad)+torch.bmm(jacobian_phi,prefinal_vf.unsqueeze(2))\n",
    "            # print(first_part.shape,second_part.shape)\n",
    "            velocity_field=first_part+second_part\n",
    "        elif approach==1:\n",
    "            velocity_field=prefinal_vf\n",
    "        # velocity_field=torch.bmm(jacobian_param_tail,param_grad)+torch.bmm(jacobian_phi,prefinal_vf.unsqueeze(2))\n",
    "        return(velocity_field)\n",
    "        \n",
    "class WrappedModel(ModelWrapper):\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor, **extras):\n",
    "        return self.model(x, t)\n",
    "\n",
    "\n",
    "\n",
    "def calc_Wassertein(MODEL,TAIL_PARAMNET,NOISE2DATA,VAL_DATASET,dimension):\n",
    "    # step size for ode solver\n",
    "    Combo=combined(TAIL_PARAMNET,MODEL,NOISE2DATA)\n",
    "    wrapped_vf = WrappedModel(Combo)\n",
    "    step_size = 0.05\n",
    "\n",
    " \n",
    "\n",
    "    batch_size = VAL_DATASET.shape[0]  # batch size\n",
    " \n",
    "    T = torch.linspace(0,1,10)  # sample times\n",
    "    T = T.to(device=device)\n",
    "    # print(a)\n",
    "\n",
    "    x_init = torch.randn((batch_size, dimension), dtype=torch.float32, device=device)\n",
    "    solver = ODESolver(velocity_model=wrapped_vf)  # create an ODESolver class\n",
    "    sol = solver.sample(time_grid=T, x_init=x_init, method='midpoint', step_size=step_size, return_intermediates=True)  # sample from the model\n",
    "    generated_data=sol[9].cpu().numpy()\n",
    "    validation_data=VAL_DATASET\n",
    "    distance=np.mean(plot_wasserstein_distances(generated_data,validation_data))\n",
    "    print(generated_data.shape,validation_data.shape,distance,\"aloha\")\n",
    "\n",
    "    return distance\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "def plot_wasserstein_distances(generate_data: np.ndarray, test_data: np.ndarray):\n",
    "    \"\"\"\n",
    "    Computes and plots Wasserstein distances for each feature between generated and test data.\n",
    "\n",
    "    Parameters:\n",
    "    - generate_data: np.ndarray of shape (N, D)\n",
    "    - test_data: np.ndarray of shape (N, D)\n",
    "    \"\"\"\n",
    "    assert generate_data.shape[1] == test_data.shape[1], \"Feature dimensions must match\"\n",
    "    num_features = generate_data.shape[1]\n",
    "    \n",
    "    distances = [\n",
    "        wasserstein_distance(test_data[:, i], generate_data[:, i])\n",
    "        for i in range(num_features)\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    return distances  # Optional: return the distances for further use\n",
    " \n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param_tail torch.Size([4096, 8]) tensor(0.2001, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(27.3665, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.2866, device='cuda:0') tensor(13433.4258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.1997, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(64.4060, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4869.8784, device='cuda:0') tensor(15699.7568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.1996, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(156.3222, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1329.1620, device='cuda:0') tensor(2945.2783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.1996, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(191.4043, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.5408, device='cuda:0') tensor(14333.6992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.1996, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(611.5013, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.0459, device='cuda:0') tensor(27495.6797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.1996, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(409.4528, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.0671, device='cuda:0') tensor(2685.7732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.1997, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(296.6086, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.9644, device='cuda:0') tensor(3437.2871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.1998, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(750.1467, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2040.3943, device='cuda:0') tensor(3376.3508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.1999, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1185.0288, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.0679, device='cuda:0') tensor(4720.4453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter     10 | 1746.89 ms/step | loss 4720.445 \n",
      "param_tail torch.Size([4096, 8]) tensor(0.2001, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1593.8154, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.6572, device='cuda:0') tensor(16588.3828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2004, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(386.6457, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1993.8584, device='cuda:0') tensor(2560.5410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2007, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(925.5084, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.2200, device='cuda:0') tensor(9719.3730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2010, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1617.0162, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.2578, device='cuda:0') tensor(6770.0508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2015, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2595.0454, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.1853, device='cuda:0') tensor(4869.1587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2019, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(703.9992, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.4419, device='cuda:0') tensor(7304.1362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(997.7845, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3415.9006, device='cuda:0') tensor(4003.2678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2031, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(521.9252, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.7565, device='cuda:0') tensor(2181.7747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2038, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3763.5667, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.3984, device='cuda:0') tensor(13955.3086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2047, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(931.2734, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1153.1273, device='cuda:0') tensor(1425.7456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter     20 | 324.12 ms/step | loss 1425.746 \n",
      "param_tail torch.Size([3712, 8]) tensor(0.2055, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(597.1506, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9922, device='cuda:0') tensor(16414.8340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2064, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2791.9421, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.3264, device='cuda:0') tensor(1905.1229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2074, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1406.7109, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.4146, device='cuda:0') tensor(8667.4434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2084, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2251.1772, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.4468, device='cuda:0') tensor(5934.1748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2093, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1101.2911, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.9646, device='cuda:0') tensor(3467.7773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2102, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2143.1636, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.2610, device='cuda:0') tensor(3265.7329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2110, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5107.3882, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.8242, device='cuda:0') tensor(3425.5513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2118, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3306.6687, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.6841, device='cuda:0') tensor(4943.3257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2127, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(713.3156, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1173.0415, device='cuda:0') tensor(1634.0542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2138, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1902.8173, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.9917, device='cuda:0') tensor(4650.9746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter     30 | 91.60 ms/step | loss 4650.975 \n",
      "param_tail torch.Size([4096, 8]) tensor(0.2146, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1522.8270, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.7456, device='cuda:0') tensor(2748.6321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2155, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7687.3989, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.4333, device='cuda:0') tensor(16337.9854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2163, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9532.3652, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.3667, device='cuda:0') tensor(5930.5576, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2168, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1719.5197, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.4309, device='cuda:0') tensor(14575.0547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2172, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(12694.5186, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.6055, device='cuda:0') tensor(12851.8984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2173, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(914.5262, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1128.3008, device='cuda:0') tensor(1028.1038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2177, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3553.1917, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.3311, device='cuda:0') tensor(1720.8776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2178, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2724.8694, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.5110, device='cuda:0') tensor(3631.2178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2181, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(938.4438, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.0784, device='cuda:0') tensor(15337.8184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2184, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1264.7626, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1993.7245, device='cuda:0') tensor(1875.4778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter     40 | 78.95 ms/step | loss 1875.478 \n",
      "param_tail torch.Size([3712, 8]) tensor(0.2189, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4714.0381, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6748, device='cuda:0') tensor(8824.5889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2194, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5714.5391, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.2078, device='cuda:0') tensor(13257.2773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2200, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2347.5828, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.0632, device='cuda:0') tensor(1125.7227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2204, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(909.0342, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.8428, device='cuda:0') tensor(8802.3164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2212, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(12679.4766, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.5078, device='cuda:0') tensor(10573.4805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2218, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(600.5527, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.4922, device='cuda:0') tensor(2077.8955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2226, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1713.2776, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.0095, device='cuda:0') tensor(7277.3101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2232, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1521.9479, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.8953, device='cuda:0') tensor(1299.8938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2240, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7920.6489, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.1396, device='cuda:0') tensor(4718.1455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2243, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2728.9915, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.4639, device='cuda:0') tensor(1519.2307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter     50 | 86.43 ms/step | loss 1519.231 \n",
      "param_tail torch.Size([4096, 8]) tensor(0.2247, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2762.4016, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3122.3872, device='cuda:0') tensor(1911.0404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2252, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1866.5681, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1559.5039, device='cuda:0') tensor(1671.5610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2254, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2355.8186, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.6655, device='cuda:0') tensor(18674.4941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2260, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2429.7000, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4874.1294, device='cuda:0') tensor(6100.8735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2265, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(286.9066, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.2412, device='cuda:0') tensor(1764.2855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2272, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1834.8933, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.7202, device='cuda:0') tensor(13060.7861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2279, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1648.5377, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.2222, device='cuda:0') tensor(3383.3899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2286, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4469.4678, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.2783, device='cuda:0') tensor(2121.6074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2294, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1678.6079, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.1670, device='cuda:0') tensor(7907.3467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2302, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2497.2354, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.6360, device='cuda:0') tensor(1191.4310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter     60 | 66.90 ms/step | loss 1191.431 \n",
      "param_tail torch.Size([3712, 8]) tensor(0.2313, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2686.1279, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.7900, device='cuda:0') tensor(2587.9622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2322, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4984.4932, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.6372, device='cuda:0') tensor(8217.8496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2331, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4544.8223, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.1768, device='cuda:0') tensor(4946.1997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2339, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1912.4871, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.5043, device='cuda:0') tensor(1065.4702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2352, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2723.5740, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4874.5869, device='cuda:0') tensor(3410.6116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2361, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2138.5962, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.4170, device='cuda:0') tensor(2073.9121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2370, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6001.1504, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.7769, device='cuda:0') tensor(10667.4736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2379, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(978.6072, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.6711, device='cuda:0') tensor(2370.1099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2385, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4234.2354, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.2847, device='cuda:0') tensor(13430.5303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2395, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2178.4409, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.2651, device='cuda:0') tensor(4912.0771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter     70 | 81.22 ms/step | loss 4912.077 \n",
      "param_tail torch.Size([4096, 8]) tensor(0.2408, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(621.1663, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.3650, device='cuda:0') tensor(2830.0703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2419, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4495.8105, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.6001, device='cuda:0') tensor(10642.0137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2429, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1827.4946, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.8054, device='cuda:0') tensor(1878.6716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2439, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1678.3655, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.4812, device='cuda:0') tensor(8201.4102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2451, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4126.6274, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.3564, device='cuda:0') tensor(1671.9814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2465, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1731.3678, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2611.1614, device='cuda:0') tensor(1594.2205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2475, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2910.1277, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.0420, device='cuda:0') tensor(6507.8999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2485, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4240.5776, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.6982, device='cuda:0') tensor(1890.5934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2496, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(968.6592, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2039.0436, device='cuda:0') tensor(1941.4990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2508, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(855.7836, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.6311, device='cuda:0') tensor(16247.2402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter     80 | 84.40 ms/step | loss 16247.240 \n",
      "param_tail torch.Size([3712, 8]) tensor(0.2519, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7214.5845, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4746, device='cuda:0') tensor(2744.1931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2527, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(10422.6963, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6025, device='cuda:0') tensor(10044.8516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2530, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4083.1243, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.4832, device='cuda:0') tensor(1977.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2532, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1058.1206, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1327.7904, device='cuda:0') tensor(1370.3931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2539, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1318.5768, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.5984, device='cuda:0') tensor(2134.2585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2545, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9413.8779, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.6235, device='cuda:0') tensor(6413.0098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2547, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2674.9434, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2258.1223, device='cuda:0') tensor(2814.2998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2548, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1583.9220, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1126.0834, device='cuda:0') tensor(1036.1335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2550, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9088.9824, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.1309, device='cuda:0') tensor(4547.5464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2550, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1200.3787, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1174.5046, device='cuda:0') tensor(1096.7257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter     90 | 62.66 ms/step | loss 1096.726 \n",
      "param_tail torch.Size([4096, 8]) tensor(0.2553, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9161.7256, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9780, device='cuda:0') tensor(10823.8594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2551, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4321.2456, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.8877, device='cuda:0') tensor(2964.6753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2550, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2962.1140, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.7271, device='cuda:0') tensor(2240.2485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2550, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1082.3152, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.9741, device='cuda:0') tensor(2503.3027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2550, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1126.3394, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.7861, device='cuda:0') tensor(2341.9578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2550, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6200.5464, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.8623, device='cuda:0') tensor(4133.5371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2554, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(876.2980, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.7173, device='cuda:0') tensor(10321.4072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2560, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3754.3677, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.0757, device='cuda:0') tensor(3182.9026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2563, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2214.2412, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.4521, device='cuda:0') tensor(1869.8864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2568, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2910.9790, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.3508, device='cuda:0') tensor(1339.2797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    100 | 82.12 ms/step | loss 1339.280 \n",
      "param_tail torch.Size([3712, 8]) tensor(0.2572, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3248.3457, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.0425, device='cuda:0') tensor(4021.0620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2579, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2085.0278, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1994.0789, device='cuda:0') tensor(2235.1565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2586, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8352.2344, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.6143, device='cuda:0') tensor(4036.6907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2590, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2172.7070, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.9980, device='cuda:0') tensor(10660.3652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2597, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5973.3633, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.8171, device='cuda:0') tensor(14497.0352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2602, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1831.9873, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.7227, device='cuda:0') tensor(4922.7344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2611, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1400.7291, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.6353, device='cuda:0') tensor(9473.1836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2620, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5731.4839, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.5308, device='cuda:0') tensor(6356.8193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2630, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(267.1129, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1994.6503, device='cuda:0') tensor(1671.5466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2639, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2948.7622, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.3401, device='cuda:0') tensor(4622.9424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    110 | 82.57 ms/step | loss 4622.942 \n",
      "param_tail torch.Size([4096, 8]) tensor(0.2651, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3390.5837, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.6016, device='cuda:0') tensor(2432.5474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2663, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2405.4695, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.2805, device='cuda:0') tensor(1790.0691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2678, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5986.7539, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.3037, device='cuda:0') tensor(1947.0447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2692, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(956.4750, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.8274, device='cuda:0') tensor(3062.9663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2706, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1836.9216, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.4360, device='cuda:0') tensor(10367.5635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2716, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(552.1600, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1174.4058, device='cuda:0') tensor(1090.6238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2733, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5001.2227, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.4194, device='cuda:0') tensor(9251.9414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2742, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2017.7003, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.2676, device='cuda:0') tensor(4013.7920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2764, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2743.6304, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.4736, device='cuda:0') tensor(4839.8076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2781, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1957.8391, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.7034, device='cuda:0') tensor(3090.7803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    120 | 65.47 ms/step | loss 3090.780 \n",
      "param_tail torch.Size([3712, 8]) tensor(0.2795, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7383.7451, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4434, device='cuda:0') tensor(11555.8877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2802, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3634.5627, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.4709, device='cuda:0') tensor(8898.2754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2815, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(731.9114, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1559.0812, device='cuda:0') tensor(2572.5100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2823, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3549.6614, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.0542, device='cuda:0') tensor(13810.5537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2825, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8981.3994, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.1514, device='cuda:0') tensor(3279.3491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2828, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2936.0603, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.0137, device='cuda:0') tensor(4357.4038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2828, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1648.4875, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.8811, device='cuda:0') tensor(4277.0117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2827, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2248.7290, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.3176, device='cuda:0') tensor(2644.7349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2830, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4235.2266, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.3384, device='cuda:0') tensor(2222.6362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2838, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3899.9866, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.0054, device='cuda:0') tensor(11556.7842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    130 | 84.27 ms/step | loss 11556.784 \n",
      "param_tail torch.Size([4096, 8]) tensor(0.2844, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6569.0918, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.2368, device='cuda:0') tensor(1045.0339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2852, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1307.3025, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1993.8263, device='cuda:0') tensor(1359.3586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2859, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4631.9961, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4038.4619, device='cuda:0') tensor(4262.7832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2863, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3526.3608, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.7007, device='cuda:0') tensor(2948.7891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2872, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5845.6299, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.5811, device='cuda:0') tensor(1395.0597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2880, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6402.4028, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.9563, device='cuda:0') tensor(4064.2400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2889, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2248.5061, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.6658, device='cuda:0') tensor(3224.6851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2895, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2279.7769, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.6016, device='cuda:0') tensor(1034.1580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2903, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3363.6160, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.0337, device='cuda:0') tensor(10991.9678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2916, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1641.2949, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1559.1025, device='cuda:0') tensor(1047.8164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    140 | 67.22 ms/step | loss 1047.816 \n",
      "param_tail torch.Size([3712, 8]) tensor(0.2928, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4092.8347, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.0596, device='cuda:0') tensor(8872.8770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2946, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(713.5576, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1994.0671, device='cuda:0') tensor(1654.7458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2967, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7113.3223, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.8569, device='cuda:0') tensor(1686.4523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.2982, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4164.9653, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.1011, device='cuda:0') tensor(2787.0151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.2991, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3876.6301, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.6992, device='cuda:0') tensor(6567.9468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3004, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3919.8943, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.6489, device='cuda:0') tensor(8371.2119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3017, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3905.1421, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.5317, device='cuda:0') tensor(2194.3369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3033, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4941.2998, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.1091, device='cuda:0') tensor(3696.3940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.3046, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2126.6753, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.5227, device='cuda:0') tensor(2393.0137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3057, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2264.5100, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2043.1198, device='cuda:0') tensor(1711.6896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    150 | 82.52 ms/step | loss 1711.690 \n",
      "param_tail torch.Size([4096, 8]) tensor(0.3075, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(666.6532, device='cuda:0', grad_fn=<MaxBackward1>) tensor(699.8431, device='cuda:0') tensor(1179.3810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3090, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6962.8818, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.6123, device='cuda:0') tensor(3522.0381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.3107, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5852.1436, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.4277, device='cuda:0') tensor(15347.8506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3121, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(831.4517, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.1072, device='cuda:0') tensor(10772.1045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3136, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1644.7358, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2042.5422, device='cuda:0') tensor(1853.7501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3150, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3214.6450, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.7573, device='cuda:0') tensor(5729.2080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.3172, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4797.1655, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.6548, device='cuda:0') tensor(3613.6367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3194, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3316.6655, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.2024, device='cuda:0') tensor(4900.0488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3215, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(728.9495, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1995.6068, device='cuda:0') tensor(1297.5875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3242, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6718.3657, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.6279, device='cuda:0') tensor(10419.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    160 | 93.65 ms/step | loss 10419.003 \n",
      "param_tail torch.Size([3712, 8]) tensor(0.3263, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1085.1892, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.7935, device='cuda:0') tensor(1824.1255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3287, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(11791.7041, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.6123, device='cuda:0') tensor(8058.3486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3302, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3337.2910, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.2031, device='cuda:0') tensor(3415.1814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3321, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5647.3945, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.1572, device='cuda:0') tensor(4464.9160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.3335, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2269.3325, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.7422, device='cuda:0') tensor(9556.3965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3349, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1680.0144, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.9248, device='cuda:0') tensor(6758.7583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3364, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3331.0337, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.7515, device='cuda:0') tensor(2804.7317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3387, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2249.5872, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.0288, device='cuda:0') tensor(2868.1143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.3409, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2824.6963, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.7312, device='cuda:0') tensor(4906.6509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3429, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(934.6166, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.4390, device='cuda:0') tensor(10226.7793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    170 | 65.00 ms/step | loss 10226.779 \n",
      "param_tail torch.Size([4096, 8]) tensor(0.3451, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6727.7778, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.9438, device='cuda:0') tensor(4729.4131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3467, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3521.0940, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.9917, device='cuda:0') tensor(8750.6406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.3480, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(720.7664, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1154.5221, device='cuda:0') tensor(865.8417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3497, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2689.4602, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.2607, device='cuda:0') tensor(7819.9058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3519, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1034.3723, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1558.2836, device='cuda:0') tensor(2713.0496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3549, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3628.5449, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.7312, device='cuda:0') tensor(1856.8019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.3573, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1176.3993, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.7720, device='cuda:0') tensor(4755.2129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3601, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(11858.9580, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.3252, device='cuda:0') tensor(5486.9014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3616, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1876.1915, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.4546, device='cuda:0') tensor(1184.5615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3634, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3189.8081, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.9614, device='cuda:0') tensor(11828.4961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    180 | 84.48 ms/step | loss 11828.496 \n",
      "param_tail torch.Size([3712, 8]) tensor(0.3649, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1138.0839, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4874.0825, device='cuda:0') tensor(3735.4758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3666, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5003.1533, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.5176, device='cuda:0') tensor(7537.3779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3686, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3369.7896, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.1406, device='cuda:0') tensor(5339.8516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3708, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1866.9253, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.5142, device='cuda:0') tensor(2108.3516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.3732, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1166.1559, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.5684, device='cuda:0') tensor(10353.6045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3765, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5597.8506, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.5435, device='cuda:0') tensor(2626.3137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3782, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2705.9658, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.2563, device='cuda:0') tensor(1582.1213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3806, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6642.4526, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.3657, device='cuda:0') tensor(4131.2856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.3823, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2461.8086, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.2913, device='cuda:0') tensor(989.6745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3847, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8006.5801, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.2329, device='cuda:0') tensor(6739.7246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    190 | 70.99 ms/step | loss 6739.725 \n",
      "param_tail torch.Size([4096, 8]) tensor(0.3850, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3366.2583, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.8818, device='cuda:0') tensor(2759.8921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3872, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(422.5852, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.0574, device='cuda:0') tensor(9605.7754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.3891, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2146.6479, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.8921, device='cuda:0') tensor(1068.5563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3914, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3366.9231, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.5732, device='cuda:0') tensor(7767.5430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3937, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(814.6649, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.8159, device='cuda:0') tensor(3928.4485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.3967, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5476.1909, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.0691, device='cuda:0') tensor(3354.6543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.3989, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5393.9409, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.2715, device='cuda:0') tensor(4827.5771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.4003, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3037.6345, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.0850, device='cuda:0') tensor(5754.3052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.4026, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2032.0132, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.9480, device='cuda:0') tensor(5068.7603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.4055, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3805.8269, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.3940, device='cuda:0') tensor(2136.0635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    200 | 82.27 ms/step | loss 2136.063 \n",
      "param_tail torch.Size([3712, 8]) tensor(0.4089, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1921.7886, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.4312, device='cuda:0') tensor(8027.5156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "checking 49\n",
      "(16000, 2) torch.Size([16000, 2]) 28.996185479503325 aloha\n",
      "saving iteration- 49\n",
      "param_tail torch.Size([4096, 8]) tensor(0.4121, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(297.5999, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1997, device='cuda:0') tensor(8961.2666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.4162, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2115.4045, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2608.5264, device='cuda:0') tensor(1970.7631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.4202, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5103.5903, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.2544, device='cuda:0') tensor(2382.2739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.4231, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1967.6196, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.4766, device='cuda:0') tensor(4765.6455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.4274, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3403.8040, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.1011, device='cuda:0') tensor(1321.8502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.4311, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1748.9150, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.2881, device='cuda:0') tensor(5373.7349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.4356, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4749.7920, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.4199, device='cuda:0') tensor(2670.1523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.4392, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4343.5186, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.4380, device='cuda:0') tensor(3727.8313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.4429, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(733.6012, device='cuda:0', grad_fn=<MaxBackward1>) tensor(926.6500, device='cuda:0') tensor(951.0327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    210 | 272.71 ms/step | loss  951.033 \n",
      "param_tail torch.Size([4096, 8]) tensor(0.4469, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4491.0547, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.8477, device='cuda:0') tensor(4135.2305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.4500, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4916.6626, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.2935, device='cuda:0') tensor(2313.7039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.4539, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5418.2188, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.8711, device='cuda:0') tensor(6236.5532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.4571, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2978.6929, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.2944, device='cuda:0') tensor(3957.1201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.4612, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2413.1045, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.0154, device='cuda:0') tensor(1711.6560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.4648, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1667.9926, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1174.2642, device='cuda:0') tensor(821.8612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.4671, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1769.1438, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.2261, device='cuda:0') tensor(14078.2812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.4706, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2390.6306, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.5183, device='cuda:0') tensor(2771.9551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.4734, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(867.1833, device='cuda:0', grad_fn=<MaxBackward1>) tensor(924.2646, device='cuda:0') tensor(786.8672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.4779, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1656.8202, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1558.7507, device='cuda:0') tensor(920.3911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    220 | 65.06 ms/step | loss  920.391 \n",
      "param_tail torch.Size([3712, 8]) tensor(0.4818, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(12090.8740, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.5859, device='cuda:0') tensor(19373.3008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.4846, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2453.2605, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.9795, device='cuda:0') tensor(3513.1938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.4877, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8973.0645, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.7998, device='cuda:0') tensor(3423.0132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.4894, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(496.4693, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.9617, device='cuda:0') tensor(7045.4912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.4921, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1960.0518, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2611.0732, device='cuda:0') tensor(1461.7563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.4947, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6729.0361, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.8398, device='cuda:0') tensor(1538.2657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.4963, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1870.0768, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.9875, device='cuda:0') tensor(1101.8945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.4989, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1801.2596, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.4932, device='cuda:0') tensor(5721.6987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.5025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1398.5049, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.2681, device='cuda:0') tensor(15807.6660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.5064, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(10262.4814, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.1191, device='cuda:0') tensor(3976.0420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    230 | 80.61 ms/step | loss 3976.042 \n",
      "param_tail torch.Size([4096, 8]) tensor(0.5083, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1603.0714, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.5796, device='cuda:0') tensor(4087.4941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.5111, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3450.1953, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.7527, device='cuda:0') tensor(2175.1235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.5130, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3050.3984, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.2249, device='cuda:0') tensor(2974.1416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.5168, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3765.5361, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.8232, device='cuda:0') tensor(2726.0137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.5196, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1805.7911, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.0688, device='cuda:0') tensor(1770.3654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.5237, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1032.7371, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.7412, device='cuda:0') tensor(6844.7852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.5280, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2862.8840, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.8701, device='cuda:0') tensor(2806.4451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.5334, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2257.3359, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.1055, device='cuda:0') tensor(1147.5496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.5393, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2524.9905, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.4912, device='cuda:0') tensor(5395.1992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.5462, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5868.1572, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.4995, device='cuda:0') tensor(5206.2666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    240 | 82.39 ms/step | loss 5206.267 \n",
      "param_tail torch.Size([3712, 8]) tensor(0.5520, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1608.1934, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1994.0599, device='cuda:0') tensor(1204.7721, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.5581, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1577.3372, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.0581, device='cuda:0') tensor(2364.7935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.5644, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1864.1772, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1994.5482, device='cuda:0') tensor(1557.0571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.5713, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2446.9807, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.5444, device='cuda:0') tensor(4629.2520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.5777, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5300.0142, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.2422, device='cuda:0') tensor(5858.6860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.5855, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4104.2100, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.8931, device='cuda:0') tensor(2307.3921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.5939, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4550.8164, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.5107, device='cuda:0') tensor(8341.3379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.6023, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3205.8774, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3122.0051, device='cuda:0') tensor(1457.8942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.6093, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1432.5551, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1995.4456, device='cuda:0') tensor(888.8536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.6187, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(518.7090, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.1111, device='cuda:0') tensor(7949.0840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    250 | 63.20 ms/step | loss 7949.084 \n",
      "param_tail torch.Size([4096, 8]) tensor(0.6271, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4422.0894, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.7500, device='cuda:0') tensor(7031.0879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.6370, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1022.9503, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4038.6306, device='cuda:0') tensor(5501.5732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.6470, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1435.7720, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2039.3275, device='cuda:0') tensor(1720.5826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.6569, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3621.2676, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4869.7773, device='cuda:0') tensor(12763.0146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.6667, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8635.8008, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.5371, device='cuda:0') tensor(18392.7812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.6746, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1716.4666, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.7559, device='cuda:0') tensor(2883.2483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.6812, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1412.0668, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.7639, device='cuda:0') tensor(1041.0195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.6885, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2321.4377, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.2285, device='cuda:0') tensor(9372.2148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.6953, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2647.7419, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.8770, device='cuda:0') tensor(994.6296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.7005, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(10045.1787, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.1748, device='cuda:0') tensor(2863.0918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    260 | 103.52 ms/step | loss 2863.092 \n",
      "param_tail torch.Size([3712, 8]) tensor(0.7045, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1526.2876, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1174.0891, device='cuda:0') tensor(896.4058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.7078, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2581.3057, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.7747, device='cuda:0') tensor(3100.5178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.7111, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1850.7823, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.3779, device='cuda:0') tensor(813.3741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.7162, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3082.8887, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9360, device='cuda:0') tensor(16321.8066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.7207, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5269.3096, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.2300, device='cuda:0') tensor(835.6700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.7236, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2699.6658, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6577, device='cuda:0') tensor(18544.4355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.7278, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1355.3369, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.5288, device='cuda:0') tensor(6101.0195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.7333, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(282.4423, device='cuda:0', grad_fn=<MaxBackward1>) tensor(750.8159, device='cuda:0') tensor(1130.7761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.7391, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(843.0068, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2040.4510, device='cuda:0') tensor(3023.0603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.7461, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5402.6001, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9648, device='cuda:0') tensor(8107.0991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    270 | 89.11 ms/step | loss 8107.099 \n",
      "param_tail torch.Size([4096, 8]) tensor(0.7544, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7603.2427, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4875.0063, device='cuda:0') tensor(2283.8125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.7599, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3275.1758, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3122.6631, device='cuda:0') tensor(3998.3569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.7636, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(857.3320, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1558.0605, device='cuda:0') tensor(1166.6156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.7678, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1964.6230, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9556, device='cuda:0') tensor(9578.6631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.7732, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2424.7109, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1995.7700, device='cuda:0') tensor(1778.7517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.7792, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(442.1342, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.5310, device='cuda:0') tensor(10729.9980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.7855, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(969.0193, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.0859, device='cuda:0') tensor(7466.7822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.7924, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(739.6036, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1994.9650, device='cuda:0') tensor(1357.0061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.8014, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3846.7292, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.7747, device='cuda:0') tensor(2272.2319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.8094, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5610.9771, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.6458, device='cuda:0') tensor(5082.1772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    280 | 65.43 ms/step | loss 5082.177 \n",
      "param_tail torch.Size([3712, 8]) tensor(0.8159, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5968.3848, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.7007, device='cuda:0') tensor(2961.8657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.8233, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2426.1443, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4043.1873, device='cuda:0') tensor(10009.3154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.8315, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2213.2026, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.9561, device='cuda:0') tensor(4118.4609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.8400, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(593.2841, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.6235, device='cuda:0') tensor(10887.0273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.8491, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6737.4731, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.7549, device='cuda:0') tensor(2003.8016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.8571, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6411.3398, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.2905, device='cuda:0') tensor(2164.0784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.8656, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3955.2197, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.8206, device='cuda:0') tensor(1535.0271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.8725, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2476.6008, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1996.2365, device='cuda:0') tensor(753.1461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.8761, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2886.9414, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.3218, device='cuda:0') tensor(6094.5815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.8811, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1597.8180, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.2327, device='cuda:0') tensor(10328.6084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    290 | 89.96 ms/step | loss 10328.608 \n",
      "param_tail torch.Size([4096, 8]) tensor(0.8882, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(458.4391, device='cuda:0', grad_fn=<MaxBackward1>) tensor(750.8233, device='cuda:0') tensor(892.6388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.8961, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2388.6958, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.8896, device='cuda:0') tensor(10742.8516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.9040, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(718.1764, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1557.6641, device='cuda:0') tensor(3019.8518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.9143, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3360.2322, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2039.1918, device='cuda:0') tensor(1672.1516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.9209, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5314.3740, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.2107, device='cuda:0') tensor(1781.2417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.9259, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2023.3113, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.9258, device='cuda:0') tensor(3256.5510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.9317, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3852.3459, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.6460, device='cuda:0') tensor(4035.4695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.9384, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3589.3108, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.8381, device='cuda:0') tensor(1263.7688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.9444, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2483.7720, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.0996, device='cuda:0') tensor(5423.2500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.9522, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2462.8708, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.7734, device='cuda:0') tensor(7705.7446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    300 | 68.96 ms/step | loss 7705.745 \n",
      "param_tail torch.Size([3712, 8]) tensor(0.9601, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5898.4111, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.6416, device='cuda:0') tensor(2172.5835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.9679, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6704.2734, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.0010, device='cuda:0') tensor(11392.5234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.9735, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3626.5957, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1855, device='cuda:0') tensor(9889.5322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.9807, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1049.5587, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.3149, device='cuda:0') tensor(1016.7788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(0.9892, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6067.6958, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.6445, device='cuda:0') tensor(1104.5536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(0.9953, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4059.3650, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.1328, device='cuda:0') tensor(17974.1875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.0027, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4723.9165, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.5552, device='cuda:0') tensor(3188.6482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.0082, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(753.3467, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1996.0659, device='cuda:0') tensor(1459.2393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(1.0157, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1284.0002, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.7480, device='cuda:0') tensor(1649.7521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.0238, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2004.2018, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.1960, device='cuda:0') tensor(10372.8213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    310 | 82.19 ms/step | loss 10372.821 \n",
      "param_tail torch.Size([4096, 8]) tensor(1.0326, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1914.0618, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.0562, device='cuda:0') tensor(1589.5287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.0424, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4292.2222, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6431, device='cuda:0') tensor(8672.5664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(1.0516, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2809.1021, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.3420, device='cuda:0') tensor(2214.4421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.0611, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2954.5627, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.0269, device='cuda:0') tensor(4309.6157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.0716, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1346.5074, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.3953, device='cuda:0') tensor(2993.9976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.0822, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2100.3872, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.2251, device='cuda:0') tensor(11424.1553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(1.0927, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1532.3376, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2608.8481, device='cuda:0') tensor(2845.4875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.1041, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(553.1628, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.7566, device='cuda:0') tensor(2377.8335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.1165, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3509.5388, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.6482, device='cuda:0') tensor(1192.5024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.1286, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3570.1270, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.6470, device='cuda:0') tensor(7300.4507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    320 | 85.83 ms/step | loss 7300.451 \n",
      "param_tail torch.Size([3712, 8]) tensor(1.1420, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5138.9155, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.4163, device='cuda:0') tensor(2170.5647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.1527, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2844.6335, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.8142, device='cuda:0') tensor(1138.9291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.1608, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7837.5566, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.2495, device='cuda:0') tensor(3513.8225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.1653, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8341.9873, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.7578, device='cuda:0') tensor(3257.6077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(1.1663, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(610.7538, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1557.3436, device='cuda:0') tensor(3465.0930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.1694, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4752.8535, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.8413, device='cuda:0') tensor(3082.0610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.1741, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1492.7830, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.1121, device='cuda:0') tensor(5061.5293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.1800, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1067.9041, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.4260, device='cuda:0') tensor(7067.4810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(1.1866, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5911.5049, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.3740, device='cuda:0') tensor(2767.9421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.1905, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2522.1987, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.8818, device='cuda:0') tensor(7668.0220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    330 | 70.55 ms/step | loss 7668.022 \n",
      "param_tail torch.Size([4096, 8]) tensor(1.1967, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3483.6497, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4038.5781, device='cuda:0') tensor(1895.8755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.2035, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1843.9645, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.3457, device='cuda:0') tensor(2126.5745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(1.2113, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1206.1821, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.2422, device='cuda:0') tensor(3064.9526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.2206, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5893.8765, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.3374, device='cuda:0') tensor(1778.1362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.2268, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(821.6163, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2260.0823, device='cuda:0') tensor(2701.0439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.2339, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2247.0073, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.3152, device='cuda:0') tensor(3644.0786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(1.2403, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6589.4453, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.3926, device='cuda:0') tensor(5546.8521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.2470, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8230.8955, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.1992, device='cuda:0') tensor(2681.9937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.2505, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2533.1016, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3420.2244, device='cuda:0') tensor(1771.3822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.2550, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3399.6370, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1995.1509, device='cuda:0') tensor(1022.5148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    340 | 86.19 ms/step | loss 1022.515 \n",
      "param_tail torch.Size([3712, 8]) tensor(1.2561, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3300.8816, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.9478, device='cuda:0') tensor(5685.1401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.2593, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4252.4829, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.5815, device='cuda:0') tensor(1474.0331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.2613, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4191.3120, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.8452, device='cuda:0') tensor(5210.5615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.2624, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2352.1123, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.4551, device='cuda:0') tensor(1174.1414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(1.2645, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8187.5283, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.8711, device='cuda:0') tensor(1760.3938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.2637, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2593.5767, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2611.3677, device='cuda:0') tensor(1764.0923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.2627, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1772.3301, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.7268, device='cuda:0') tensor(2942.4614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.2630, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2245.2959, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.2656, device='cuda:0') tensor(2465.7664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(1.2654, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6105.5430, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1396, device='cuda:0') tensor(1017.8460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.2700, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3779.4932, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4316, device='cuda:0') tensor(7762.3008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    350 | 89.13 ms/step | loss 7762.301 \n",
      "param_tail torch.Size([4096, 8]) tensor(1.2759, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1813.6702, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.3169, device='cuda:0') tensor(3557.5320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.2828, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5804.7324, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.5068, device='cuda:0') tensor(1049.3502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(1.2872, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3075.5852, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.2456, device='cuda:0') tensor(1169.9274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.2932, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1694.5748, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.7715, device='cuda:0') tensor(7900.1108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.3001, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(574.5217, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1329.6370, device='cuda:0') tensor(844.6964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.3090, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1593.5424, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4116, device='cuda:0') tensor(5523.9653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(1.3194, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3289.5969, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.1882, device='cuda:0') tensor(2041.0582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.3301, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3578.6946, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.9480, device='cuda:0') tensor(1086.5076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.3394, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1822.2487, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1993.4502, device='cuda:0') tensor(702.6687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.3508, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2095.7063, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.6470, device='cuda:0') tensor(5883.8818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    360 | 71.45 ms/step | loss 5883.882 \n",
      "param_tail torch.Size([3712, 8]) tensor(1.3630, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1896.7590, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.3174, device='cuda:0') tensor(8733.2246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.3764, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4222.9131, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.5273, device='cuda:0') tensor(6814.8525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.3903, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1708.3190, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.4609, device='cuda:0') tensor(3874.0933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.4021, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4261.7002, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.5427, device='cuda:0') tensor(1637.3599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(1.4117, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4631.6108, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.0103, device='cuda:0') tensor(1325.4049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.4234, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4895.0859, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.0142, device='cuda:0') tensor(2474.6716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.4362, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4917.5439, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.9424, device='cuda:0') tensor(3168.4832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.4468, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1780.9952, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1556.6742, device='cuda:0') tensor(996.4799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(1.4558, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1956.9172, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.4187, device='cuda:0') tensor(2359.5112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.4656, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1738.3761, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3419.3105, device='cuda:0') tensor(7442.3892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    370 | 80.05 ms/step | loss 7442.389 \n",
      "param_tail torch.Size([4096, 8]) tensor(1.4753, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2426.4497, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.4292, device='cuda:0') tensor(7421.2085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.4871, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1975.8701, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.9055, device='cuda:0') tensor(1449.5731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(1.4973, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8122.5278, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.1533, device='cuda:0') tensor(9218.4941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.5051, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3117.5396, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.7935, device='cuda:0') tensor(3363.7659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.5150, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1830.1366, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1558.0693, device='cuda:0') tensor(880.3352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.5257, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2882.9543, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2040.7590, device='cuda:0') tensor(1543.9985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(1.5335, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4734.7168, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.5107, device='cuda:0') tensor(5317.1719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.5389, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3357.3816, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.4250, device='cuda:0') tensor(1159.0226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.5452, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5737.9102, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.4810, device='cuda:0') tensor(1603.6658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.5500, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6673.0537, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.9946, device='cuda:0') tensor(2011.4904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    380 | 86.75 ms/step | loss 2011.490 \n",
      "param_tail torch.Size([3712, 8]) tensor(1.5530, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6807.1938, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.1243, device='cuda:0') tensor(9244.7471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.5543, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2344.0591, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.9595, device='cuda:0') tensor(3311.0730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.5576, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1605.9552, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.0608, device='cuda:0') tensor(1233.1202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.5624, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2314.6067, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.3149, device='cuda:0') tensor(4992.2075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(1.5689, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(11987.4150, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9370, device='cuda:0') tensor(7678.2578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.5715, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2570.0264, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.0259, device='cuda:0') tensor(1270.1901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.5759, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3333.1233, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.2129, device='cuda:0') tensor(1052.5806, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.5830, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7669.4141, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.4590, device='cuda:0') tensor(1545.1213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(1.5868, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5266.3740, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.1289, device='cuda:0') tensor(1281.1051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.5869, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4603.3301, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.7593, device='cuda:0') tensor(2322.1196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    390 | 71.31 ms/step | loss 2322.120 \n",
      "param_tail torch.Size([4096, 8]) tensor(1.5901, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3327.1663, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.1479, device='cuda:0') tensor(5137.0742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.5954, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(264.0154, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.8699, device='cuda:0') tensor(9296.0615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(1.6017, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(414.9452, device='cuda:0', grad_fn=<MaxBackward1>) tensor(749.3947, device='cuda:0') tensor(1713.2174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.6094, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1089.2590, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.3975, device='cuda:0') tensor(13246.4307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.6182, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2702.4336, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.3750, device='cuda:0') tensor(946.6589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.6293, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2500.3835, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6509, device='cuda:0') tensor(5820.7129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(1.6418, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2952.4700, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.6980, device='cuda:0') tensor(3294.6719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.6553, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5365.1182, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.1489, device='cuda:0') tensor(1841.4316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.6647, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(844.2015, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9575, device='cuda:0') tensor(14834.4570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.6803, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2271.4849, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.6267, device='cuda:0') tensor(1237.2649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    400 | 79.06 ms/step | loss 1237.265 \n",
      "param_tail torch.Size([3712, 8]) tensor(1.7000, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2685.5454, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.0254, device='cuda:0') tensor(1112.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "checking 99\n",
      "(16000, 2) torch.Size([16000, 2]) 28.868687989474132 aloha\n",
      "saving iteration- 99\n",
      "param_tail torch.Size([4096, 8]) tensor(1.7199, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1828.0045, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.0227, device='cuda:0') tensor(4677.5205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.7410, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1023.6625, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.2693, device='cuda:0') tensor(5513.4648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.7616, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4544.1074, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.9268, device='cuda:0') tensor(4253.8262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(1.7820, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1947.2307, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.7993, device='cuda:0') tensor(2574.5959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.8035, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3010.0642, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.7915, device='cuda:0') tensor(1069.7197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.8252, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3265.4985, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3419.0703, device='cuda:0') tensor(1154.7108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.8424, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2701.9609, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.6436, device='cuda:0') tensor(3256.7964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(1.8563, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5022.1992, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1294, device='cuda:0') tensor(1907.1497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.8714, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4717.0723, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.6270, device='cuda:0') tensor(1893.7488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    410 | 234.61 ms/step | loss 1893.749 \n",
      "param_tail torch.Size([4096, 8]) tensor(1.8870, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2315.2183, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.9534, device='cuda:0') tensor(2073.3354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.9044, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2112.9041, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.6306, device='cuda:0') tensor(922.2234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(1.9239, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4969.5127, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.1533, device='cuda:0') tensor(1750.9022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.9407, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3966.9614, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.8721, device='cuda:0') tensor(10106.4199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.9526, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1451.9014, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2039.5400, device='cuda:0') tensor(1217.0231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.9668, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1820.7162, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.8130, device='cuda:0') tensor(2827.5398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(1.9827, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6950.2446, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9761, device='cuda:0') tensor(1433.3625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(1.9990, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4457.4370, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.8364, device='cuda:0') tensor(2027.5658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.0153, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4854.8350, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.8755, device='cuda:0') tensor(3530.9629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.0284, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3806.0039, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.6272, device='cuda:0') tensor(3275.0852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    420 | 78.17 ms/step | loss 3275.085 \n",
      "param_tail torch.Size([3712, 8]) tensor(2.0374, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1188.7887, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2258.8823, device='cuda:0') tensor(2342.1101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.0498, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3318.4099, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.2065, device='cuda:0') tensor(10972.7305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.0616, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4815.8511, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.4902, device='cuda:0') tensor(4467.8276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.0690, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6932.0859, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.3921, device='cuda:0') tensor(4171.9219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(2.0726, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1172.2937, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1173.0889, device='cuda:0') tensor(885.6107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.0784, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3587.0298, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.0996, device='cuda:0') tensor(5528.1504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.0812, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(694.3925, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.1392, device='cuda:0') tensor(1262.3617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.0875, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1187.8280, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1995.5946, device='cuda:0') tensor(875.1985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(2.0961, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7866.7383, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.0547, device='cuda:0') tensor(2667.3911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.1025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(847.4567, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.8892, device='cuda:0') tensor(2166.2429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    430 | 78.19 ms/step | loss 2166.243 \n",
      "param_tail torch.Size([4096, 8]) tensor(2.1125, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7431.9053, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.8599, device='cuda:0') tensor(6696.8975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.1200, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2224.6426, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.1160, device='cuda:0') tensor(6433.2871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(2.1300, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3490.6951, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.6597, device='cuda:0') tensor(2739.1318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.1407, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2352.1360, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9766, device='cuda:0') tensor(11317.1953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.1525, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(474.1912, device='cuda:0', grad_fn=<MaxBackward1>) tensor(946.0101, device='cuda:0') tensor(793.6239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.1626, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2105.4595, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.4138, device='cuda:0') tensor(1544.1312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(2.1753, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3435.3308, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.8972, device='cuda:0') tensor(1398.8074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.1898, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1775.1980, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.6899, device='cuda:0') tensor(1339.2893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.2068, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3568.7815, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.3301, device='cuda:0') tensor(7751.6104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.2255, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2036.3445, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.1699, device='cuda:0') tensor(1911.6765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    440 | 64.62 ms/step | loss 1911.677 \n",
      "param_tail torch.Size([3712, 8]) tensor(2.2458, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1382.2714, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.1248, device='cuda:0') tensor(12026.0654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.2673, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7376.6558, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.9404, device='cuda:0') tensor(9254.9932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.2893, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2834.7681, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.0486, device='cuda:0') tensor(2304.8455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.3108, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3659.6150, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.7400, device='cuda:0') tensor(1338.4391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(2.3288, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1178.2081, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1559.2178, device='cuda:0') tensor(1484.1763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.3485, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1309.2488, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9727, device='cuda:0') tensor(6995.1660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.3692, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2536.1880, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.7126, device='cuda:0') tensor(2013.6144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.3910, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4838.8042, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.1982, device='cuda:0') tensor(1339.2161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(2.4073, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4031.9453, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.0640, device='cuda:0') tensor(1057.7794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.4242, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4667.9473, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.6379, device='cuda:0') tensor(1414.1362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    450 | 82.59 ms/step | loss 1414.136 \n",
      "param_tail torch.Size([4096, 8]) tensor(2.4356, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5874.9355, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.5298, device='cuda:0') tensor(1503.4471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.4420, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3320.9607, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3415.7910, device='cuda:0') tensor(1280.8767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(2.4515, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6232.8418, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.3638, device='cuda:0') tensor(1588.2522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.4608, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3791.4045, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3420.2026, device='cuda:0') tensor(993.9818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.4662, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6071.1870, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.4834, device='cuda:0') tensor(2667.8550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.4678, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2725.6882, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.3662, device='cuda:0') tensor(2886.5056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(2.4735, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5255.8984, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.4453, device='cuda:0') tensor(4225.0483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.4779, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1933.1036, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.4177, device='cuda:0') tensor(2286.7327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.4800, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2857.6555, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.7036, device='cuda:0') tensor(3045.0854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.4854, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3171.0266, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.0020, device='cuda:0') tensor(9318.8184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    460 | 82.66 ms/step | loss 9318.818 \n",
      "param_tail torch.Size([3712, 8]) tensor(2.4928, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6721.5303, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.7954, device='cuda:0') tensor(867.1713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.4978, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3037.1929, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.4297, device='cuda:0') tensor(1537.7592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.5061, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7949.6226, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.6558, device='cuda:0') tensor(3750.6626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.5123, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2368.1294, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.1157, device='cuda:0') tensor(3111.7671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(2.5195, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2129.3687, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.9741, device='cuda:0') tensor(2248.2358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.5294, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3109.0769, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.8010, device='cuda:0') tensor(1390.9532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.5401, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1285.4240, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.3613, device='cuda:0') tensor(3770.5266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.5538, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2934.1157, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.5408, device='cuda:0') tensor(2246.1016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(2.5697, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7393.8452, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.1484, device='cuda:0') tensor(1277.5698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.5823, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4812.4214, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1147, device='cuda:0') tensor(1729.9072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    470 | 66.40 ms/step | loss 1729.907 \n",
      "param_tail torch.Size([4096, 8]) tensor(2.5959, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1524.9412, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.1604, device='cuda:0') tensor(4090.5996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.6115, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1949.6444, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.5408, device='cuda:0') tensor(3810.4915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(2.6295, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6233.8008, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.4312, device='cuda:0') tensor(2946.2219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.6455, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5435.1475, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.4946, device='cuda:0') tensor(1351.1334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.6567, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5391.5010, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.5750, device='cuda:0') tensor(3432.5562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.6635, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5824.6509, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.3525, device='cuda:0') tensor(8785.1211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(2.6681, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5008.1528, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3122.4575, device='cuda:0') tensor(1809.3403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.6684, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2054.2705, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.2219, device='cuda:0') tensor(5066.9731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.6704, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1207.7625, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1174.0973, device='cuda:0') tensor(806.3754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.6741, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5230.9756, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.3110, device='cuda:0') tensor(1293.7784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    480 | 79.69 ms/step | loss 1293.778 \n",
      "param_tail torch.Size([3712, 8]) tensor(2.6804, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4264.2271, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.7979, device='cuda:0') tensor(2765.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.6825, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7025.7959, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1460, device='cuda:0') tensor(969.9283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.6826, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2717.2983, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.2158, device='cuda:0') tensor(4256.7012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.6866, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2578.8701, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.6086, device='cuda:0') tensor(986.2925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(2.6947, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1801.5371, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.3638, device='cuda:0') tensor(5416.7666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.7038, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3667.3638, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.6062, device='cuda:0') tensor(2981.5234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.7157, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2184.5728, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1279, device='cuda:0') tensor(8869.6172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.7299, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2267.1292, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.1287, device='cuda:0') tensor(1624.6447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(2.7466, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5443.3584, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.0889, device='cuda:0') tensor(788.1457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.7589, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5485.1680, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.6729, device='cuda:0') tensor(1854.3041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    490 | 68.21 ms/step | loss 1854.304 \n",
      "param_tail torch.Size([4096, 8]) tensor(2.7711, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2599.2375, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.8735, device='cuda:0') tensor(1324.9728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.7866, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2296.8101, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.8999, device='cuda:0') tensor(5017.2871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(2.8034, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1800.2424, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.2212, device='cuda:0') tensor(9031.5166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.8223, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3501.5269, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.3154, device='cuda:0') tensor(12474.2080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.8422, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2793.0298, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.9241, device='cuda:0') tensor(2047.6854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.8618, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5232.4048, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.2183, device='cuda:0') tensor(1498.7382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(2.8817, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1397.3206, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.4475, device='cuda:0') tensor(3568.5723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.9042, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6080.0239, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.3945, device='cuda:0') tensor(1313.7083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.9275, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2988.2822, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.5569, device='cuda:0') tensor(3968.7026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(2.9531, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1195.0106, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1329.1012, device='cuda:0') tensor(1236.6038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    500 | 97.31 ms/step | loss 1236.604 \n",
      "param_tail torch.Size([3712, 8]) tensor(2.9797, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4365.0200, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.5850, device='cuda:0') tensor(1690.0118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.0064, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3271.7222, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.3369, device='cuda:0') tensor(1086.8411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.0296, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1798.7922, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.8135, device='cuda:0') tensor(3166.6416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.0484, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(10786.0898, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.4292, device='cuda:0') tensor(6506.5938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(3.0645, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(707.6497, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1328.6151, device='cuda:0') tensor(927.1359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.0835, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1076.1095, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.6956, device='cuda:0') tensor(1469.3876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.1053, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8248.5342, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.2588, device='cuda:0') tensor(2453.3811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.1240, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4803.1836, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4043.3157, device='cuda:0') tensor(3129.0935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(3.1401, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2063.9019, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.7686, device='cuda:0') tensor(2576.1763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.1583, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2921.1851, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.4028, device='cuda:0') tensor(1113.0643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    510 | 85.76 ms/step | loss 1113.064 \n",
      "param_tail torch.Size([4096, 8]) tensor(3.1731, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1126.8889, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1558.9045, device='cuda:0') tensor(864.3617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.1906, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2635.1377, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.7883, device='cuda:0') tensor(3740.4180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(3.2102, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6335.8521, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4307, device='cuda:0') tensor(3159.9080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.2265, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4739.8867, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.7861, device='cuda:0') tensor(5985.3467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.2439, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4247.0630, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.0864, device='cuda:0') tensor(2155.5200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.2594, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(388.2700, device='cuda:0', grad_fn=<MaxBackward1>) tensor(924.4612, device='cuda:0') tensor(828.6473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(3.2783, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1181.8871, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.9255, device='cuda:0') tensor(1589.8826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.3001, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3443.5659, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.3547, device='cuda:0') tensor(1706.8516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.3223, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3339.9006, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.9424, device='cuda:0') tensor(1307.8354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.3435, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1972.1359, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.8833, device='cuda:0') tensor(7211.0127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    520 | 68.12 ms/step | loss 7211.013 \n",
      "param_tail torch.Size([3712, 8]) tensor(3.3648, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(913.5758, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.2749, device='cuda:0') tensor(11548.4727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.3888, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5539.2021, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.3672, device='cuda:0') tensor(8427.5039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.4094, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6253.6992, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.0010, device='cuda:0') tensor(1195.9827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.4294, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3373.3513, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3122.0715, device='cuda:0') tensor(1812.4072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(3.4438, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2300.7388, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4038.5342, device='cuda:0') tensor(11625.4004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.4534, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3559.2349, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3122.7695, device='cuda:0') tensor(1168.6296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.4585, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4798.0015, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.5776, device='cuda:0') tensor(2106.2893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.4670, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5183.2671, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9111, device='cuda:0') tensor(8150.6318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(3.4762, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1815.2700, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.3975, device='cuda:0') tensor(934.7300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.4884, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2598.6079, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2258.7458, device='cuda:0') tensor(1357.1162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    530 | 80.57 ms/step | loss 1357.116 \n",
      "param_tail torch.Size([4096, 8]) tensor(3.4961, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2603.2942, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.5896, device='cuda:0') tensor(1094.9062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.5062, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8290.4844, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.3638, device='cuda:0') tensor(2277.8867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(3.5125, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4460.9956, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4038.3684, device='cuda:0') tensor(2035.6096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.5165, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6695.6333, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9570, device='cuda:0') tensor(2415.4253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.5190, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1534.6688, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.9663, device='cuda:0') tensor(939.2870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.5264, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1521.1455, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1560.9296, device='cuda:0') tensor(1021.0284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(3.5313, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3885.8738, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.0361, device='cuda:0') tensor(3206.5581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.5375, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3598.6284, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9370, device='cuda:0') tensor(5808.1587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.5457, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1054.6893, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2608.7639, device='cuda:0') tensor(1613.3022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.5568, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1706.8876, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.6055, device='cuda:0') tensor(4682.9834, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    540 | 79.19 ms/step | loss 4682.983 \n",
      "param_tail torch.Size([3712, 8]) tensor(3.5687, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5468.5781, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.0303, device='cuda:0') tensor(1204.3004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.5826, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4354.5542, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.2136, device='cuda:0') tensor(3412.1909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.5907, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3608.2908, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.4070, device='cuda:0') tensor(1065.7380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.5954, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4567.9214, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.4097, device='cuda:0') tensor(6151.9019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(3.6020, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2184.0803, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.7051, device='cuda:0') tensor(2037.1604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.6121, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1683.5312, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.7539, device='cuda:0') tensor(6246.5469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.6238, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3790.2769, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.6541, device='cuda:0') tensor(883.3553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.6336, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3852.5146, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.0337, device='cuda:0') tensor(3621.5420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(3.6474, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4056.8325, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.8374, device='cuda:0') tensor(765.9583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.6556, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3155.9077, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9570, device='cuda:0') tensor(3921.1545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    550 | 64.83 ms/step | loss 3921.155 \n",
      "param_tail torch.Size([4096, 8]) tensor(3.6659, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4453.9219, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.7065, device='cuda:0') tensor(1334.2153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.6739, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6095.5029, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.5278, device='cuda:0') tensor(1001.4178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(3.6781, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1496.8929, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.2412, device='cuda:0') tensor(7715.4517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.6861, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1173.6274, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.9170, device='cuda:0') tensor(4731.4443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.6966, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3169.5015, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.5908, device='cuda:0') tensor(6631.7671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.7099, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2383.9995, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.0696, device='cuda:0') tensor(1392.3113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(3.7270, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2026.1829, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4126, device='cuda:0') tensor(9470.9766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.7475, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(708.4718, device='cuda:0', grad_fn=<MaxBackward1>) tensor(749.2916, device='cuda:0') tensor(679.5534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.7659, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2363.9824, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.2666, device='cuda:0') tensor(11090.9404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.7832, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(10221.6113, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.0386, device='cuda:0') tensor(5108.2417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    560 | 80.69 ms/step | loss 5108.242 \n",
      "param_tail torch.Size([3712, 8]) tensor(3.7972, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3551.6707, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.9312, device='cuda:0') tensor(1166.2872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.8066, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3846.2744, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.9148, device='cuda:0') tensor(1132.3496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.8114, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2273.6765, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9702, device='cuda:0') tensor(5823.9502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.8198, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2209.1523, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2258.3140, device='cuda:0') tensor(888.9132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(3.8297, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1989.1189, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.2708, device='cuda:0') tensor(5027.2983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.8429, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7949.0425, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.4907, device='cuda:0') tensor(1750.7546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.8541, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4299.2524, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.2024, device='cuda:0') tensor(2467.3564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.8608, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1344.9894, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1559.0386, device='cuda:0') tensor(998.5420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(3.8713, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3639.2632, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.3701, device='cuda:0') tensor(1397.9014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.8852, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6559.3374, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.3306, device='cuda:0') tensor(1755.5308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    570 | 65.72 ms/step | loss 1755.531 \n",
      "param_tail torch.Size([4096, 8]) tensor(3.8980, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5497.4565, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.7388, device='cuda:0') tensor(9308.7256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.9065, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4345.0034, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.1755, device='cuda:0') tensor(1096.0129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(3.9102, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(891.7420, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.8511, device='cuda:0') tensor(2135.5986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.9188, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6382.9170, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.3198, device='cuda:0') tensor(1590.6296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.9242, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4046.6167, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.4133, device='cuda:0') tensor(2543.9241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.9319, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1584.0852, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.3794, device='cuda:0') tensor(1300.4232, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(3.9436, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1201.4250, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2039.4509, device='cuda:0') tensor(1173.5808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.9572, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2505.6438, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.9897, device='cuda:0') tensor(2970.4312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.9724, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3776.7954, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.9648, device='cuda:0') tensor(3535.8057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(3.9892, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3906.8354, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.5371, device='cuda:0') tensor(2951.0693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    580 | 81.56 ms/step | loss 2951.069 \n",
      "param_tail torch.Size([3712, 8]) tensor(4.0057, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1511.6064, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.2957, device='cuda:0') tensor(2317.6843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.0262, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4215.3027, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.2046, device='cuda:0') tensor(2042.7692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.0413, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6636.8726, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.8530, device='cuda:0') tensor(3942.2891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.0540, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(636.4174, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1127.4092, device='cuda:0') tensor(1143.1511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(4.0710, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3895.6367, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.1392, device='cuda:0') tensor(1811.9496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.0861, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2675.7493, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.1226, device='cuda:0') tensor(1343.7334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.0993, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3840.3286, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.1099, device='cuda:0') tensor(849.0817, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.1109, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5077.2236, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.9072, device='cuda:0') tensor(5961.1343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(4.1248, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4574.3276, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6880, device='cuda:0') tensor(1744.0514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.1397, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4360.3047, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4038.6924, device='cuda:0') tensor(1466.4231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    590 | 84.82 ms/step | loss 1466.423 \n",
      "param_tail torch.Size([4096, 8]) tensor(4.1519, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2923.4500, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.8557, device='cuda:0') tensor(806.6021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.1683, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4637.7690, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.7554, device='cuda:0') tensor(2400.7422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(4.1860, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4148.5962, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4874.0562, device='cuda:0') tensor(1215.6686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.2061, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2653.2332, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.2532, device='cuda:0') tensor(5192.0703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.2285, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1872.8613, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1996.1133, device='cuda:0') tensor(916.1270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.2541, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5671.2134, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9873, device='cuda:0') tensor(1823.1938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(4.2782, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2601.4714, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2611.0657, device='cuda:0') tensor(1848.5735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.2966, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8563.9775, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9272, device='cuda:0') tensor(5745.1641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.3095, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2423.0652, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.5292, device='cuda:0') tensor(757.4471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.3226, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4976.7417, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.4148, device='cuda:0') tensor(1832.6772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    600 | 68.77 ms/step | loss 1832.677 \n",
      "param_tail torch.Size([3712, 8]) tensor(4.3330, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(431.8423, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.9873, device='cuda:0') tensor(1836.5668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "checking 149\n",
      "(16000, 2) torch.Size([16000, 2]) 28.75123190220721 aloha\n",
      "saving iteration- 149\n",
      "param_tail torch.Size([4096, 8]) tensor(4.3478, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(900.6248, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.1387, device='cuda:0') tensor(8472.2783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.3657, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2136.9331, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.5627, device='cuda:0') tensor(988.7112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.3874, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3895.9382, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9556, device='cuda:0') tensor(4300.8286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(4.4091, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1450.7639, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.8291, device='cuda:0') tensor(1103.5707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.4331, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4005.8403, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.6963, device='cuda:0') tensor(1384.2769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.4547, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6634.1616, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.7339, device='cuda:0') tensor(2029.5901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.4774, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2990.2715, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.4146, device='cuda:0') tensor(3086.5947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(4.5021, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(771.0842, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1328.9983, device='cuda:0') tensor(1425.1776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.5292, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3385.9146, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.8582, device='cuda:0') tensor(1311.8513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    610 | 260.62 ms/step | loss 1311.851 \n",
      "param_tail torch.Size([4096, 8]) tensor(4.5585, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2539.5171, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.5078, device='cuda:0') tensor(1228.7297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.5895, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6105.3257, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.5356, device='cuda:0') tensor(8976.7031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(4.6162, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5104.6812, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9688, device='cuda:0') tensor(1478.8395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.6431, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3535.1819, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.1814, device='cuda:0') tensor(1081.7551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.6691, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7494.9082, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.5874, device='cuda:0') tensor(2084.4177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.6884, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3199.2983, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.3750, device='cuda:0') tensor(3555.1448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(4.7105, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1105.1569, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1559.7161, device='cuda:0') tensor(946.0989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.7356, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1938.4407, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2611.2463, device='cuda:0') tensor(1318.5852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.7561, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3757.1768, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.7832, device='cuda:0') tensor(2424.1934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.7790, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2726.8750, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.8296, device='cuda:0') tensor(9245.8184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    620 | 66.61 ms/step | loss 9245.818 \n",
      "param_tail torch.Size([3712, 8]) tensor(4.8030, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2739.0288, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1993.8022, device='cuda:0') tensor(752.8715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.8238, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2871.4570, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.2714, device='cuda:0') tensor(1016.6953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.8434, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3684.1436, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.5239, device='cuda:0') tensor(1194.1160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.8565, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1425.8062, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.1489, device='cuda:0') tensor(3956.4038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(4.8737, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5536.3516, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.5425, device='cuda:0') tensor(6254.0645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.8851, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5094.9478, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.7095, device='cuda:0') tensor(6975.7417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.8911, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4077.9026, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.2798, device='cuda:0') tensor(4779.6543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.8972, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5291.8535, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.9199, device='cuda:0') tensor(1589.9309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(4.9009, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1326.5012, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2258.6257, device='cuda:0') tensor(1766.6061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.9101, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1389.9061, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.9282, device='cuda:0') tensor(7636.5635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    630 | 79.04 ms/step | loss 7636.563 \n",
      "param_tail torch.Size([4096, 8]) tensor(4.9234, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4159.5220, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.6509, device='cuda:0') tensor(3484.8164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.9370, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2555.4678, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.6431, device='cuda:0') tensor(4584.7837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(4.9531, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1264.7802, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.4863, device='cuda:0') tensor(1137.7069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.9731, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4113.2354, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.7820, device='cuda:0') tensor(20130.9980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(4.9871, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4039.4600, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.1216, device='cuda:0') tensor(2842.0537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.0030, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1609.3496, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.3374, device='cuda:0') tensor(4087.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(5.0235, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1187.5459, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1154.8915, device='cuda:0') tensor(705.3832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.0483, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5542.6924, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.2710, device='cuda:0') tensor(2151.6279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.0747, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9162.6377, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.8970, device='cuda:0') tensor(3226.7881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.0969, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(703.8094, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.2800, device='cuda:0') tensor(11617.4033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    640 | 82.63 ms/step | loss 11617.403 \n",
      "param_tail torch.Size([3712, 8]) tensor(5.1236, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2298.3066, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.1172, device='cuda:0') tensor(1442.1381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.1441, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5315.2939, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.9663, device='cuda:0') tensor(5342.9990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.1641, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3015.2302, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.4502, device='cuda:0') tensor(1707.0325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.1778, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7721.7637, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.6401, device='cuda:0') tensor(2802.5757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(5.1847, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3156.2578, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.6265, device='cuda:0') tensor(10898.1357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.1917, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3855.6289, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3122.7036, device='cuda:0') tensor(1553.8289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.1932, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6525.9297, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.7974, device='cuda:0') tensor(17922.6445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.1957, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1247.0328, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.3059, device='cuda:0') tensor(896.0494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(5.2041, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2999.4731, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2258.4670, device='cuda:0') tensor(1311.5714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.2081, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9183.3447, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6880, device='cuda:0') tensor(2922.2261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    650 | 63.72 ms/step | loss 2922.226 \n",
      "param_tail torch.Size([4096, 8]) tensor(5.2083, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2144.6213, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.7524, device='cuda:0') tensor(1905.7983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.2136, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1895.4585, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.5747, device='cuda:0') tensor(2086.6194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(5.2219, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4394.1201, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.9202, device='cuda:0') tensor(2694.9553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.2249, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3457.0303, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.8542, device='cuda:0') tensor(925.7327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.2297, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4075.0054, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.4937, device='cuda:0') tensor(4417.5459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.2312, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4221.7866, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.6943, device='cuda:0') tensor(1721.1044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(5.2350, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1741.8584, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1557.5903, device='cuda:0') tensor(1476.6979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.2348, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(813.0354, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2608.4751, device='cuda:0') tensor(1261.0386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.2380, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2844.0874, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.9272, device='cuda:0') tensor(4844.5005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.2375, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1863.0209, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2255.6880, device='cuda:0') tensor(1330.0952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    660 | 86.87 ms/step | loss 1330.095 \n",
      "param_tail torch.Size([3712, 8]) tensor(5.2353, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5606.5312, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.7661, device='cuda:0') tensor(2869.5281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.2382, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3768.5508, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.7676, device='cuda:0') tensor(2435.2598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.2432, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3625.3003, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.9766, device='cuda:0') tensor(10539.0625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.2511, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2912.1565, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.8364, device='cuda:0') tensor(1938.8167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(5.2617, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2464.4905, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.9392, device='cuda:0') tensor(1482.8341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.2771, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1564.2711, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2608.1389, device='cuda:0') tensor(941.8494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.2970, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3383.2595, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.1143, device='cuda:0') tensor(3197.0552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.3197, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4033.3669, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.7905, device='cuda:0') tensor(1166.3066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(5.3461, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5610.3975, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.8755, device='cuda:0') tensor(1718.6667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.3696, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2926.3438, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.8210, device='cuda:0') tensor(911.6319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    670 | 87.05 ms/step | loss  911.632 \n",
      "param_tail torch.Size([4096, 8]) tensor(5.3959, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2409.7180, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.1060, device='cuda:0') tensor(6415.2910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.4233, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5730.5469, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.7803, device='cuda:0') tensor(909.2780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(5.4451, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3516.1624, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.2358, device='cuda:0') tensor(3905.2610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.4685, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1369.7482, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3420.0195, device='cuda:0') tensor(6289.6890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.4944, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3507.3450, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.6943, device='cuda:0') tensor(1911.1133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.5240, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4931.6230, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.1787, device='cuda:0') tensor(2899.6953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(5.5539, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3256.4126, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.6174, device='cuda:0') tensor(1529.8373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.5832, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3373.4299, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.6274, device='cuda:0') tensor(11532.5664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.6152, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7959.2803, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.4224, device='cuda:0') tensor(1947.5911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.6394, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1336.2367, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2608.6055, device='cuda:0') tensor(2413.7258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    680 | 72.46 ms/step | loss 2413.726 \n",
      "param_tail torch.Size([3712, 8]) tensor(5.6682, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2528.6365, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.7710, device='cuda:0') tensor(5592.2241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.6968, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4240.7725, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.3833, device='cuda:0') tensor(3685.0647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.7185, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4117.3071, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.5908, device='cuda:0') tensor(1309.8723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.7442, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(10033.1211, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.8994, device='cuda:0') tensor(3155.5222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(5.7658, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1984.4514, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.2660, device='cuda:0') tensor(1019.6324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.7904, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4034.5991, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.0474, device='cuda:0') tensor(809.2159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.8186, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1747.7993, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.6025, device='cuda:0') tensor(23434.4805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.8484, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3019.5737, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.5637, device='cuda:0') tensor(1278.8837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(5.8718, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2236.8916, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.8718, device='cuda:0') tensor(3662.9485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.8945, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1680.7725, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.7266, device='cuda:0') tensor(1144.9127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    690 | 89.82 ms/step | loss 1144.913 \n",
      "param_tail torch.Size([4096, 8]) tensor(5.9208, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2453.6257, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6209.9634, device='cuda:0') tensor(5567.8506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.9500, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4391.0181, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.6775, device='cuda:0') tensor(1783.5547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(5.9742, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4443.9419, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.5200, device='cuda:0') tensor(1437.9846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(5.9991, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1527.1466, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.5022, device='cuda:0') tensor(10299.7314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.0269, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(904.5519, device='cuda:0', grad_fn=<MaxBackward1>) tensor(749.8218, device='cuda:0') tensor(608.8643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.0590, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4122.1768, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.5396, device='cuda:0') tensor(5892.7104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(6.0886, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2695.7290, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4874.2407, device='cuda:0') tensor(6041.3315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.1209, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3964.3599, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.3181, device='cuda:0') tensor(1652.1527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.1462, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3270.4773, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.1963, device='cuda:0') tensor(6635.3662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.1703, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1008.7743, device='cuda:0', grad_fn=<MaxBackward1>) tensor(946.4371, device='cuda:0') tensor(708.2242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    700 | 86.11 ms/step | loss  708.224 \n",
      "param_tail torch.Size([3712, 8]) tensor(6.1983, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4577.0176, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.8335, device='cuda:0') tensor(3266.5229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.2197, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1040.7349, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1328.3887, device='cuda:0') tensor(616.9999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.2418, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5185.4180, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.1897, device='cuda:0') tensor(2888.7610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.2603, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4012.6731, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.4375, device='cuda:0') tensor(1736.5522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(6.2821, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6076.9937, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.2222, device='cuda:0') tensor(1479.9985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.3042, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4619.9932, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.7007, device='cuda:0') tensor(935.3859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.3220, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7488.0889, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.5737, device='cuda:0') tensor(6868.8301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.3378, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1170.1108, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2258.6931, device='cuda:0') tensor(1763.0425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(6.3590, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1414.9813, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.7583, device='cuda:0') tensor(6781.7310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.3826, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1247.5264, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1558.5055, device='cuda:0') tensor(757.7683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    710 | 70.50 ms/step | loss  757.768 \n",
      "param_tail torch.Size([4096, 8]) tensor(6.4029, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7129.8262, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.7817, device='cuda:0') tensor(1991.6636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.4211, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2037.2117, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4874.1963, device='cuda:0') tensor(2270.9004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(6.4433, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3349.0986, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.8457, device='cuda:0') tensor(7243.4731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.4664, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2909.4541, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.4395, device='cuda:0') tensor(2526.7549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.4935, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4006.7144, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.9443, device='cuda:0') tensor(2287.8560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.5211, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2159.9717, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4043.1243, device='cuda:0') tensor(4464.2803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(6.5496, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2291.1831, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.8655, device='cuda:0') tensor(718.3217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.5813, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4968.5542, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.0464, device='cuda:0') tensor(4783.4595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.6149, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3376.4065, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.7539, device='cuda:0') tensor(4753.9946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.6449, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4103.6250, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.5725, device='cuda:0') tensor(873.0238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    720 | 87.34 ms/step | loss  873.024 \n",
      "param_tail torch.Size([3712, 8]) tensor(6.6747, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3661.3621, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.6025, device='cuda:0') tensor(730.3785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.6973, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4601.8320, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.4033, device='cuda:0') tensor(996.4357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.7120, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7533.7827, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.8916, device='cuda:0') tensor(2378.5027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.7199, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6126.6079, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6406, device='cuda:0') tensor(1734.2867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(6.7280, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1049.1514, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.3174, device='cuda:0') tensor(6445.4731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.7407, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3598.5847, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.9165, device='cuda:0') tensor(3518.2451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.7567, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2733.2031, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.7148, device='cuda:0') tensor(3064.0938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.7785, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2099.3923, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1329.9386, device='cuda:0') tensor(867.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(6.7985, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4342.6807, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.9446, device='cuda:0') tensor(2002.4622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.8128, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2462.8386, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.0718, device='cuda:0') tensor(10988.4814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    730 | 75.09 ms/step | loss 10988.481 \n",
      "param_tail torch.Size([4096, 8]) tensor(6.8292, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4519.3447, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.8193, device='cuda:0') tensor(2493.5415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.8400, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4155.6758, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.2451, device='cuda:0') tensor(1170.8123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(6.8444, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1595.1296, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2042.1980, device='cuda:0') tensor(1086.0364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.8552, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(892.5175, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2039.8782, device='cuda:0') tensor(1824.9082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.8721, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3663.4419, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.5728, device='cuda:0') tensor(646.0344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.8842, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7865.4502, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.8608, device='cuda:0') tensor(4227.1953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(6.8929, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2472.2773, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2611.2148, device='cuda:0') tensor(790.4449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.9072, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8377.3594, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.5981, device='cuda:0') tensor(3795.1189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.9175, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4099.5352, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.9707, device='cuda:0') tensor(1606.3571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.9318, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2006.8035, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2040.9242, device='cuda:0') tensor(1463.2980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    740 | 92.84 ms/step | loss 1463.298 \n",
      "param_tail torch.Size([3712, 8]) tensor(6.9509, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2654.4888, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.3989, device='cuda:0') tensor(1098.3611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.9735, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5479.6001, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9111, device='cuda:0') tensor(1258.2531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(6.9987, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1250.5726, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1174.1514, device='cuda:0') tensor(741.7726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.0278, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4212.9995, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.2964, device='cuda:0') tensor(1724.5941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(7.0610, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3453.2432, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.5544, device='cuda:0') tensor(1768.5748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.0896, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4489.5850, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.7871, device='cuda:0') tensor(2407.4507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.1215, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2715.8940, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.2129, device='cuda:0') tensor(2731.0657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.1537, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3269.7266, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.7522, device='cuda:0') tensor(2735.3804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(7.1886, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2813.1973, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.3789, device='cuda:0') tensor(3572.2505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.2236, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1241.4579, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1994.5459, device='cuda:0') tensor(1333.0056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    750 | 88.36 ms/step | loss 1333.006 \n",
      "param_tail torch.Size([4096, 8]) tensor(7.2614, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5765.3076, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.4204, device='cuda:0') tensor(2099.6426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.3013, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2483.9834, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.1250, device='cuda:0') tensor(3067.6230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(7.3418, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3511.2097, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.1604, device='cuda:0') tensor(700.3180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.3798, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5734.0757, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4341, device='cuda:0') tensor(1612.2917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.4162, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(864.9858, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.3384, device='cuda:0') tensor(9423.1865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.4555, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3371.8279, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.2737, device='cuda:0') tensor(1032.6289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(7.4876, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3751.6650, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3123.0457, device='cuda:0') tensor(1516.9172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.5113, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6482.6558, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4785, device='cuda:0') tensor(19212.0469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.5299, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2290.0264, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1994.0784, device='cuda:0') tensor(594.4294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.5498, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4129.1284, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.7258, device='cuda:0') tensor(906.8793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    760 | 74.63 ms/step | loss  906.879 \n",
      "param_tail torch.Size([3712, 8]) tensor(7.5662, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3820.9836, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.8525, device='cuda:0') tensor(1324.2463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.5748, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3489.8079, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.2139, device='cuda:0') tensor(7519.5713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.5823, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4455.0757, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.2490, device='cuda:0') tensor(1353.6609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.5826, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3486.9258, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.7754, device='cuda:0') tensor(997.2419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(7.5781, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3001.5391, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.6904, device='cuda:0') tensor(4380.4956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.5775, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5753.7393, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.7607, device='cuda:0') tensor(3731.3545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.5726, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9421.0176, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.2065, device='cuda:0') tensor(2398.3130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.5651, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2974.8760, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.6985, device='cuda:0') tensor(997.5516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(7.5553, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2377.5278, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.8618, device='cuda:0') tensor(1785.3701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.5520, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6326.8105, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9292, device='cuda:0') tensor(6604.6904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    770 | 88.23 ms/step | loss 6604.690 \n",
      "param_tail torch.Size([4096, 8]) tensor(7.5480, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(778.5305, device='cuda:0', grad_fn=<MaxBackward1>) tensor(750.1326, device='cuda:0') tensor(742.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.5518, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3058.2598, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.5703, device='cuda:0') tensor(2606.6841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(7.5631, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2788.8079, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.4089, device='cuda:0') tensor(1453.3258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.5782, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4734.4707, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.8594, device='cuda:0') tensor(3346.7927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.5966, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3156.3918, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.1328, device='cuda:0') tensor(1998.1807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.6186, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(715.8066, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1153.0483, device='cuda:0') tensor(747.9874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(7.6458, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2349.9268, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.6885, device='cuda:0') tensor(2040.2063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.6771, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5571.2876, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.0820, device='cuda:0') tensor(9160.7500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.7043, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1131.8470, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.3213, device='cuda:0') tensor(7760.2881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.7341, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2604.3159, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.5703, device='cuda:0') tensor(2277.8340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    780 | 64.60 ms/step | loss 2277.834 \n",
      "param_tail torch.Size([3712, 8]) tensor(7.7653, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3501.2783, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.7102, device='cuda:0') tensor(864.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.7888, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3654.2871, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.1318, device='cuda:0') tensor(5488.1631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.8104, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5641.7778, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9971, device='cuda:0') tensor(6994.3164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.8336, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(375.7230, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1331.4384, device='cuda:0') tensor(744.3029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(7.8614, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1919.5673, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.2021, device='cuda:0') tensor(3719.3860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.8918, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3102.7390, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.0029, device='cuda:0') tensor(1269.4584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.9271, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3854.6343, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.0156, device='cuda:0') tensor(3585.7400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(7.9628, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2287.5513, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4038.8958, device='cuda:0') tensor(10073.4102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(7.9983, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2503.8198, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2042.2135, device='cuda:0') tensor(1191.6940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.0373, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7744.5742, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.1250, device='cuda:0') tensor(1972.6409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    790 | 79.00 ms/step | loss 1972.641 \n",
      "param_tail torch.Size([4096, 8]) tensor(8.0710, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5187.0864, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.5713, device='cuda:0') tensor(1945.1819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.0983, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3942.5801, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.5847, device='cuda:0') tensor(1079.8951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(8.1167, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3047.1975, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.1184, device='cuda:0') tensor(1245.1874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.1375, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6085.0898, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.0293, device='cuda:0') tensor(3008.7922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.1613, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5326.0420, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.9197, device='cuda:0') tensor(1118.4137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.1782, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4038.5781, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.3940, device='cuda:0') tensor(8059.6611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(8.1925, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3026.6345, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.6050, device='cuda:0') tensor(1974.9308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.2111, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7783.8213, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1821, device='cuda:0') tensor(12790.6973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.2245, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1791.1404, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2608.9194, device='cuda:0') tensor(709.9207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.2410, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3937.8767, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.7588, device='cuda:0') tensor(5976.5361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    800 | 78.98 ms/step | loss 5976.536 \n",
      "param_tail torch.Size([3712, 8]) tensor(8.2512, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1651.8628, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1152.6460, device='cuda:0') tensor(736.4025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "checking 199\n",
      "(16000, 2) torch.Size([16000, 2]) 28.633303190203232 aloha\n",
      "saving iteration- 199\n",
      "param_tail torch.Size([4096, 8]) tensor(8.2566, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(697.4787, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1327.6306, device='cuda:0') tensor(806.1703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.2702, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3630.8232, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2608.4583, device='cuda:0') tensor(986.5107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.2755, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6103.8047, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.2422, device='cuda:0') tensor(2048.2583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(8.2777, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2971.5225, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.4883, device='cuda:0') tensor(6120.1460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.2860, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4920.1836, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.7446, device='cuda:0') tensor(1111.5183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.3005, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4460.9985, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.1780, device='cuda:0') tensor(733.4964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.3146, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1445.0696, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.6150, device='cuda:0') tensor(1617.2617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(8.3330, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8131.4434, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.1689, device='cuda:0') tensor(5744.7256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.3522, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4388.7637, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.8833, device='cuda:0') tensor(3493.9597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    810 | 249.59 ms/step | loss 3493.960 \n",
      "param_tail torch.Size([4096, 8]) tensor(8.3746, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3330.3115, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.0737, device='cuda:0') tensor(3629.1226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.4033, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6381.3994, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.6704, device='cuda:0') tensor(2392.3062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(8.4305, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1865.1348, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1994.4056, device='cuda:0') tensor(1886.0811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.4593, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2174.7644, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.8789, device='cuda:0') tensor(8124.3779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.4905, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3192.8271, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.6675, device='cuda:0') tensor(2006.4124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.5201, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3346.0093, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.3770, device='cuda:0') tensor(846.1161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(8.5397, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3899.2144, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.8152, device='cuda:0') tensor(1964.0706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.5615, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6188.7783, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4263, device='cuda:0') tensor(2282.1230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.5777, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4248.6411, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.3291, device='cuda:0') tensor(1132.0709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.5857, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3836.1660, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.6768, device='cuda:0') tensor(1814.6001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    820 | 64.91 ms/step | loss 1814.600 \n",
      "param_tail torch.Size([3712, 8]) tensor(8.5866, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1785.8478, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.3169, device='cuda:0') tensor(2325.4080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.5955, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2494.3569, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2612.1428, device='cuda:0') tensor(1313.0564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.6003, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4479.4551, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.7158, device='cuda:0') tensor(4667.3408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.6002, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1273.3800, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.8042, device='cuda:0') tensor(7175.4014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(8.6041, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2128.1938, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.0151, device='cuda:0') tensor(5579.6011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.6162, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2639.4744, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.1152, device='cuda:0') tensor(5978.1499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.6311, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1710.4436, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2608.5295, device='cuda:0') tensor(1491.8120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.6440, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2283.5425, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.8984, device='cuda:0') tensor(2532.0674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(8.6642, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8569.9814, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.7075, device='cuda:0') tensor(3419.3855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.6793, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2819.8521, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.4482, device='cuda:0') tensor(2073.0583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    830 | 98.30 ms/step | loss 2073.058 \n",
      "param_tail torch.Size([4096, 8]) tensor(8.6919, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5424.7002, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.8501, device='cuda:0') tensor(793.0554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.6967, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5837.6084, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9038, device='cuda:0') tensor(2210.5283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(8.6959, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1685.9324, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1328.9818, device='cuda:0') tensor(693.8935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.6939, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3881.1047, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.2209, device='cuda:0') tensor(5089.0190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.6909, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(937.7570, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1558.4583, device='cuda:0') tensor(1006.8785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.6900, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8577.7744, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.4399, device='cuda:0') tensor(3362.8174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(8.6864, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1886.7125, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1995.3762, device='cuda:0') tensor(1930.0543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.6889, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4701.6572, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4570, device='cuda:0') tensor(9042.2061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.6954, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3165.3694, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.7349, device='cuda:0') tensor(1175.3831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.7090, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(421.8453, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1329.3735, device='cuda:0') tensor(1123.9800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    840 | 75.64 ms/step | loss 1123.980 \n",
      "param_tail torch.Size([3712, 8]) tensor(8.7262, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1715.7531, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.6494, device='cuda:0') tensor(4521.9829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.7499, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4946.4043, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.3281, device='cuda:0') tensor(2115.0454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.7770, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4556.8291, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.2600, device='cuda:0') tensor(3569.5254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.8012, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1252.8694, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2258.5369, device='cuda:0') tensor(2136.7832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(8.8315, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6834.4121, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.1167, device='cuda:0') tensor(1284.1700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.8584, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2002.2640, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.4717, device='cuda:0') tensor(5644.0195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.8901, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3993.7271, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.7566, device='cuda:0') tensor(1244.3909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.9212, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3960.7832, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.8965, device='cuda:0') tensor(2494.4009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(8.9549, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1303.8674, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1174.1699, device='cuda:0') tensor(898.1582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(8.9898, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3772.9194, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.9741, device='cuda:0') tensor(5650.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    850 | 85.05 ms/step | loss 5650.716 \n",
      "param_tail torch.Size([4096, 8]) tensor(9.0268, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4011.6655, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4575, device='cuda:0') tensor(1873.9248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(9.0637, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4618.0820, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.0537, device='cuda:0') tensor(2187.3682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(9.0907, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(291.1017, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1172.8390, device='cuda:0') tensor(933.8325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(9.1240, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7377.4917, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4868.8516, device='cuda:0') tensor(1785.1707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(9.1483, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2527.5283, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.5559, device='cuda:0') tensor(1294.9426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(9.1767, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7229.5078, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.7397, device='cuda:0') tensor(1037.4430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(9.1998, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4190.0708, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.6089, device='cuda:0') tensor(11095.4316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(9.2142, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4459.8291, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.5635, device='cuda:0') tensor(2207.9795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(9.2262, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3747.5850, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.5728, device='cuda:0') tensor(2277.5818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(9.2421, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(770.0353, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.2156, device='cuda:0') tensor(1686.1868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    860 | 67.90 ms/step | loss 1686.187 \n",
      "param_tail torch.Size([3712, 8]) tensor(9.2657, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4068.8237, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.7080, device='cuda:0') tensor(2429.4209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(9.2809, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6472.2646, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.5308, device='cuda:0') tensor(9874.4141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(9.2970, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3561.0894, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.9333, device='cuda:0') tensor(1547.2419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(9.3155, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1653.6592, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2608.6584, device='cuda:0') tensor(896.4578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(9.3405, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3126.7705, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.1592, device='cuda:0') tensor(2161.5212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(9.3690, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1400.3254, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1329.4911, device='cuda:0') tensor(759.1317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(9.4037, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6679.1450, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.8535, device='cuda:0') tensor(1083.8855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(9.4403, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2880.9536, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.3713, device='cuda:0') tensor(1579.4846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(9.4809, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4132.8335, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.4985, device='cuda:0') tensor(1486.5336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(9.5226, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2505.1421, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2611.9551, device='cuda:0') tensor(1205.9211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    870 | 84.87 ms/step | loss 1205.921 \n",
      "param_tail torch.Size([4096, 8]) tensor(9.5690, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6312.6196, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.2139, device='cuda:0') tensor(1246.5994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(9.6131, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6170.9370, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.2295, device='cuda:0') tensor(1440.2102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(9.6479, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4211.6562, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.7751, device='cuda:0') tensor(1108.7362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(9.6732, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6054.7603, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.8481, device='cuda:0') tensor(2393.2798, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(9.6979, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1108.4749, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.7742, device='cuda:0') tensor(1991.0908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(9.7301, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2624.3713, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3420.4900, device='cuda:0') tensor(1514.3590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(9.7663, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4179.9438, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.4199, device='cuda:0') tensor(2177.0146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(9.8038, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(390.4933, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.2246, device='cuda:0') tensor(2118.6147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(9.8475, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2885.5251, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.2163, device='cuda:0') tensor(1247.5312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(9.8937, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8179.5791, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.2427, device='cuda:0') tensor(5622.2500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    880 | 85.54 ms/step | loss 5622.250 \n",
      "param_tail torch.Size([3712, 8]) tensor(9.9352, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2380.2336, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.4043, device='cuda:0') tensor(5498.8892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(9.9775, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6453.4512, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.8867, device='cuda:0') tensor(1238.3464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(10.0202, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2223.8657, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.2981, device='cuda:0') tensor(1605.6497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(10.0686, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4900.2007, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.2708, device='cuda:0') tensor(3469.2117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(10.1041, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6248.7227, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.9668, device='cuda:0') tensor(11440.4082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(10.1300, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2409.0862, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1558.9963, device='cuda:0') tensor(1821.6294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(10.1467, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2143.3442, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.7275, device='cuda:0') tensor(9536.9248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(10.1697, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4682.0728, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.8462, device='cuda:0') tensor(4945.3789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(10.1821, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4660.2246, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.9348, device='cuda:0') tensor(2764.5632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(10.1902, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2385.9829, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3122.2769, device='cuda:0') tensor(932.9407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    890 | 65.72 ms/step | loss  932.941 \n",
      "param_tail torch.Size([4096, 8]) tensor(10.2035, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4362.9272, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.6826, device='cuda:0') tensor(4394.3320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(10.2146, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7007.6802, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.0635, device='cuda:0') tensor(991.7574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(10.2206, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1162.9387, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2258.0254, device='cuda:0') tensor(2519.1067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(10.2358, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3583.0930, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.2007, device='cuda:0') tensor(1103.1616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(10.2473, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4516.8042, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.3682, device='cuda:0') tensor(2269.3484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(10.2640, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2819.3704, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.7310, device='cuda:0') tensor(4378.3223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(10.2861, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1180.7062, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2260.6853, device='cuda:0') tensor(1959.8547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(10.3149, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4594.0537, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.6680, device='cuda:0') tensor(2225.9976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(10.3457, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7007.3252, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.5449, device='cuda:0') tensor(1364.6019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(10.3669, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1194.9116, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.6404, device='cuda:0') tensor(2387.1736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    900 | 86.92 ms/step | loss 2387.174 \n",
      "param_tail torch.Size([3712, 8]) tensor(10.3946, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1461.8135, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.8364, device='cuda:0') tensor(9232.0068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(10.4277, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4059.6646, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.0718, device='cuda:0') tensor(1279.1553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(10.4621, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1718.0083, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1995.9459, device='cuda:0') tensor(1241.1335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(10.5002, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7383.0693, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.5054, device='cuda:0') tensor(969.6539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(10.5337, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5631.9648, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.5923, device='cuda:0') tensor(1528.3994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(10.5648, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3945.6011, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.4216, device='cuda:0') tensor(948.5663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(10.5962, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1109.3289, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1128.8712, device='cuda:0') tensor(1691.6018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(10.6343, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2925.0859, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.5667, device='cuda:0') tensor(843.8635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(10.6763, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4581.9590, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.0786, device='cuda:0') tensor(6204.0366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(10.7219, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7781.6108, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.5132, device='cuda:0') tensor(1168.9280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    910 | 82.86 ms/step | loss 1168.928 \n",
      "param_tail torch.Size([4096, 8]) tensor(10.7605, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3206.0110, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2608.9871, device='cuda:0') tensor(906.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(10.7949, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1779.9209, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.6182, device='cuda:0') tensor(2368.7112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(10.8307, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3412.9709, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.8911, device='cuda:0') tensor(1939.9038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(10.8656, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1063.4847, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1995.0083, device='cuda:0') tensor(1324.5112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(10.9071, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3056.7280, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.1831, device='cuda:0') tensor(1603.5415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(10.9482, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3011.5071, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.5151, device='cuda:0') tensor(3268.3228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(10.9954, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9546.2441, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.9097, device='cuda:0') tensor(2927.2991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.0331, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(625.2549, device='cuda:0', grad_fn=<MaxBackward1>) tensor(752.1237, device='cuda:0') tensor(833.8320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.0731, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5864.7993, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.4385, device='cuda:0') tensor(10533.9258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.1063, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9787.2480, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.6523, device='cuda:0') tensor(7066.9229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    920 | 69.45 ms/step | loss 7066.923 \n",
      "param_tail torch.Size([3712, 8]) tensor(11.1306, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(829.2203, device='cuda:0', grad_fn=<MaxBackward1>) tensor(947.5392, device='cuda:0') tensor(602.0165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.1608, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6614.8438, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.0308, device='cuda:0') tensor(3200.8613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.1833, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3921.0647, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.2568, device='cuda:0') tensor(2287.3936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.1982, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3886.1191, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.8677, device='cuda:0') tensor(2097.8301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(11.2106, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2225.0540, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.4331, device='cuda:0') tensor(795.3602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.2322, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4049.2117, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.2310, device='cuda:0') tensor(1589.0908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.2556, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4798.0918, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.1484, device='cuda:0') tensor(1221.6527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.2782, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2438.5469, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.4370, device='cuda:0') tensor(6934.1484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(11.3076, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2524.0952, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.2966, device='cuda:0') tensor(1544.5659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.3324, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2712.9116, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.4585, device='cuda:0') tensor(1105.9653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    930 | 82.94 ms/step | loss 1105.965 \n",
      "param_tail torch.Size([4096, 8]) tensor(11.3552, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2765.9941, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6064, device='cuda:0') tensor(6509.2515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.3854, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2893.3752, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2611.7964, device='cuda:0') tensor(2772.5981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(11.4212, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(942.6150, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.2827, device='cuda:0') tensor(1403.8885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.4642, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2338.7471, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2042.6019, device='cuda:0') tensor(717.4752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.4979, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4320.4946, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.1782, device='cuda:0') tensor(1958.8319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.5334, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6039.4404, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.9043, device='cuda:0') tensor(2273.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(11.5700, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3893.9790, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.8674, device='cuda:0') tensor(1423.1063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.6071, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7825.6353, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4497, device='cuda:0') tensor(5260.6436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.6344, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2172.5918, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.2114, device='cuda:0') tensor(995.5585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.6698, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1834.1450, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1994.7732, device='cuda:0') tensor(901.4299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    940 | 87.48 ms/step | loss  901.430 \n",
      "param_tail torch.Size([3712, 8]) tensor(11.6977, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3845.3918, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.8230, device='cuda:0') tensor(1593.3909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.7270, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7880.5981, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.7397, device='cuda:0') tensor(1452.1763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.7506, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4179.0591, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4874.0752, device='cuda:0') tensor(3680.1609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.7669, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5001.4873, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.2217, device='cuda:0') tensor(1115.9642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(11.7787, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1247.6421, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1328.6310, device='cuda:0') tensor(678.7427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.7995, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4780.3882, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.1655, device='cuda:0') tensor(2566.1855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.8152, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7629.9438, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.2632, device='cuda:0') tensor(1311.1165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.8261, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3451.2996, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.0308, device='cuda:0') tensor(1213.0670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(11.8424, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4319.4121, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.1384, device='cuda:0') tensor(952.4855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.8566, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6511.5205, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.9746, device='cuda:0') tensor(872.4523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    950 | 72.40 ms/step | loss  872.452 \n",
      "param_tail torch.Size([4096, 8]) tensor(11.8705, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1173.9042, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1171.9498, device='cuda:0') tensor(906.2003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.8945, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3914.8237, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.8264, device='cuda:0') tensor(3153.8486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(11.9221, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5689.4600, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.2168, device='cuda:0') tensor(847.9098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.9441, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3949.6555, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.4980, device='cuda:0') tensor(3100.4961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.9700, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3596.2273, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.6997, device='cuda:0') tensor(1369.4487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(11.9904, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7364.8398, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.8789, device='cuda:0') tensor(2045.5173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(12.0012, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4226.6689, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.8652, device='cuda:0') tensor(2358.7134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.0047, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3689.6343, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.9009, device='cuda:0') tensor(8173.5508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.0182, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2649.0183, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.9785, device='cuda:0') tensor(3458.8386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.0362, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2555.8733, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.5391, device='cuda:0') tensor(1712.8451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    960 | 94.48 ms/step | loss 1712.845 \n",
      "param_tail torch.Size([3712, 8]) tensor(12.0606, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3592.9954, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.9409, device='cuda:0') tensor(986.3673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.0950, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2008.7319, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2040.0426, device='cuda:0') tensor(1054.9783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.1369, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5468.4644, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.8560, device='cuda:0') tensor(1351.3198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.1666, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2785.7363, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.0308, device='cuda:0') tensor(830.0806, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(12.2042, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6341.4023, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.5801, device='cuda:0') tensor(3469.8389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.2404, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4148.4385, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9170, device='cuda:0') tensor(7261.0215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.2795, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(722.4919, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1174.0867, device='cuda:0') tensor(788.3805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.3264, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3388.3804, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.9160, device='cuda:0') tensor(1369.6113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(12.3626, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3048.6255, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.4214, device='cuda:0') tensor(2327.3093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.4018, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4005.6008, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.9072, device='cuda:0') tensor(6402.0503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    970 | 92.08 ms/step | loss 6402.050 \n",
      "param_tail torch.Size([4096, 8]) tensor(12.4305, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7897.7676, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.8896, device='cuda:0') tensor(4771.6431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.4558, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1465.6719, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1327.4056, device='cuda:0') tensor(762.2335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(12.4908, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3991.8755, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.8513, device='cuda:0') tensor(1257.9594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.5144, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(819.2517, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.0898, device='cuda:0') tensor(10235.8887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.5454, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5294.4058, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.7712, device='cuda:0') tensor(3445.9165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.5698, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4709.4712, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.0176, device='cuda:0') tensor(7169.6719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(12.5909, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1170.2367, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1994.7961, device='cuda:0') tensor(1119.2629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.6201, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4559.8682, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.9290, device='cuda:0') tensor(2188.5588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.6511, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7262.0122, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.2861, device='cuda:0') tensor(1721.8611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.6715, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4247.9829, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.5493, device='cuda:0') tensor(2266.3276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    980 | 66.56 ms/step | loss 2266.328 \n",
      "param_tail torch.Size([3712, 8]) tensor(12.6949, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4125.1704, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4043.1370, device='cuda:0') tensor(671., device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.7216, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1782.3257, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.8555, device='cuda:0') tensor(6162.0298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.7530, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3879.2048, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.4863, device='cuda:0') tensor(9097.6699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.7893, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5975.2432, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4874.9102, device='cuda:0') tensor(1049.1016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(12.8147, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3929.3679, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.1426, device='cuda:0') tensor(2399.6802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.8307, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9284.3076, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.7427, device='cuda:0') tensor(3028.2776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.8395, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2660.7537, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.9802, device='cuda:0') tensor(3215.8965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.8521, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(982.0558, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2042.7723, device='cuda:0') tensor(906.0786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(12.8753, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1471.4141, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.3413, device='cuda:0') tensor(8467.7568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.9051, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4058.7344, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.2151, device='cuda:0') tensor(1285.8264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter    990 | 95.15 ms/step | loss 1285.826 \n",
      "param_tail torch.Size([4096, 8]) tensor(12.9244, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2372.6958, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2255.7327, device='cuda:0') tensor(935.3849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.9473, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7230.8682, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.3613, device='cuda:0') tensor(1169.6460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(12.9637, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4204.5522, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.4844, device='cuda:0') tensor(1599.6625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(12.9891, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(345.3069, device='cuda:0', grad_fn=<MaxBackward1>) tensor(924.2445, device='cuda:0') tensor(823.1276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(13.0238, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2762.3979, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3420.8298, device='cuda:0') tensor(1351.7971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(13.0637, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6935.7026, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.4971, device='cuda:0') tensor(2551.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(13.0999, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1866.7828, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.0935, device='cuda:0') tensor(8053.4521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(13.1388, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3071.3213, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.2468, device='cuda:0') tensor(1769.5847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(13.1709, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5464.8486, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1616, device='cuda:0') tensor(8813.7500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(13.1919, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1869.4583, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.0574, device='cuda:0') tensor(852.6515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1000 | 74.20 ms/step | loss  852.651 \n",
      "param_tail torch.Size([3712, 8]) tensor(13.2226, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3288.5806, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.6519, device='cuda:0') tensor(2226.8906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "checking 249\n",
      "(16000, 2) torch.Size([16000, 2]) 28.95562213380106 aloha\n",
      "param_tail torch.Size([4096, 8]) tensor(13.2593, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4537.7163, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.7300, device='cuda:0') tensor(9708.5830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(13.3030, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1796.5374, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2608.4341, device='cuda:0') tensor(1612.8352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(13.3547, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3767.6938, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.5796, device='cuda:0') tensor(877.2073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(13.3989, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3799.0618, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.4739, device='cuda:0') tensor(1961.4501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(13.4352, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4776.1523, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.5566, device='cuda:0') tensor(4425.4976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(13.4666, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1263.3826, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1154.0391, device='cuda:0') tensor(829.0057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(13.5030, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2293.3105, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.1138, device='cuda:0') tensor(1490.4175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(13.5472, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4165.8828, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.8933, device='cuda:0') tensor(1034.9236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(13.5852, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2342.5410, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.8804, device='cuda:0') tensor(2245.4607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1010 | 267.75 ms/step | loss 2245.461 \n",
      "param_tail torch.Size([4096, 8]) tensor(13.6305, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1032.0034, device='cuda:0', grad_fn=<MaxBackward1>) tensor(699.0568, device='cuda:0') tensor(657.1831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(13.6836, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6460.8682, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.5581, device='cuda:0') tensor(1405.4038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(13.7401, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3931.5955, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.8530, device='cuda:0') tensor(13994.0283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(13.8003, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2860.8049, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.6348, device='cuda:0') tensor(1434.1501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(13.8659, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3935.2029, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.4695, device='cuda:0') tensor(4666.3677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(13.9290, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7750.7832, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.2246, device='cuda:0') tensor(1559.2122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(13.9818, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3552.4639, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.8030, device='cuda:0') tensor(718.2372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(14.0219, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7726.4717, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.8198, device='cuda:0') tensor(1265.7539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(14.0534, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1894.3477, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1994.3186, device='cuda:0') tensor(1123.2382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(14.0829, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6340.4502, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.3218, device='cuda:0') tensor(2041.3724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1020 | 68.15 ms/step | loss 2041.372 \n",
      "param_tail torch.Size([3712, 8]) tensor(14.1039, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4333.2144, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3415.8933, device='cuda:0') tensor(1151.8763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(14.1137, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6864.5903, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.1831, device='cuda:0') tensor(2156.2456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(14.1144, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2939.1963, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.6775, device='cuda:0') tensor(981.6321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(14.1249, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1637.5452, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1557.8734, device='cuda:0') tensor(949.0513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(14.1441, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6384.6621, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9624, device='cuda:0') tensor(4854.5952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(14.1694, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5143.3198, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.5615, device='cuda:0') tensor(2804.6431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(14.1917, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5708.3862, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.2861, device='cuda:0') tensor(1129.6255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(14.2106, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3154.0266, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.3813, device='cuda:0') tensor(790.5356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(14.2341, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1602.4274, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1993.4835, device='cuda:0') tensor(724.6093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(14.2634, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(958.6386, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1558.0447, device='cuda:0') tensor(989.9797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1030 | 89.03 ms/step | loss  989.980 \n",
      "param_tail torch.Size([4096, 8]) tensor(14.3009, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3349.2178, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.1633, device='cuda:0') tensor(2092.9194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(14.3447, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3241.6013, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6138, device='cuda:0') tensor(4794.1660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(14.3920, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3704.3394, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.0239, device='cuda:0') tensor(1163.4624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(14.4452, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2417.7070, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.8137, device='cuda:0') tensor(1623.4023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(14.5002, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7819.2065, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.6274, device='cuda:0') tensor(2618.2283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(14.5451, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4544.8325, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.0337, device='cuda:0') tensor(3202.5728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(14.5819, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4762.9048, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.6226, device='cuda:0') tensor(1530.4934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(14.6242, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2526.4285, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.7175, device='cuda:0') tensor(852.0701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(14.6603, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(236.4316, device='cuda:0', grad_fn=<MaxBackward1>) tensor(566.5850, device='cuda:0') tensor(641.6759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(14.7065, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4267.4028, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.1621, device='cuda:0') tensor(1489.0189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1040 | 92.17 ms/step | loss 1489.019 \n",
      "param_tail torch.Size([3712, 8]) tensor(14.7436, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4238.8408, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.0044, device='cuda:0') tensor(4294.9390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(14.7875, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4072.2954, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.3706, device='cuda:0') tensor(6872.7080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(14.8323, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1790.6840, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.6846, device='cuda:0') tensor(7153.3447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(14.8788, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1600.5189, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1557.9026, device='cuda:0') tensor(1559.8767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(14.9312, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1243.3009, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3117.1414, device='cuda:0') tensor(2342.1340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(14.9924, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(567.7812, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1154.5935, device='cuda:0') tensor(863.5851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(15.0593, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2248.2493, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1994.6118, device='cuda:0') tensor(1182.8707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(15.1277, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7746.5430, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.8623, device='cuda:0') tensor(4325.5708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(15.1922, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4800.4487, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4869.2939, device='cuda:0') tensor(9486.9512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(15.2420, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2247.7424, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.1122, device='cuda:0') tensor(768.0777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1050 | 76.21 ms/step | loss  768.078 \n",
      "param_tail torch.Size([4096, 8]) tensor(15.2813, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6305.9507, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.2021, device='cuda:0') tensor(1495.8003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(15.3196, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2899.2817, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.8376, device='cuda:0') tensor(6520.2480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(15.3650, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2706.9353, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.2261, device='cuda:0') tensor(4230.2744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(15.4200, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7916.7114, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9243, device='cuda:0') tensor(2527.0361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(15.4647, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4088.2471, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.0027, device='cuda:0') tensor(805.2563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(15.4951, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1735.8923, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.0547, device='cuda:0') tensor(2778.2161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(15.5347, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1505.4437, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1996.9525, device='cuda:0') tensor(893.9062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(15.5818, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3879.7349, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.2234, device='cuda:0') tensor(1136.1094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(15.6269, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4186.1030, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.1289, device='cuda:0') tensor(1832.3435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(15.6633, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5603.2036, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.9434, device='cuda:0') tensor(1201.6627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1060 | 97.11 ms/step | loss 1201.663 \n",
      "param_tail torch.Size([3712, 8]) tensor(15.7025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2139.1250, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.5090, device='cuda:0') tensor(4016.7495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(15.7469, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1294.1608, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.8092, device='cuda:0') tensor(823.1122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(15.8009, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3641.8748, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9258, device='cuda:0') tensor(3142.2097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(15.8610, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3854.6958, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.1023, device='cuda:0') tensor(3850.6960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(15.9132, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2240.2815, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.2568, device='cuda:0') tensor(2469.3782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(15.9739, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2829.2515, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.5388, device='cuda:0') tensor(1511.8838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.0399, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1323.8949, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.4233, device='cuda:0') tensor(14854.7314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.1090, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3382.9749, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.5496, device='cuda:0') tensor(1169.8678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(16.1657, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2740.0168, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9155, device='cuda:0') tensor(7614.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.2261, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4214.8184, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.4863, device='cuda:0') tensor(6875.3003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1070 | 93.71 ms/step | loss 6875.300 \n",
      "param_tail torch.Size([4096, 8]) tensor(16.2818, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1957.2887, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2040.2386, device='cuda:0') tensor(1646.9736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.3350, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3539.0261, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.9651, device='cuda:0') tensor(960.0771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(16.3881, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7677.6777, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.7739, device='cuda:0') tensor(3548.0791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.4301, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4060.7886, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.4331, device='cuda:0') tensor(4013.4922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.4589, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(711.1736, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.0566, device='cuda:0') tensor(2571.5449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.4998, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1806.1277, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.0012, device='cuda:0') tensor(1676.3440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(16.5505, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4685.1216, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.5811, device='cuda:0') tensor(3552.0828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.5951, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3734.9316, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.8853, device='cuda:0') tensor(2756.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.6264, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5573.0601, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.9048, device='cuda:0') tensor(1806.9169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.6607, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5170.5903, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.4512, device='cuda:0') tensor(1670.9189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1080 | 72.57 ms/step | loss 1670.919 \n",
      "param_tail torch.Size([3712, 8]) tensor(16.7013, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2340.3538, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2042.1102, device='cuda:0') tensor(738.4263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.7447, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3300.3530, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.2625, device='cuda:0') tensor(857.8967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.7740, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1532.3885, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.0989, device='cuda:0') tensor(3224.6768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.8112, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7170.5679, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.8833, device='cuda:0') tensor(10999.6211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(16.8347, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7570.5957, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.8042, device='cuda:0') tensor(1467.2992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.8499, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2398.3330, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.2612, device='cuda:0') tensor(4612.3096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.8728, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3112.5120, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.6072, device='cuda:0') tensor(1370.5828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.8882, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5184.8672, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.7417, device='cuda:0') tensor(6068.0874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(16.8976, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3938.0129, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.9382, device='cuda:0') tensor(2113.5513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.8968, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3934.9614, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3415.9983, device='cuda:0') tensor(3167.0391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1090 | 93.68 ms/step | loss 3167.039 \n",
      "param_tail torch.Size([4096, 8]) tensor(16.8870, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5353.2788, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.2502, device='cuda:0') tensor(2944.3604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.8733, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2186.0486, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.6290, device='cuda:0') tensor(1191.5587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(16.8645, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7875.4741, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9336, device='cuda:0') tensor(3025.4387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.8511, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3864.7046, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.3936, device='cuda:0') tensor(7711.9526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.8518, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1263.9922, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.7012, device='cuda:0') tensor(4808.9580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.8590, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5504.0483, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.2227, device='cuda:0') tensor(4025.1436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(16.8735, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(482.3635, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.9602, device='cuda:0') tensor(2346.5227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.9006, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3760.2971, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.0503, device='cuda:0') tensor(2018.2251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.9327, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2606.5906, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.0435, device='cuda:0') tensor(12318.9463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.9529, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3622.7300, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.7222, device='cuda:0') tensor(4717.1753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1100 | 88.27 ms/step | loss 4717.175 \n",
      "param_tail torch.Size([3712, 8]) tensor(16.9737, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6017.0513, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.9189, device='cuda:0') tensor(955.4231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.9858, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3691.8921, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2611.4624, device='cuda:0') tensor(1063.6348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.9849, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6502.0220, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.8413, device='cuda:0') tensor(7712.5742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.9735, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5515.6499, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6209.4951, device='cuda:0') tensor(821.4624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(16.9707, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4136.1362, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.0320, device='cuda:0') tensor(1701.1903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.9592, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1630.8394, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.7263, device='cuda:0') tensor(8427.7188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.9599, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2843.2991, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6519, device='cuda:0') tensor(4532.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(16.9715, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3171.9878, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.0125, device='cuda:0') tensor(2537.3203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(16.9855, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1087.0206, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.7036, device='cuda:0') tensor(1288.2939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(17.0127, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7359.3472, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.5991, device='cuda:0') tensor(2388.3525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1110 | 66.87 ms/step | loss 2388.353 \n",
      "param_tail torch.Size([4096, 8]) tensor(17.0249, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2446.0400, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2040.5028, device='cuda:0') tensor(711.2135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(17.0348, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4070.7905, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.6538, device='cuda:0') tensor(10327.9668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(17.0547, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2455.6326, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.4360, device='cuda:0') tensor(5447.9346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(17.0815, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1102.1777, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1172.6947, device='cuda:0') tensor(733.7103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(17.1158, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5770.5684, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6987, device='cuda:0') tensor(2146.3276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(17.1594, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3058.1699, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.8521, device='cuda:0') tensor(1245.0360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(17.1891, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2064.6106, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2608.8391, device='cuda:0') tensor(2097.7954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(17.2309, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(10243.2305, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.1982, device='cuda:0') tensor(4721.4746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(17.2631, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2967.4998, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2611.9985, device='cuda:0') tensor(1647.1627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(17.2843, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5038.4941, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.8926, device='cuda:0') tensor(805.6705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1120 | 84.83 ms/step | loss  805.671 \n",
      "param_tail torch.Size([3712, 8]) tensor(17.2942, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4868.8931, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.0635, device='cuda:0') tensor(5546.0439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(17.2934, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1821.9471, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2608.7910, device='cuda:0') tensor(1159.4513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(17.3003, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9470.5215, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.9551, device='cuda:0') tensor(4177.2432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(17.2990, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3171.4854, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.2959, device='cuda:0') tensor(5257.2886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(17.3093, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1827.1259, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.6138, device='cuda:0') tensor(871.8963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(17.3307, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1331.1001, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4044.0220, device='cuda:0') tensor(4868.7983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(17.3575, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2502.9438, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.0957, device='cuda:0') tensor(4806.5112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(17.3965, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6943.9517, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.0527, device='cuda:0') tensor(8788.0674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(17.4314, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1179.0425, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.0835, device='cuda:0') tensor(1035.6312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(17.4766, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(780.1531, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.1582, device='cuda:0') tensor(7314.5234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1130 | 67.02 ms/step | loss 7314.523 \n",
      "param_tail torch.Size([4096, 8]) tensor(17.5284, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3377.1475, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.2510, device='cuda:0') tensor(1310.2794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(17.5709, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4218.7339, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.3833, device='cuda:0') tensor(1925.0872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(17.6049, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1586.6587, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2611.0825, device='cuda:0') tensor(2685.1809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(17.6486, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4134.2939, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.6245, device='cuda:0') tensor(1915.3683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(17.6960, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4805.6396, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.3140, device='cuda:0') tensor(5137.5044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(17.7476, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3064.5996, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.6099, device='cuda:0') tensor(950.6279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(17.7970, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2681.1592, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.4905, device='cuda:0') tensor(10687.4824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(17.8428, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7312.2329, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.8047, device='cuda:0') tensor(2082.1685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(17.8747, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(806.1042, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.2710, device='cuda:0') tensor(2269.0759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(17.9193, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1864.5190, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4038.2969, device='cuda:0') tensor(4410.7554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1140 | 88.69 ms/step | loss 4410.755 \n",
      "param_tail torch.Size([3712, 8]) tensor(17.9677, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4413.6685, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.8196, device='cuda:0') tensor(1179.3795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(18.0143, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3891.4263, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.8247, device='cuda:0') tensor(3928.2886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(18.0613, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1821.7811, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.7036, device='cuda:0') tensor(1405.7769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(18.1169, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2325.6028, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.9690, device='cuda:0') tensor(5886.5190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(18.1783, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6912.4551, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.0684, device='cuda:0') tensor(1123.9204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(18.2388, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3995.5115, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.0200, device='cuda:0') tensor(2481.0981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(18.2972, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1881.0803, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.3083, device='cuda:0') tensor(862.0051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(18.3589, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4400.6655, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.9565, device='cuda:0') tensor(1155.2250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(18.4284, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3155.4697, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.3423, device='cuda:0') tensor(3440.1072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(18.5017, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1731.4695, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2255.9900, device='cuda:0') tensor(1458.6887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1150 | 89.33 ms/step | loss 1458.689 \n",
      "param_tail torch.Size([4096, 8]) tensor(18.5845, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5228.9858, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.1777, device='cuda:0') tensor(2912.3110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(18.6568, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8889.0840, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.8281, device='cuda:0') tensor(2224.6765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(18.7123, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1229.6809, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1155.8315, device='cuda:0') tensor(721.6914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(18.7771, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4746.1592, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.9307, device='cuda:0') tensor(4914.7729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(18.8243, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7917.2139, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.6997, device='cuda:0') tensor(1488.0798, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(18.8616, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(927.5731, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1153.1058, device='cuda:0') tensor(807.2326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(18.9079, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1442.9092, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1995.4528, device='cuda:0') tensor(1374.5959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(18.9613, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1751.9756, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.3120, device='cuda:0') tensor(902.2328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(19.0248, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5240.1348, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.6519, device='cuda:0') tensor(1218.7300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(19.0895, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8303.6123, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.2632, device='cuda:0') tensor(5901.3145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1160 | 75.33 ms/step | loss 5901.314 \n",
      "param_tail torch.Size([3712, 8]) tensor(19.1335, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4714.5259, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.8877, device='cuda:0') tensor(1053.5438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(19.1620, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4764.9370, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.0786, device='cuda:0') tensor(4335.7725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(19.1939, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5650.8262, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.2183, device='cuda:0') tensor(1083.7251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(19.2280, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1239.6089, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2040.4398, device='cuda:0') tensor(894.6970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(19.2755, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4334.1157, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.9690, device='cuda:0') tensor(1332.3389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(19.3060, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3950.0828, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.5054, device='cuda:0') tensor(11307.0234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(19.3291, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(391.5204, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1174.0725, device='cuda:0') tensor(936.8693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(19.3675, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(839.2241, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1330.0568, device='cuda:0') tensor(1073.3588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(19.4190, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3588.1809, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.4688, device='cuda:0') tensor(9134.8740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(19.4794, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2239.9336, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.2756, device='cuda:0') tensor(3824.2427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1170 | 101.07 ms/step | loss 3824.243 \n",
      "param_tail torch.Size([4096, 8]) tensor(19.5434, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6545.5396, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6616, device='cuda:0') tensor(2896.7036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(19.6086, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2385.1243, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.4407, device='cuda:0') tensor(2112.3938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(19.6792, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1807.1873, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1992.6504, device='cuda:0') tensor(960.0687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(19.7598, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6890.2183, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.7480, device='cuda:0') tensor(3212.7766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(19.8400, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(712.1032, device='cuda:0', grad_fn=<MaxBackward1>) tensor(924.1281, device='cuda:0') tensor(904.0839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(19.9303, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3729.5601, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.2478, device='cuda:0') tensor(1310.6924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(20.0020, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1839.7942, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2042.6500, device='cuda:0') tensor(1047.8694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(20.0784, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2913.1013, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3118.5654, device='cuda:0') tensor(1067.6421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(20.1629, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3608.6621, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.7932, device='cuda:0') tensor(1003.2296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(20.2553, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4501.5391, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.9668, device='cuda:0') tensor(7925.3594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1180 | 113.03 ms/step | loss 7925.359 \n",
      "param_tail torch.Size([3712, 8]) tensor(20.3449, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9258.4893, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.3394, device='cuda:0') tensor(3090.5046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(20.4173, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2696.5337, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.5615, device='cuda:0') tensor(8638.3154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(20.4946, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2019.2988, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.5767, device='cuda:0') tensor(5681.4927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(20.5787, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4214.0303, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.6870, device='cuda:0') tensor(2871.2446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(20.6586, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3583.7632, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2039.9756, device='cuda:0') tensor(1143.7615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(20.7204, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1576.4679, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1328.7838, device='cuda:0') tensor(1179.9795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(20.7703, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7220.5811, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9106, device='cuda:0') tensor(2889.2627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(20.8119, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5618.4219, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.2307, device='cuda:0') tensor(3809.7036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(20.8356, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8154.2485, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.4917, device='cuda:0') tensor(2655.1465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(20.8447, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2176.4929, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.7975, device='cuda:0') tensor(1081.3986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1190 | 74.95 ms/step | loss 1081.399 \n",
      "param_tail torch.Size([4096, 8]) tensor(20.8688, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6841.0737, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.4487, device='cuda:0') tensor(1435.8699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(20.8788, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2625.2861, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.6240, device='cuda:0') tensor(2431.3008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(20.9009, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2111.8369, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.4370, device='cuda:0') tensor(3003.2473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(20.9370, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1044.9364, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2255.5996, device='cuda:0') tensor(2684.5586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(20.9753, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4735.6055, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.1299, device='cuda:0') tensor(1239.1829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(21.0257, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4287.9194, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.0581, device='cuda:0') tensor(5706.4141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(21.0661, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3238.9441, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.0811, device='cuda:0') tensor(3873.4644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(21.1142, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2421.8206, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.0239, device='cuda:0') tensor(1749.5330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(21.1696, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2985.2129, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.5037, device='cuda:0') tensor(4010.0425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(21.2305, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8412.2744, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.8433, device='cuda:0') tensor(2548.2236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1200 | 82.67 ms/step | loss 2548.224 \n",
      "param_tail torch.Size([3712, 8]) tensor(21.2793, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2271.1101, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.8069, device='cuda:0') tensor(6287.6182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "checking 299\n",
      "(16000, 2) torch.Size([16000, 2]) 29.100582326470622 aloha\n",
      "param_tail torch.Size([4096, 8]) tensor(21.3316, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2128.3042, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.7188, device='cuda:0') tensor(2732.4700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(21.3947, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2506.8423, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.4614, device='cuda:0') tensor(794.2248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(21.4688, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(10976.1328, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.4214, device='cuda:0') tensor(8474.1465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(21.5295, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1968.2007, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.8209, device='cuda:0') tensor(923.0634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(21.6039, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4179.4307, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.9658, device='cuda:0') tensor(1377.3673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(21.6881, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9898.0127, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.1328, device='cuda:0') tensor(2448.7478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(21.7556, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3271.2178, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.5061, device='cuda:0') tensor(4264.8022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(21.8274, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5179.8086, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.4241, device='cuda:0') tensor(1605.8558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(21.8915, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4606.6289, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.9517, device='cuda:0') tensor(2410.8206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1210 | 232.59 ms/step | loss 2410.821 \n",
      "param_tail torch.Size([4096, 8]) tensor(21.9567, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6713.3096, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.1313, device='cuda:0') tensor(1347.4536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(22.0036, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3947.9656, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.6394, device='cuda:0') tensor(1980.9976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(22.0329, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3224.3845, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.0898, device='cuda:0') tensor(1009.2419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(22.0513, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8621.9521, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4875.1240, device='cuda:0') tensor(3350.3594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(22.0567, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1563.7150, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.0005, device='cuda:0') tensor(1054.9531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(22.0779, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5383.7588, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.8223, device='cuda:0') tensor(2099.4136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(22.0969, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2596.1277, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.5522, device='cuda:0') tensor(1289.4827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(22.1233, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6391.6040, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.0933, device='cuda:0') tensor(4826.4858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(22.1371, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2379.5527, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.7000, device='cuda:0') tensor(1157.4900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(22.1601, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3494.4216, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.2075, device='cuda:0') tensor(1176.0801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1220 | 80.89 ms/step | loss 1176.080 \n",
      "param_tail torch.Size([3712, 8]) tensor(22.1673, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2104.1411, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.9565, device='cuda:0') tensor(852.9631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(22.1892, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(351.0686, device='cuda:0', grad_fn=<MaxBackward1>) tensor(944.9490, device='cuda:0') tensor(891.0071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(22.2246, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3916.1753, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.7861, device='cuda:0') tensor(6138.2314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(22.2700, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4163.8975, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.1401, device='cuda:0') tensor(1826.2557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(22.3232, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1683.9423, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.4221, device='cuda:0') tensor(5692.9136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(22.3846, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4832.9019, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6680, device='cuda:0') tensor(1666.1852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(22.4506, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4324.7197, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4874.4565, device='cuda:0') tensor(6632.1152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(22.5187, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3126.7227, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.7676, device='cuda:0') tensor(1200.5618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(22.5707, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1648.5803, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.9504, device='cuda:0') tensor(1682.9270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(22.6352, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3412.4883, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.0181, device='cuda:0') tensor(11693.2227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1230 | 81.60 ms/step | loss 11693.223 \n",
      "param_tail torch.Size([4096, 8]) tensor(22.6954, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4652.5225, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.6895, device='cuda:0') tensor(1094.2979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(22.7677, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1585.5217, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.6936, device='cuda:0') tensor(2347.7773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(22.8521, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8876.1191, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1494, device='cuda:0') tensor(10928.4932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(22.9172, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1816.9979, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1555.9832, device='cuda:0') tensor(962.7093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(22.9871, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2429.2085, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2612.5732, device='cuda:0') tensor(1088.8115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(23.0668, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(10485.5410, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.0537, device='cuda:0') tensor(6896.2163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(23.1291, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7926.9551, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9810, device='cuda:0') tensor(3833.9351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(23.1834, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2164.3206, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.3108, device='cuda:0') tensor(865.9667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(23.2491, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3257.4363, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2260.3591, device='cuda:0') tensor(944.7208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(23.2943, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7021.5767, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.0151, device='cuda:0') tensor(2471.5239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1240 | 64.92 ms/step | loss 2471.524 \n",
      "param_tail torch.Size([3712, 8]) tensor(23.3328, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3911.9680, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.1489, device='cuda:0') tensor(3215.6626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(23.3620, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5869.9502, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.2002, device='cuda:0') tensor(1209.9958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(23.3765, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4155.5396, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.4529, device='cuda:0') tensor(943.9096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(23.3752, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3498.0505, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.0044, device='cuda:0') tensor(1577.3105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(23.3657, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4117.6206, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.3120, device='cuda:0') tensor(1843.1638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(23.3669, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1028.7219, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2040.9496, device='cuda:0') tensor(1780.6128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(23.3864, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4385.6411, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.9062, device='cuda:0') tensor(2957.8596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(23.4116, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1861.7578, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.7881, device='cuda:0') tensor(4767.3218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(23.4411, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(803.3663, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.7715, device='cuda:0') tensor(17944.1973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(23.4786, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2963.2256, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.8555, device='cuda:0') tensor(1350.0190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1250 | 81.49 ms/step | loss 1350.019 \n",
      "param_tail torch.Size([4096, 8]) tensor(23.5045, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5465.6943, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.0332, device='cuda:0') tensor(1214.2969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(23.5430, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3815.4331, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.2905, device='cuda:0') tensor(4105.4858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(23.5935, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(731.7107, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.9800, device='cuda:0') tensor(11255.8213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(23.6566, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2501.5857, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.6956, device='cuda:0') tensor(3036.4229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(23.7266, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9652.1689, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.4458, device='cuda:0') tensor(4616.4844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(23.7795, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3744.6936, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.4351, device='cuda:0') tensor(1020.5444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(23.8401, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2624.0872, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.2256, device='cuda:0') tensor(2828.3506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(23.9102, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1230.1370, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.0469, device='cuda:0') tensor(3359.4778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(23.9700, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3103.9902, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1958, device='cuda:0') tensor(6546.8540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.0337, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3759.7151, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.6411, device='cuda:0') tensor(7233.6206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1260 | 81.53 ms/step | loss 7233.621 \n",
      "param_tail torch.Size([3712, 8]) tensor(24.1057, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2028.8015, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3419.2161, device='cuda:0') tensor(2468.5625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.1849, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2107.2012, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.7244, device='cuda:0') tensor(1629.9890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.2664, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4399.2510, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.9968, device='cuda:0') tensor(1333.1705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.3243, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4866.2070, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.2681, device='cuda:0') tensor(5060.1963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(24.3685, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4333.4399, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.9678, device='cuda:0') tensor(6237.9653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.3962, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2889.2917, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.9229, device='cuda:0') tensor(9559.5264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.4271, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5436.7676, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3122.9216, device='cuda:0') tensor(1582.2334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.4401, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8009.3115, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.9824, device='cuda:0') tensor(1587.8108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(24.4409, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4265.1099, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.1848, device='cuda:0') tensor(1147.2723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.4341, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5270.2637, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.7363, device='cuda:0') tensor(1133.8242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1270 | 68.01 ms/step | loss 1133.824 \n",
      "param_tail torch.Size([4096, 8]) tensor(24.4288, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4265.1113, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.5244, device='cuda:0') tensor(2612.6455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.4182, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5647.4829, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.3008, device='cuda:0') tensor(986.0052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(24.4185, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4372.8696, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.2405, device='cuda:0') tensor(1692.7632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.4173, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6599.7300, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.6694, device='cuda:0') tensor(9012.1123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.4071, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4989.4722, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6450, device='cuda:0') tensor(2488.6619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.4104, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1343.3307, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.8779, device='cuda:0') tensor(4572.2207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(24.4281, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3696.4700, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2608.0237, device='cuda:0') tensor(1363.1746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.4332, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5669.6206, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.9087, device='cuda:0') tensor(4630.9854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.4322, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1125.6667, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1993.7759, device='cuda:0') tensor(911.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.4495, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3353.5156, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3122.4131, device='cuda:0') tensor(1070.6342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1280 | 93.86 ms/step | loss 1070.634 \n",
      "param_tail torch.Size([3712, 8]) tensor(24.4784, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5454.9839, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.9858, device='cuda:0') tensor(1315.0920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.5168, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3470.7437, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.6602, device='cuda:0') tensor(1954.3201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.5669, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6076.5181, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.0183, device='cuda:0') tensor(3567.9265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.6034, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2729.1848, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.8579, device='cuda:0') tensor(1138.0569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(24.6401, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2801.6318, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.8765, device='cuda:0') tensor(3595.2727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.6858, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5220.3091, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.1699, device='cuda:0') tensor(2505.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.7195, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4294.8516, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.1265, device='cuda:0') tensor(2050.7615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.7387, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(540.2551, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1557.7513, device='cuda:0') tensor(2553.6729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(24.7733, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3921.2527, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9688, device='cuda:0') tensor(2372.4185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.8140, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5665.4424, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.0396, device='cuda:0') tensor(1302.9196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1290 | 65.72 ms/step | loss 1302.920 \n",
      "param_tail torch.Size([4096, 8]) tensor(24.8392, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5798.3296, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.0347, device='cuda:0') tensor(4631.9180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.8542, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4597.9028, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.8311, device='cuda:0') tensor(2868.1260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(24.8546, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(714.3161, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1330.6238, device='cuda:0') tensor(1274.4113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.8751, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1809.3878, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.6980, device='cuda:0') tensor(915.0103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.9120, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5722.5127, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.3130, device='cuda:0') tensor(1393.4542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.9328, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4655.8936, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.2856, device='cuda:0') tensor(8385.8848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(24.9391, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5417.5063, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.4390, device='cuda:0') tensor(1965.9020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.9327, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5281.4307, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.9531, device='cuda:0') tensor(1952.4459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.9385, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2974.1804, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1353, device='cuda:0') tensor(5730.7012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.9595, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5199.4287, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.0400, device='cuda:0') tensor(1041.0946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1300 | 80.99 ms/step | loss 1041.095 \n",
      "param_tail torch.Size([3712, 8]) tensor(24.9685, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1533.0382, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1329.7662, device='cuda:0') tensor(1082.1472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(24.9913, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1535.3033, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.2607, device='cuda:0') tensor(6550.3867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(25.0274, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1571.9563, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.2988, device='cuda:0') tensor(3155.4661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(25.0797, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3406.0359, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.0488, device='cuda:0') tensor(1641.4061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(25.1430, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4148.7461, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.7559, device='cuda:0') tensor(3661.0918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(25.2118, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3549.3352, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.2493, device='cuda:0') tensor(860.6699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(25.2763, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5572.9941, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.1992, device='cuda:0') tensor(2067.6711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(25.3480, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5060.4258, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.9771, device='cuda:0') tensor(2232.5835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(25.3960, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1724.7572, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.1521, device='cuda:0') tensor(1379.8569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(25.4578, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3993.2517, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1426, device='cuda:0') tensor(3333.3633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1310 | 79.88 ms/step | loss 3333.363 \n",
      "param_tail torch.Size([4096, 8]) tensor(25.5289, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3894.3691, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.0586, device='cuda:0') tensor(5810.0151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(25.6064, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2392.5005, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.2073, device='cuda:0') tensor(5551.2520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(25.6910, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2142.3857, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2039.0836, device='cuda:0') tensor(921.9360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(25.7877, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7656.4180, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.2700, device='cuda:0') tensor(8892.0918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(25.8782, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4566.3398, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.5203, device='cuda:0') tensor(1515.1335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(25.9520, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2584.0400, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.3337, device='cuda:0') tensor(1149.0662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(26.0388, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(926.5869, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1556.7950, device='cuda:0') tensor(1501.4261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(26.1356, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2782.3787, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.6035, device='cuda:0') tensor(6997.3145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(26.2362, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5304.5508, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.9912, device='cuda:0') tensor(1236.2019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(26.3360, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3762.5552, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.6758, device='cuda:0') tensor(2806.9392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1320 | 64.87 ms/step | loss 2806.939 \n",
      "param_tail torch.Size([3712, 8]) tensor(26.4135, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1703.4749, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1557.9976, device='cuda:0') tensor(812.0685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(26.4775, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7597.0674, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.2510, device='cuda:0') tensor(2666.7500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(26.5364, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6226.0962, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.6030, device='cuda:0') tensor(1735.0691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(26.5736, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4304.4014, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.7427, device='cuda:0') tensor(999.3336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(26.5972, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1047.0979, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1127.6974, device='cuda:0') tensor(676.7253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(26.6218, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3082.8499, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.5198, device='cuda:0') tensor(1159.4629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(26.6595, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5457.6812, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.9937, device='cuda:0') tensor(2037.9113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(26.6958, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3502.9690, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.0879, device='cuda:0') tensor(3771.6675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(26.7415, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4154.9575, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.3518, device='cuda:0') tensor(2760.8149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(26.7750, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1826.3755, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.2573, device='cuda:0') tensor(8720.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1330 | 80.39 ms/step | loss 8720.001 \n",
      "param_tail torch.Size([4096, 8]) tensor(26.8211, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5878.2339, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.5894, device='cuda:0') tensor(974.5357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(26.8668, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6713.1118, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.7251, device='cuda:0') tensor(1685.8575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(26.8971, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(740.6622, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.2996, device='cuda:0') tensor(1840.8531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(26.9445, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4531.7061, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.7573, device='cuda:0') tensor(2947.0381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(26.9758, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3183.4075, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.0566, device='cuda:0') tensor(790.5115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(27.0227, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3403.6628, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.9189, device='cuda:0') tensor(1928.8091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(27.0819, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1274.0271, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.9648, device='cuda:0') tensor(9419.8857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(27.1451, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4460.9048, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3420.3748, device='cuda:0') tensor(2530.7996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(27.1877, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(707.7391, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1127.8683, device='cuda:0') tensor(1066.1758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(27.2448, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3972.3254, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.6968, device='cuda:0') tensor(1762.3987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1340 | 80.64 ms/step | loss 1762.399 \n",
      "param_tail torch.Size([3712, 8]) tensor(27.3119, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8450.3506, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9375, device='cuda:0') tensor(2708.6426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(27.3644, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2362.0623, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4990, device='cuda:0') tensor(4241.6733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(27.4242, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4846.0347, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.6736, device='cuda:0') tensor(1381.1118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(27.4692, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4254.1221, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.5312, device='cuda:0') tensor(2222.8613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(27.4941, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6132.4849, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.6260, device='cuda:0') tensor(1612.2867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(27.5036, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1185.3712, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1330.3977, device='cuda:0') tensor(745.6230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(27.5351, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3606.1304, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.8086, device='cuda:0') tensor(4420.1025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(27.5848, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7106.1987, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6860, device='cuda:0') tensor(2821.2356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(27.6397, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(700.3141, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.9561, device='cuda:0') tensor(1778.9546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(27.7109, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5505.4121, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.4580, device='cuda:0') tensor(4572.0566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1350 | 64.38 ms/step | loss 4572.057 \n",
      "param_tail torch.Size([4096, 8]) tensor(27.7895, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2790.6462, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.4487, device='cuda:0') tensor(1519.3064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(27.8815, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4052.2710, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.8201, device='cuda:0') tensor(908.3425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(27.9493, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2498.0974, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.3105, device='cuda:0') tensor(7327.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(28.0221, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1590.7542, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.5967, device='cuda:0') tensor(1411.8049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(28.1085, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6766.6523, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.4395, device='cuda:0') tensor(1550.3005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(28.1743, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3766.8740, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.3655, device='cuda:0') tensor(6836.7354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(28.2450, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2349.1362, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.1548, device='cuda:0') tensor(2204.8376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(28.3279, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3203.9192, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4038.5430, device='cuda:0') tensor(1760.7361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(28.4212, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6147.0654, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.5854, device='cuda:0') tensor(4259.3184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(28.5107, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3730.2976, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3122.4167, device='cuda:0') tensor(990.8680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1360 | 84.01 ms/step | loss  990.868 \n",
      "param_tail torch.Size([3712, 8]) tensor(28.5810, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1673.3846, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.3142, device='cuda:0') tensor(1170.4181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(28.6658, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5220.6357, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6208.9961, device='cuda:0') tensor(1177.6826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(28.7599, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(967.7755, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1558.8861, device='cuda:0') tensor(2127.9714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(28.8673, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5813.8413, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4874.9116, device='cuda:0') tensor(11079.0645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(28.9593, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2413.8840, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.0986, device='cuda:0') tensor(7997.1108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(29.0606, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(867.6270, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1995.5198, device='cuda:0') tensor(1287.3831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(29.1739, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6030.1772, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9917, device='cuda:0') tensor(967.6806, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(29.2923, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3238.9495, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.4727, device='cuda:0') tensor(4007.7429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(29.4204, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2744.5103, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.1118, device='cuda:0') tensor(1682.0165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(29.5490, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4351.2280, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.2141, device='cuda:0') tensor(6060.3354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1370 | 65.73 ms/step | loss 6060.335 \n",
      "param_tail torch.Size([4096, 8]) tensor(29.6490, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2539.6545, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.9202, device='cuda:0') tensor(1246.6047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(29.7244, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3392.7720, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.7549, device='cuda:0') tensor(1278.6718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(29.7952, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8066.9507, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.7988, device='cuda:0') tensor(1309.8511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(29.8474, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5810.2593, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.6626, device='cuda:0') tensor(2095.4194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(29.8776, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2204.8733, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.2600, device='cuda:0') tensor(2739.7588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(29.9233, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3248.8142, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.7910, device='cuda:0') tensor(6911.0078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(29.9744, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1136.9053, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.5247, device='cuda:0') tensor(5935.4902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(30.0326, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5425.6890, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4038.7539, device='cuda:0') tensor(1531.5591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(30.0745, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2062.4092, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4336, device='cuda:0') tensor(14231.3350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(30.1331, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2189.0251, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2042.0251, device='cuda:0') tensor(837.7180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1380 | 80.69 ms/step | loss  837.718 \n",
      "param_tail torch.Size([3712, 8]) tensor(30.1977, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6023.7554, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.0659, device='cuda:0') tensor(2211.4153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(30.2508, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1738.9626, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1327.4468, device='cuda:0') tensor(927.0408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(30.3153, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8267.6816, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.2051, device='cuda:0') tensor(1853.2944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(30.3639, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4015.8428, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.4624, device='cuda:0') tensor(2051.8770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(30.4302, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4143.3481, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.8467, device='cuda:0') tensor(4336.2822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(30.5045, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3708.9580, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.4956, device='cuda:0') tensor(1353.7943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(30.5650, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4420.3501, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.8503, device='cuda:0') tensor(1148.6152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(30.6167, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4788.4883, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.5161, device='cuda:0') tensor(2905.9717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(30.6564, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5871.4482, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.4907, device='cuda:0') tensor(1325.7701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(30.6791, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4867.3096, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.0803, device='cuda:0') tensor(1559.2601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1390 | 81.51 ms/step | loss 1559.260 \n",
      "param_tail torch.Size([4096, 8]) tensor(30.6918, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2441.5659, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.2505, device='cuda:0') tensor(2683.8398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(30.7196, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5494.5161, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.8223, device='cuda:0') tensor(4435.5552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(30.7580, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2676.9609, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.7832, device='cuda:0') tensor(999.8790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(30.8057, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6778.3472, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.8398, device='cuda:0') tensor(4657.4097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(30.8601, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4981.2822, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.9326, device='cuda:0') tensor(1095.5460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(30.9285, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2327.7295, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.7249, device='cuda:0') tensor(7484.4321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(31.0084, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1932.1536, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2040.1375, device='cuda:0') tensor(774.1541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(31.1052, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6279.6279, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.2725, device='cuda:0') tensor(1691.2942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(31.2086, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3368.9192, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.4919, device='cuda:0') tensor(1222.2032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(31.3232, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4470.2178, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.8105, device='cuda:0') tensor(3425.8794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1400 | 67.93 ms/step | loss 3425.879 \n",
      "param_tail torch.Size([3712, 8]) tensor(31.4116, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1757.9106, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2258.7932, device='cuda:0') tensor(2145.6926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "checking 349\n",
      "(16000, 2) torch.Size([16000, 2]) 30.894523476414566 aloha\n",
      "param_tail torch.Size([4096, 8]) tensor(31.4897, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1136.5656, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2608.7434, device='cuda:0') tensor(1426.5248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(31.5810, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1553.5336, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.0742, device='cuda:0') tensor(6730.4761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(31.6799, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6378.6533, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.2393, device='cuda:0') tensor(2165.0337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(31.7502, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3097.1165, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.0630, device='cuda:0') tensor(1736.0852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(31.8300, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4781.7324, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.2661, device='cuda:0') tensor(2429.6699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(31.9164, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7932.7334, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.8936, device='cuda:0') tensor(1454.2151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(31.9809, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1367.3750, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1174.6257, device='cuda:0') tensor(926.5112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(32.0576, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2722.6074, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3415.7087, device='cuda:0') tensor(3022.8706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(32.1439, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2666.7234, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.7124, device='cuda:0') tensor(3521.1201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1410 | 256.52 ms/step | loss 3521.120 \n",
      "param_tail torch.Size([4096, 8]) tensor(32.2365, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5678.5195, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.5854, device='cuda:0') tensor(3824.2334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(32.3133, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(797.0071, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1558.0028, device='cuda:0') tensor(1555.1428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(32.4044, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1686.8572, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2258.1707, device='cuda:0') tensor(970.3451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(32.5052, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9107.9805, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.4028, device='cuda:0') tensor(2507.1055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(32.5828, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5034.0503, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.4690, device='cuda:0') tensor(1761.2094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(32.6425, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2768.1753, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2608.6660, device='cuda:0') tensor(952.8184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(32.6849, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4541.6948, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.2002, device='cuda:0') tensor(1495.4155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(32.7075, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1946.3271, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.1572, device='cuda:0') tensor(8658.6279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(32.7518, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5059.6333, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.6162, device='cuda:0') tensor(1845.8616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(32.7749, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5079.9185, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3118.6042, device='cuda:0') tensor(1916.7722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1420 | 79.35 ms/step | loss 1916.772 \n",
      "param_tail torch.Size([3712, 8]) tensor(32.7815, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3290.8123, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.7117, device='cuda:0') tensor(1004.4909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(32.8062, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4062.9111, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.5444, device='cuda:0') tensor(3039.6294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(32.8442, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3802.6711, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.3318, device='cuda:0') tensor(1604.6016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(32.8809, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3639.0977, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.9431, device='cuda:0') tensor(3137.8564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(32.9289, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3555.9846, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.3838, device='cuda:0') tensor(4380.6040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(32.9777, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(459.7479, device='cuda:0', grad_fn=<MaxBackward1>) tensor(925.9450, device='cuda:0') tensor(1151.3008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(33.0423, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6471.4365, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4869.5176, device='cuda:0') tensor(2833.1353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(33.1001, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2154.2185, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.7297, device='cuda:0') tensor(758.2423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(33.1749, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6699.2852, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6938, device='cuda:0') tensor(2590.4238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(33.2540, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(454.5671, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.8535, device='cuda:0') tensor(2023.6542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1430 | 64.90 ms/step | loss 2023.654 \n",
      "param_tail torch.Size([4096, 8]) tensor(33.3199, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2692.7651, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.6184, device='cuda:0') tensor(1724.0670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(33.3947, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3561.4358, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.0625, device='cuda:0') tensor(10231.3262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(33.4838, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5154.6895, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.1807, device='cuda:0') tensor(2522.6575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(33.5634, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1080.5398, device='cuda:0', grad_fn=<MaxBackward1>) tensor(926.7191, device='cuda:0') tensor(1175.3425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(33.6600, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2621.4573, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.5503, device='cuda:0') tensor(1182.5083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(33.7696, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5935.1333, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.2441, device='cuda:0') tensor(2438.9119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(33.8606, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2767.1206, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.5088, device='cuda:0') tensor(4237.7764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(33.9610, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1384.3601, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2258.6013, device='cuda:0') tensor(2023.3171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(34.0768, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2501.4744, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.7231, device='cuda:0') tensor(16325.8701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(34.2043, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4320.2568, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.2656, device='cuda:0') tensor(1278.9293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1440 | 85.23 ms/step | loss 1278.929 \n",
      "param_tail torch.Size([3712, 8]) tensor(34.3408, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3767.7383, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.1252, device='cuda:0') tensor(752.8605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(34.4742, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6675.9287, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.1240, device='cuda:0') tensor(2881.1267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(34.5987, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1396.4639, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.7205, device='cuda:0') tensor(3658.5894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(34.7293, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3500.7356, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.8240, device='cuda:0') tensor(1879.0448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(34.8519, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(760.4283, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1126.2566, device='cuda:0') tensor(911.3505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(34.9777, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3289.3394, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.7827, device='cuda:0') tensor(1044.2322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(35.0716, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(10104.3691, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.7388, device='cuda:0') tensor(7886.8267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(35.1326, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2716.6562, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1994.1769, device='cuda:0') tensor(1014.7853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(35.1774, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4422.8857, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.2041, device='cuda:0') tensor(1413.7938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(35.1998, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5988.1245, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.0264, device='cuda:0') tensor(1428.3994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1450 | 72.09 ms/step | loss 1428.399 \n",
      "param_tail torch.Size([4096, 8]) tensor(35.2061, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(10163.6221, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.1191, device='cuda:0') tensor(4948.1768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(35.1959, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4284.3472, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.4316, device='cuda:0') tensor(1240.6785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(35.1696, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2220.3660, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.5942, device='cuda:0') tensor(944.7462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(35.1708, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1438.8541, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1993.7942, device='cuda:0') tensor(1023.6503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(35.1944, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3746.8574, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1631, device='cuda:0') tensor(4355.0757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(35.2259, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3303.1558, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.8904, device='cuda:0') tensor(1183.3730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(35.2726, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5182.4375, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.3311, device='cuda:0') tensor(1437.5826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(35.3386, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1753.6824, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.7168, device='cuda:0') tensor(3349.6555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(35.4117, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2516.5000, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1196, device='cuda:0') tensor(10209.6250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(35.4992, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(973.6858, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.5986, device='cuda:0') tensor(2924.6279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1460 | 88.14 ms/step | loss 2924.628 \n",
      "param_tail torch.Size([3712, 8]) tensor(35.5968, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3048.7996, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.2385, device='cuda:0') tensor(2576.4641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(35.7047, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4287.4658, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.5432, device='cuda:0') tensor(2310.6638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(35.7854, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4554.0049, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.6128, device='cuda:0') tensor(1568.1613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(35.8737, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3630.3447, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.5032, device='cuda:0') tensor(1141.0039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(35.9617, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6340.1719, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.1055, device='cuda:0') tensor(2809.2664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(36.0432, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(649.4415, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1328.6649, device='cuda:0') tensor(1013.3285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(36.1452, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2479.7124, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1694, device='cuda:0') tensor(7654.5732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(36.2595, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2994.2930, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.6665, device='cuda:0') tensor(7147.0581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(36.3857, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(884.8757, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1993.8013, device='cuda:0') tensor(1134.6467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(36.5230, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3357.4888, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.3979, device='cuda:0') tensor(5941.8008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1470 | 91.94 ms/step | loss 5941.801 \n",
      "param_tail torch.Size([4096, 8]) tensor(36.6648, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5048.6421, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.8013, device='cuda:0') tensor(2681.1143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(36.7800, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1639.9250, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2042.0366, device='cuda:0') tensor(1067.5830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(36.9118, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1464.6243, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2611.5190, device='cuda:0') tensor(976.1923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(37.0542, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(700.1833, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.3474, device='cuda:0') tensor(2517.9590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(37.2116, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4888.9609, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.2549, device='cuda:0') tensor(1240.0635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(37.3652, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3405.0647, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.5205, device='cuda:0') tensor(7797.7363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(37.5293, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(976.9901, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1173.7087, device='cuda:0') tensor(997.2899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(37.6966, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4511.8521, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.7622, device='cuda:0') tensor(3997.1694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(37.8420, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2210.0034, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2255.8577, device='cuda:0') tensor(794.7294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(37.9992, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4078.2595, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.4316, device='cuda:0') tensor(1859.6914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1480 | 66.11 ms/step | loss 1859.691 \n",
      "param_tail torch.Size([3712, 8]) tensor(38.1230, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2487.2649, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.7495, device='cuda:0') tensor(5085.9927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(38.2529, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4568.8477, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.8630, device='cuda:0') tensor(3535.6807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(38.3564, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8068.7104, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.8706, device='cuda:0') tensor(1437.1145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(38.4314, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1497.3101, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2042.5571, device='cuda:0') tensor(1238.9910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(38.5245, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3647.2051, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.8699, device='cuda:0') tensor(1549.8594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(38.6295, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1937.9779, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.5898, device='cuda:0') tensor(3227.4451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(38.7479, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4811.6572, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.8967, device='cuda:0') tensor(1691.5944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(38.8475, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4689.3159, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.0181, device='cuda:0') tensor(11533.5195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(38.9576, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(637.9958, device='cuda:0', grad_fn=<MaxBackward1>) tensor(700.2350, device='cuda:0') tensor(1023.6915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(39.0612, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4358.0781, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.4722, device='cuda:0') tensor(1874.3628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1490 | 81.70 ms/step | loss 1874.363 \n",
      "param_tail torch.Size([4096, 8]) tensor(39.1412, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9028.1113, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.1982, device='cuda:0') tensor(7842.5308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(39.2066, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1785.6121, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.7231, device='cuda:0') tensor(2095.1550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(39.2738, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1971.9622, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.3396, device='cuda:0') tensor(5855.2134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(39.3477, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3031.6240, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.1072, device='cuda:0') tensor(2446.6692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(39.4311, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8464.6709, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4785, device='cuda:0') tensor(1582.3220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(39.4896, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2264.0686, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.7661, device='cuda:0') tensor(2721.7114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(39.5582, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4001.1025, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.8115, device='cuda:0') tensor(2638.2153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(39.6077, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3025.5007, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2608.4390, device='cuda:0') tensor(1210.8718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(39.6623, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1257.7500, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1993.8734, device='cuda:0') tensor(1240.5323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(39.7287, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6910.7988, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.9824, device='cuda:0') tensor(5679.5830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1500 | 84.23 ms/step | loss 5679.583 \n",
      "param_tail torch.Size([3712, 8]) tensor(39.7702, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1833.9362, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2258.5452, device='cuda:0') tensor(1206.7074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(39.8118, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3239.0432, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2608.7742, device='cuda:0') tensor(1320.6765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(39.8368, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8080.8989, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.9810, device='cuda:0') tensor(4002.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(39.8414, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8085.0952, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.8267, device='cuda:0') tensor(5324.7090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(39.8363, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(757.5900, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1326.9497, device='cuda:0') tensor(913.1454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(39.8574, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4403.2881, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.6675, device='cuda:0') tensor(1861.5645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(39.8613, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2006.0430, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.2715, device='cuda:0') tensor(3754.9958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(39.8812, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(674.1174, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.5972, device='cuda:0') tensor(7721.1357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(39.9223, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2995.8804, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.3804, device='cuda:0') tensor(3990.2993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(39.9816, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5530.4678, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.0293, device='cuda:0') tensor(1206.8386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1510 | 68.66 ms/step | loss 1206.839 \n",
      "param_tail torch.Size([4096, 8]) tensor(40.0592, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3286.2107, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.1912, device='cuda:0') tensor(1138.8550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(40.1197, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2006.0981, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.2969, device='cuda:0') tensor(7315.9272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(40.1960, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2652.9590, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.7900, device='cuda:0') tensor(2528.8350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(40.2908, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4468.4771, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.5229, device='cuda:0') tensor(3792.0454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(40.3617, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2707.7922, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.4192, device='cuda:0') tensor(1230.0587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(40.4350, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4034.2817, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4478, device='cuda:0') tensor(2394.7031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(40.5238, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1531.6749, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1170.6494, device='cuda:0') tensor(925.5901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(40.6119, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4056.7646, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.5305, device='cuda:0') tensor(1280.5242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(40.6836, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3729.1335, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.8452, device='cuda:0') tensor(1472.5022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(40.7636, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7833.4756, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.0132, device='cuda:0') tensor(2681.4302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1520 | 89.50 ms/step | loss 2681.430 \n",
      "param_tail torch.Size([3712, 8]) tensor(40.8204, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3610.2773, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.7312, device='cuda:0') tensor(1302.6028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(40.8881, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(751.6555, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.7253, device='cuda:0') tensor(4608.8457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(40.9762, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4968.6572, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.3003, device='cuda:0') tensor(9384.0879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(41.0332, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3055.1475, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.5852, device='cuda:0') tensor(1452.0916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(41.0982, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1481.6707, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.9644, device='cuda:0') tensor(3031.2544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(41.1824, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4921.1265, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.9194, device='cuda:0') tensor(5734.4062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(41.2445, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3455.1780, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.9260, device='cuda:0') tensor(9494.9473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(41.3105, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1791.6658, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1994.3761, device='cuda:0') tensor(1449.1074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(41.3941, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3082.9387, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.1025, device='cuda:0') tensor(5277.7969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(41.4811, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4264.4692, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3415.6392, device='cuda:0') tensor(2110.6899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1530 | 64.34 ms/step | loss 2110.690 \n",
      "param_tail torch.Size([4096, 8]) tensor(41.5738, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(931.6354, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1993.7026, device='cuda:0') tensor(1406.4447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(41.6862, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3839.6685, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.7798, device='cuda:0') tensor(2575.1841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(41.8040, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6711.1841, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.5010, device='cuda:0') tensor(2233.6274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(41.9049, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6058.7544, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.4053, device='cuda:0') tensor(2468.8430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(42.0106, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4137.4043, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4658, device='cuda:0') tensor(6844.9243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(42.1235, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1675.6594, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.8596, device='cuda:0') tensor(1720.6915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(42.2515, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1364.8290, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.7710, device='cuda:0') tensor(1994.3434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(42.3800, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4199.7261, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.2910, device='cuda:0') tensor(2975.8711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(42.4751, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2820.3943, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.0396, device='cuda:0') tensor(1982.1716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(42.5825, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1122.7666, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9624, device='cuda:0') tensor(9034.2578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1540 | 80.31 ms/step | loss 9034.258 \n",
      "param_tail torch.Size([3712, 8]) tensor(42.7100, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2375.5452, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3118.9263, device='cuda:0') tensor(1407.5664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(42.8520, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2066.1675, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.2349, device='cuda:0') tensor(6260.3970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(43.0032, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5590.5928, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.5654, device='cuda:0') tensor(2211.0398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(43.1414, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5749.0171, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.2896, device='cuda:0') tensor(1487.0571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(43.2466, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2631.1890, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1993.2991, device='cuda:0') tensor(1335.8958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(43.3181, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5249.6650, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3419.0437, device='cuda:0') tensor(2247.4810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(43.3718, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8303.4902, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4551, device='cuda:0') tensor(11089.5176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(43.4079, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2878.2393, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.2544, device='cuda:0') tensor(1975.8320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(43.4662, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1371.6902, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1558.6646, device='cuda:0') tensor(2850.6392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(43.5300, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1194.6544, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1331.0647, device='cuda:0') tensor(1034.9398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1550 | 80.28 ms/step | loss 1034.940 \n",
      "param_tail torch.Size([4096, 8]) tensor(43.6051, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3456.0330, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4800, device='cuda:0') tensor(10601.5254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(43.6990, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2873.2654, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.2886, device='cuda:0') tensor(5905.5186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(43.8089, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2719.7456, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.9417, device='cuda:0') tensor(3918.5762, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(43.8993, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(815.8450, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1153.2258, device='cuda:0') tensor(1162.5811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(43.9666, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3100.0083, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.0542, device='cuda:0') tensor(4139.3125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.0522, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8587.5557, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.0923, device='cuda:0') tensor(10458.0078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(44.1134, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(982.8540, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1995.4210, device='cuda:0') tensor(1619.1620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.1614, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3111.3115, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.1707, device='cuda:0') tensor(1698.6157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.1865, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3442.7615, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.8079, device='cuda:0') tensor(2537.8979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.1896, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4524.2134, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.3867, device='cuda:0') tensor(2140.0815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1560 | 65.00 ms/step | loss 2140.082 \n",
      "param_tail torch.Size([3712, 8]) tensor(44.1916, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6481.4253, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.7417, device='cuda:0') tensor(4830.4995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.1769, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3019.8892, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.4712, device='cuda:0') tensor(2619.0083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.1912, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6188.4199, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6006, device='cuda:0') tensor(4941.2720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.1848, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3002.9966, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.4802, device='cuda:0') tensor(1519.9011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(44.1892, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3280.6541, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.6265, device='cuda:0') tensor(2638.7932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.2059, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8615.4395, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.6128, device='cuda:0') tensor(4184.9668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.2081, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5192.3496, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.1255, device='cuda:0') tensor(4046.0344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.1993, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1496.9928, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.6597, device='cuda:0') tensor(5336.1279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(44.2134, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1158.1509, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2042.1421, device='cuda:0') tensor(1477.6591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.2562, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9912.2354, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4502, device='cuda:0') tensor(7191.1367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1570 | 81.43 ms/step | loss 7191.137 \n",
      "param_tail torch.Size([4096, 8]) tensor(44.2714, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(532.7672, device='cuda:0', grad_fn=<MaxBackward1>) tensor(946.4393, device='cuda:0') tensor(1289.3536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.3002, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4502.2056, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.7637, device='cuda:0') tensor(1392.3412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(44.3037, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2139.0620, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1996.3489, device='cuda:0') tensor(2908.0151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.2962, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3970.0256, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.3105, device='cuda:0') tensor(3063.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.3066, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6937.8936, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.3994, device='cuda:0') tensor(1393.4927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.2897, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2258.9319, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.0378, device='cuda:0') tensor(1678.5514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(44.2624, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4033.0410, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.6902, device='cuda:0') tensor(3043.3835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.2197, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(608.3010, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.2097, device='cuda:0') tensor(1700.0139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.1858, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4422.7866, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.4497, device='cuda:0') tensor(6605.8008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.1438, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4116.0581, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.6128, device='cuda:0') tensor(1793.6847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1580 | 83.77 ms/step | loss 1793.685 \n",
      "param_tail torch.Size([3712, 8]) tensor(44.1299, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2153.6875, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.0063, device='cuda:0') tensor(4310.5864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.1370, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1191.0964, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1995.0490, device='cuda:0') tensor(1953.4386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.1738, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4138.2500, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4038.5012, device='cuda:0') tensor(1670.7046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.1942, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4690.3569, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.9390, device='cuda:0') tensor(3780.6206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(44.2378, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4768.4189, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.9609, device='cuda:0') tensor(6379.7485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.2883, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4335.9878, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.1113, device='cuda:0') tensor(2090.7393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.3365, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2649.1614, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2254.6672, device='cuda:0') tensor(1312.8850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.3988, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1686.8311, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1559.0271, device='cuda:0') tensor(1442.4539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(44.4741, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8490.8281, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1357, device='cuda:0') tensor(13138.6357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.5251, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5418.8584, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9067, device='cuda:0') tensor(3542.2307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1590 | 66.86 ms/step | loss 3542.231 \n",
      "param_tail torch.Size([4096, 8]) tensor(44.5958, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4788.8896, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.1677, device='cuda:0') tensor(1417.6329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.6694, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4679.0093, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.4258, device='cuda:0') tensor(3643.1982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(44.7174, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5590.8926, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.7441, device='cuda:0') tensor(1281.6432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.7519, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4560.0845, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.2263, device='cuda:0') tensor(2464.7974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.7635, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8265.6250, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.5396, device='cuda:0') tensor(2099.9397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.7608, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4389.2593, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.9761, device='cuda:0') tensor(10350.3135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(44.7882, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(753.1110, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1560.2972, device='cuda:0') tensor(1455.6084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.8386, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2357.4014, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.6296, device='cuda:0') tensor(2890.9038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(44.9104, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3165.1282, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.2246, device='cuda:0') tensor(2202.1216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(45.0012, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1667.3984, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.4873, device='cuda:0') tensor(2026.5332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1600 | 79.67 ms/step | loss 2026.533 \n",
      "param_tail torch.Size([3712, 8]) tensor(45.1076, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8359.7520, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.0801, device='cuda:0') tensor(2229.0957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "checking 399\n",
      "(16000, 2) torch.Size([16000, 2]) 40.19257181559824 aloha\n",
      "param_tail torch.Size([4096, 8]) tensor(45.1854, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3395.4785, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.5945, device='cuda:0') tensor(1983.5144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(45.2369, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4729.6533, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.9141, device='cuda:0') tensor(3142.6113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(45.2822, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2248.4067, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.5908, device='cuda:0') tensor(1283.7505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(45.3200, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3797.2542, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.1953, device='cuda:0') tensor(2980.2551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(45.3748, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2201.4302, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2259.0020, device='cuda:0') tensor(1081.8972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(45.4191, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4766.6982, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.3467, device='cuda:0') tensor(4696.5479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(45.4773, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4719.7065, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.8511, device='cuda:0') tensor(1747.1984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(45.5167, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3437.8936, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3122.7629, device='cuda:0') tensor(1427.7198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(45.5754, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4636.8232, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.3965, device='cuda:0') tensor(6316.5742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1610 | 230.45 ms/step | loss 6316.574 \n",
      "param_tail torch.Size([4096, 8]) tensor(45.6471, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2409.4895, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1572, device='cuda:0') tensor(5351.7720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(45.7382, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1120.0630, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.3767, device='cuda:0') tensor(1665.2732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(45.8486, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2914.3621, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2611.3357, device='cuda:0') tensor(1513.1107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(45.9671, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6663.5181, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.6968, device='cuda:0') tensor(4889.3662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(46.0953, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2301.0854, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4038.3835, device='cuda:0') tensor(9141.7617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(46.2354, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4442.1216, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.0005, device='cuda:0') tensor(1825.0979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(46.3403, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3223.6587, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2611.9978, device='cuda:0') tensor(1181.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(46.4223, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(591.2111, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.2129, device='cuda:0') tensor(9221.7998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(46.5193, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1966.4752, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.9343, device='cuda:0') tensor(5023.3452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(46.6261, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3352.8022, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.6045, device='cuda:0') tensor(3980.2878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1620 | 93.14 ms/step | loss 3980.288 \n",
      "param_tail torch.Size([3712, 8]) tensor(46.7468, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5522.3691, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.7744, device='cuda:0') tensor(3314.6169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(46.8497, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3282.9312, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.0742, device='cuda:0') tensor(5431.3809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(46.9697, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3055.3325, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.5835, device='cuda:0') tensor(5169.1411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(47.1008, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4672.9653, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3419.6433, device='cuda:0') tensor(1720.8884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(47.1933, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2541.3596, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.2029, device='cuda:0') tensor(1311.2581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(47.3012, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3720.1785, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.8394, device='cuda:0') tensor(2818.1489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(47.4104, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(10263.7822, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.5303, device='cuda:0') tensor(7049.4004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(47.4903, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6951.2729, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.2791, device='cuda:0') tensor(4265.4824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(47.5454, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3503.6748, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.0125, device='cuda:0') tensor(1872.8025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(47.5864, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3138.4309, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.4580, device='cuda:0') tensor(1780.6096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1630 | 84.97 ms/step | loss 1780.610 \n",
      "param_tail torch.Size([4096, 8]) tensor(47.6511, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(543.0801, device='cuda:0', grad_fn=<MaxBackward1>) tensor(751.2155, device='cuda:0') tensor(1207.4209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(47.7224, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5058.7153, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.0513, device='cuda:0') tensor(4003.2988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(47.7980, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4876.1543, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.3291, device='cuda:0') tensor(4358.1133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(47.8950, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4214.9468, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2611.8728, device='cuda:0') tensor(2135.1226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(47.9602, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8133.3027, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.3472, device='cuda:0') tensor(1986.8386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(47.9999, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5709.6885, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.0610, device='cuda:0') tensor(2234.8115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(48.0089, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5831.5151, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.5530, device='cuda:0') tensor(5564.2969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(47.9942, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4630.9756, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.9731, device='cuda:0') tensor(1399.8735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(47.9936, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5549.4043, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.0854, device='cuda:0') tensor(6032.1470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(47.9882, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(614.1682, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1173.2651, device='cuda:0') tensor(1332.7339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1640 | 63.93 ms/step | loss 1332.734 \n",
      "param_tail torch.Size([3712, 8]) tensor(48.0110, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1541.5819, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1559.9241, device='cuda:0') tensor(1748.8069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(48.0536, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4240.4775, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.3726, device='cuda:0') tensor(4635.2349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(48.1076, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5137.7227, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.3115, device='cuda:0') tensor(3663.1143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(48.1786, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6297.7686, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.9255, device='cuda:0') tensor(2770.3711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(48.2231, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2820.3027, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.7192, device='cuda:0') tensor(3848.4790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(48.2817, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1815.2737, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.6556, device='cuda:0') tensor(2126.7280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(48.3679, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2892.6218, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.0583, device='cuda:0') tensor(1216.1125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(48.4494, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4571.9683, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.5259, device='cuda:0') tensor(6261.3350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(48.5488, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4658.7666, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.5601, device='cuda:0') tensor(2761.7725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(48.6620, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2107.1660, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.2334, device='cuda:0') tensor(6158.4526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1650 | 87.05 ms/step | loss 6158.453 \n",
      "param_tail torch.Size([4096, 8]) tensor(48.7925, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3056.8289, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2611.5847, device='cuda:0') tensor(1363.5632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(48.8971, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4181.2256, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3419.0925, device='cuda:0') tensor(1757.2163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(48.9645, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5592.0215, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.3735, device='cuda:0') tensor(3529.2053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(49.0400, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8730.5889, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.6499, device='cuda:0') tensor(2318.9646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(49.0830, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(855.9326, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2042.0240, device='cuda:0') tensor(1737.3577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(49.1443, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4170.2925, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.7637, device='cuda:0') tensor(1736.2000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(49.2146, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2211.3750, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.5081, device='cuda:0') tensor(1661.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(49.3056, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7997.7197, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.1440, device='cuda:0') tensor(3465.1553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(49.3746, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4173.6504, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.8625, device='cuda:0') tensor(2508.5305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(49.4107, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3478.5808, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.7529, device='cuda:0') tensor(2572.9746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1660 | 80.25 ms/step | loss 2572.975 \n",
      "param_tail torch.Size([3712, 8]) tensor(49.4230, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1254.9092, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1328.3958, device='cuda:0') tensor(1213.4518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(49.4458, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5404.9067, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4561, device='cuda:0') tensor(4856.5312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(49.4894, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2225.6577, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.8865, device='cuda:0') tensor(1871.5265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(49.5595, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1760.5815, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.2444, device='cuda:0') tensor(1536.5930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(49.6518, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6076.6099, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.9680, device='cuda:0') tensor(2398.5525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(49.7267, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3764.0049, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.0508, device='cuda:0') tensor(1864.4526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(49.7897, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(963.6279, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.2373, device='cuda:0') tensor(10005.8711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(49.8739, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4662.3389, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.8896, device='cuda:0') tensor(2461.3743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(49.9635, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4286.0332, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.5596, device='cuda:0') tensor(6738.9336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(50.0758, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3461.9441, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.8389, device='cuda:0') tensor(4163.5063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1670 | 64.39 ms/step | loss 4163.506 \n",
      "param_tail torch.Size([4096, 8]) tensor(50.1828, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5308.9502, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.2617, device='cuda:0') tensor(2479.4463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(50.2874, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9504.4355, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.4312, device='cuda:0') tensor(3403.0903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(50.3674, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1131.8114, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.2493, device='cuda:0') tensor(2064.7021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(50.4549, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6338.1177, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.7173, device='cuda:0') tensor(2918.5107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(50.5112, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5733.5444, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.7632, device='cuda:0') tensor(2631.4263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(50.5403, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3686.4004, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.7981, device='cuda:0') tensor(1918.6313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(50.5394, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1573.7256, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.5139, device='cuda:0') tensor(3537.8481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(50.5387, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4626.1680, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.7734, device='cuda:0') tensor(2011.8889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(50.5140, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2011.5190, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.9717, device='cuda:0') tensor(2496.9163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(50.5203, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4433.9600, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.8594, device='cuda:0') tensor(2500.3679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1680 | 77.76 ms/step | loss 2500.368 \n",
      "param_tail torch.Size([3712, 8]) tensor(50.5003, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7749.7998, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4541, device='cuda:0') tensor(2410.5356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(50.4870, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3341.6465, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.1956, device='cuda:0') tensor(1326.5815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(50.4517, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4525.5576, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.4746, device='cuda:0') tensor(4324.7681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(50.3983, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8251.2588, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.5532, device='cuda:0') tensor(8605.9531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(50.3414, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2302.1689, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.5527, device='cuda:0') tensor(1516.8168, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(50.3186, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3739.2170, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.0132, device='cuda:0') tensor(2484.4929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(50.3116, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2913.6558, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.2114, device='cuda:0') tensor(3576.5684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(50.3263, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5637.2671, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.4023, device='cuda:0') tensor(1540.5994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(50.3153, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7379.2959, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.7231, device='cuda:0') tensor(1859.0287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(50.2954, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3287.0706, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.6279, device='cuda:0') tensor(7772.2505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1690 | 68.38 ms/step | loss 7772.250 \n",
      "param_tail torch.Size([4096, 8]) tensor(50.3085, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1684.1879, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.3713, device='cuda:0') tensor(1216.6399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(50.3444, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1184.0583, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.1763, device='cuda:0') tensor(6060.1768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(50.4115, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4148.3960, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.0027, device='cuda:0') tensor(3119.3469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(50.4582, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2291.7632, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.4915, device='cuda:0') tensor(3484.9133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(50.5233, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2937.0835, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.5176, device='cuda:0') tensor(10361.4062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(50.6110, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6819.3774, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.4702, device='cuda:0') tensor(2093.7305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(50.6908, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2433.5723, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.2461, device='cuda:0') tensor(1632.4834, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(50.7611, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3294.3325, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.7241, device='cuda:0') tensor(6071.5840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(50.8505, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4488.9233, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.0212, device='cuda:0') tensor(1675.4287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(50.9079, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4907.7344, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.4929, device='cuda:0') tensor(1896.6838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1700 | 84.78 ms/step | loss 1896.684 \n",
      "param_tail torch.Size([3712, 8]) tensor(50.9320, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7943.5493, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.3105, device='cuda:0') tensor(9853.5957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(50.9397, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5433.0884, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.0039, device='cuda:0') tensor(1754.3525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(50.9758, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1581.7216, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.2227, device='cuda:0') tensor(5200.7349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(51.0328, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1741.9840, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.3923, device='cuda:0') tensor(5800.0977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(51.1037, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5091.4648, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.2988, device='cuda:0') tensor(1491.6936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(51.1676, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8292.0479, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.3433, device='cuda:0') tensor(3249.5156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(51.2057, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2952.0437, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.2268, device='cuda:0') tensor(1470.9421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(51.2677, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4394.8359, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.7791, device='cuda:0') tensor(2067.9985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(51.2984, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2414.0659, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.7366, device='cuda:0') tensor(1811.7563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(51.3531, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5313.3979, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.2773, device='cuda:0') tensor(2644.1216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1710 | 78.48 ms/step | loss 2644.122 \n",
      "param_tail torch.Size([4096, 8]) tensor(51.4021, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1554.0537, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.1550, device='cuda:0') tensor(1441.2290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(51.4785, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4153.2593, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3419.0999, device='cuda:0') tensor(1447.4209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(51.5503, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2528.4536, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2612.2161, device='cuda:0') tensor(1777.6354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(51.6454, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2976.7798, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.7480, device='cuda:0') tensor(7192.5957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(51.7603, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2947.4424, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.8572, device='cuda:0') tensor(1377.6846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(51.8917, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5306.9312, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.2524, device='cuda:0') tensor(1511.1367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(51.9913, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6306.2017, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.5293, device='cuda:0') tensor(1615.0804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(52.1007, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3165.9985, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.8000, device='cuda:0') tensor(1314.6868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(52.1873, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6086.5259, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.5249, device='cuda:0') tensor(2204.9014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(52.2831, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5583.8335, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.6724, device='cuda:0') tensor(1960.7258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1720 | 63.77 ms/step | loss 1960.726 \n",
      "param_tail torch.Size([3712, 8]) tensor(52.3760, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(998.0948, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1154.1808, device='cuda:0') tensor(1422.9081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(52.4857, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4554.8174, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.6853, device='cuda:0') tensor(2566.7266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(52.5594, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5254.8789, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.4353, device='cuda:0') tensor(1938.3038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(52.6043, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5386.9585, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.2183, device='cuda:0') tensor(7538.1895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(52.6585, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(856.0854, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.3140, device='cuda:0') tensor(2136.7712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(52.7357, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6282.3799, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.4946, device='cuda:0') tensor(7666.6650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(52.8319, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(813.5585, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1329.3812, device='cuda:0') tensor(1522.5378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(52.9377, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1653.0781, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.0200, device='cuda:0') tensor(3448.7544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(53.0579, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(847.8036, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.0200, device='cuda:0') tensor(11836.7754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(53.1892, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3091.1362, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.1360, device='cuda:0') tensor(3523.3904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1730 | 83.07 ms/step | loss 3523.390 \n",
      "param_tail torch.Size([4096, 8]) tensor(53.3408, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5140.2505, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.7188, device='cuda:0') tensor(1311.5356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(53.4681, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5732.2300, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6209.4517, device='cuda:0') tensor(2381.1631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(53.6159, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4816.4878, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.3816, device='cuda:0') tensor(2193.6228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(53.7195, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2244.1545, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4875.2612, device='cuda:0') tensor(3349.8130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(53.8348, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5024.5654, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.8071, device='cuda:0') tensor(2560.5693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(53.9088, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5996.4556, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.7559, device='cuda:0') tensor(5700.6914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(53.9496, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4913.1777, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.1824, device='cuda:0') tensor(3035.5603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(53.9901, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5896.8271, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.1958, device='cuda:0') tensor(1582.7405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(54.0090, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1256.0521, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1559.7362, device='cuda:0') tensor(2689.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(54.0490, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9503.0371, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4912, device='cuda:0') tensor(3324.9341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1740 | 79.87 ms/step | loss 3324.934 \n",
      "param_tail torch.Size([3712, 8]) tensor(54.0687, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5902.1450, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.2036, device='cuda:0') tensor(3520.8960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(54.0644, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(988.5448, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2258.7739, device='cuda:0') tensor(2041.1475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(54.0750, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2743.2515, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.3894, device='cuda:0') tensor(9052.0693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(54.0986, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4576.6562, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.2705, device='cuda:0') tensor(4648.5127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(54.1518, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1927.9139, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.0093, device='cuda:0') tensor(4908.8857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(54.2238, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3754.0830, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.5483, device='cuda:0') tensor(4192.2939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(54.3193, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1483.6483, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.1030, device='cuda:0') tensor(9150.1875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(54.4354, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4775.1011, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.6650, device='cuda:0') tensor(1613.7916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(54.5274, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4577.5522, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.2512, device='cuda:0') tensor(1494.8416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(54.6016, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2512.0820, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.2629, device='cuda:0') tensor(7338.0889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1750 | 69.88 ms/step | loss 7338.089 \n",
      "param_tail torch.Size([4096, 8]) tensor(54.6900, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2301.8635, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.7094, device='cuda:0') tensor(1441.8562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(54.7683, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5625.6865, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.7690, device='cuda:0') tensor(5050.5820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(54.8576, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8056.1943, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.6040, device='cuda:0') tensor(2642.6841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(54.9185, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3157.2202, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.3167, device='cuda:0') tensor(1591.4436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(54.9952, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5365.6792, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.7178, device='cuda:0') tensor(1870.3790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(55.0449, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8069.8750, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1206, device='cuda:0') tensor(7447.5034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(55.0719, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3270.8950, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2608.8767, device='cuda:0') tensor(1548.8937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(55.0726, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(559.8258, device='cuda:0', grad_fn=<MaxBackward1>) tensor(753.0888, device='cuda:0') tensor(1579.4081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(55.0772, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5299.9399, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.0752, device='cuda:0') tensor(3591.3750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(55.0513, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4332.2573, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.5913, device='cuda:0') tensor(2987.0815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1760 | 93.17 ms/step | loss 2987.082 \n",
      "param_tail torch.Size([3712, 8]) tensor(55.0636, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8929.7754, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.8535, device='cuda:0') tensor(3827.5999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(55.0495, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3862.5088, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.3242, device='cuda:0') tensor(4338.0615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(55.0614, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2808.7173, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.2227, device='cuda:0') tensor(1226.4714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(55.0624, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6988.4175, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9370, device='cuda:0') tensor(3126.7405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(55.0723, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3524.1130, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.5840, device='cuda:0') tensor(9780.0068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(55.1021, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4805.2031, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.6274, device='cuda:0') tensor(2098.2983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(55.1368, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(798.4374, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2608.9531, device='cuda:0') tensor(2734.9863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(55.2072, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3074.2456, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.6035, device='cuda:0') tensor(1819.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(55.2685, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3341.0056, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.8491, device='cuda:0') tensor(7994.9497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(55.3503, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2506.4692, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.3789, device='cuda:0') tensor(2728.6650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1770 | 63.19 ms/step | loss 2728.665 \n",
      "param_tail torch.Size([4096, 8]) tensor(55.4527, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(961.1158, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1173.6859, device='cuda:0') tensor(1337.3975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(55.5816, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3687.4214, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.6938, device='cuda:0') tensor(2220.4297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(55.6900, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7061.5547, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.7051, device='cuda:0') tensor(6591.8481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(55.7902, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4995.8755, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.5229, device='cuda:0') tensor(8943.7637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(55.8763, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1351.4474, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.8879, device='cuda:0') tensor(2862.5137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(55.9877, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4327.5449, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.9995, device='cuda:0') tensor(1545.9913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(56.0997, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2451.7981, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.8071, device='cuda:0') tensor(2147.0764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(56.2349, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3985.2637, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4038.7466, device='cuda:0') tensor(2077.2407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(56.3796, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3121.9250, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.9666, device='cuda:0') tensor(1627.4875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(56.5002, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3189.7922, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.4824, device='cuda:0') tensor(8910.7637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1780 | 85.06 ms/step | loss 8910.764 \n",
      "param_tail torch.Size([3712, 8]) tensor(56.6382, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5654.8140, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.1675, device='cuda:0') tensor(2864.1946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(56.7884, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2196.8438, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.5933, device='cuda:0') tensor(5348.5269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(56.9520, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(880.7235, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2612.6853, device='cuda:0') tensor(3672.8767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(57.1242, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5105.9224, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.2964, device='cuda:0') tensor(2317.6572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(57.3062, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5254.7451, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.2566, device='cuda:0') tensor(2487.8601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(57.4378, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5263.1021, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.2432, device='cuda:0') tensor(1595.3486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(57.5858, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4347.1494, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.1423, device='cuda:0') tensor(2933.4595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(57.7326, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5724.0771, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.1079, device='cuda:0') tensor(2869.0337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(57.8501, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4844.5093, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.4014, device='cuda:0') tensor(1857.2699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(57.9301, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8295.9199, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.1060, device='cuda:0') tensor(3967.4019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1790 | 80.55 ms/step | loss 3967.402 \n",
      "param_tail torch.Size([4096, 8]) tensor(57.9782, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4319.3999, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.3916, device='cuda:0') tensor(2126.8970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(58.0561, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4472.5381, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.3462, device='cuda:0') tensor(2106.9995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(58.1034, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1553.0554, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.5765, device='cuda:0') tensor(1968.4628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(58.1670, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5525.4287, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.8955, device='cuda:0') tensor(3145.3770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(58.2572, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6040.3726, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4874.4434, device='cuda:0') tensor(3142.7429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(58.3464, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5013.6152, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.8354, device='cuda:0') tensor(1759.9187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(58.4000, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1431.1704, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1558.9608, device='cuda:0') tensor(1359.8370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(58.4806, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1037.5504, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.0259, device='cuda:0') tensor(1902.6919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(58.5835, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4842.2744, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.4478, device='cuda:0') tensor(3906.0437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(58.6534, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5088.3623, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.6543, device='cuda:0') tensor(2372.8428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1800 | 65.03 ms/step | loss 2372.843 \n",
      "param_tail torch.Size([3712, 8]) tensor(58.7390, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7189.3027, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1411, device='cuda:0') tensor(2798.6633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "checking 449\n",
      "(16000, 2) torch.Size([16000, 2]) 36.905150194663044 aloha\n",
      "param_tail torch.Size([4096, 8]) tensor(58.8170, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7435.4644, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.3442, device='cuda:0') tensor(2530.1628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(58.8544, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(996.8114, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1329.0328, device='cuda:0') tensor(1264.4346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(58.9262, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2852.3789, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.5000, device='cuda:0') tensor(3517.5957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(59.0250, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5060.5249, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4038.6494, device='cuda:0') tensor(1572.0653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(59.0895, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2203.4224, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2611.4343, device='cuda:0') tensor(2176.8745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(59.1816, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3109.8481, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.0300, device='cuda:0') tensor(12510.3594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(59.2943, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2263.6453, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1993.7799, device='cuda:0') tensor(1417.5380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(59.3980, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5892.1484, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.0757, device='cuda:0') tensor(2310.3098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(59.4882, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1165.7311, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.8115, device='cuda:0') tensor(7671.5020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1810 | 247.35 ms/step | loss 7671.502 \n",
      "param_tail torch.Size([4096, 8]) tensor(59.5977, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4316.1743, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3122.1050, device='cuda:0') tensor(1561.8934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(59.6755, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1364.8485, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.8066, device='cuda:0') tensor(4174.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(59.7800, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5639.2158, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.6289, device='cuda:0') tensor(2508.2246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(59.8410, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4697.1890, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.1118, device='cuda:0') tensor(1735.7209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(59.9149, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4761.9214, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6606, device='cuda:0') tensor(5135.2832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(60.0121, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3029.8638, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.7092, device='cuda:0') tensor(3183.8684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(60.1286, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4241.2598, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.5955, device='cuda:0') tensor(1472.5016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(60.2152, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4478.7612, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.6499, device='cuda:0') tensor(2835.9622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(60.3247, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4197.4780, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.9580, device='cuda:0') tensor(1610.2644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(60.4460, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(987.3032, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1151.1587, device='cuda:0') tensor(1244.6118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1820 | 79.36 ms/step | loss 1244.612 \n",
      "param_tail torch.Size([3712, 8]) tensor(60.5838, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2578.0049, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.9856, device='cuda:0') tensor(5893.6313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(60.7393, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3339.2910, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.7744, device='cuda:0') tensor(1519.6655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(60.8801, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(10492.9912, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.3018, device='cuda:0') tensor(4390.9004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(60.9836, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4394.3257, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.9500, device='cuda:0') tensor(1561.9247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(61.0983, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2303.8716, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.7678, device='cuda:0') tensor(7136.2222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(61.2294, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2197.1541, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2040.9249, device='cuda:0') tensor(3092.1008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(61.3828, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4433.6367, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.1885, device='cuda:0') tensor(2174.1616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(61.5132, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8545.8594, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.6279, device='cuda:0') tensor(8598.6338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(61.5935, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(932.0410, device='cuda:0', grad_fn=<MaxBackward1>) tensor(946.2939, device='cuda:0') tensor(1402.6643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(61.6597, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4381.3848, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.5542, device='cuda:0') tensor(2883.6667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1830 | 64.41 ms/step | loss 2883.667 \n",
      "param_tail torch.Size([4096, 8]) tensor(61.7423, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9173.4902, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9727, device='cuda:0') tensor(2816.2471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(61.7923, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3741.2627, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.7466, device='cuda:0') tensor(1928.4984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(61.8607, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(537.2122, device='cuda:0', grad_fn=<MaxBackward1>) tensor(751.4355, device='cuda:0') tensor(1302.9954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(61.9091, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3531.7791, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.2046, device='cuda:0') tensor(2710.3335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(61.9794, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6119.7793, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.6157, device='cuda:0') tensor(1877.4265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(62.0705, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1447.5070, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.3555, device='cuda:0') tensor(2515.4600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(62.1919, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5310.6133, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.8291, device='cuda:0') tensor(1942.8898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(62.2857, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5086.4219, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.5110, device='cuda:0') tensor(3430.5562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(62.3486, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4443.5117, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.0361, device='cuda:0') tensor(1955.3274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(62.4378, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3868.1772, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.4409, device='cuda:0') tensor(7246.9038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1840 | 80.25 ms/step | loss 7246.904 \n",
      "param_tail torch.Size([3712, 8]) tensor(62.5570, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(188.1438, device='cuda:0', grad_fn=<MaxBackward1>) tensor(565.0812, device='cuda:0') tensor(1520.4476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(62.6972, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6138.6396, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.2214, device='cuda:0') tensor(3949.2300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(62.8042, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(524.6952, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1557.1517, device='cuda:0') tensor(2296.2126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(62.9366, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1853.5120, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.2566, device='cuda:0') tensor(2333.1921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(63.0651, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4628.9932, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.2896, device='cuda:0') tensor(7848.1118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(63.2138, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1082.2522, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1174.6593, device='cuda:0') tensor(1841.0469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(63.3320, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3710.9780, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9985, device='cuda:0') tensor(6587.0942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(63.4632, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5543.8730, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.8467, device='cuda:0') tensor(2302.5762, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(63.5544, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3404.9084, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.9795, device='cuda:0') tensor(5967.5591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(63.6606, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2927.1702, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1994.0884, device='cuda:0') tensor(2083.0830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1850 | 62.86 ms/step | loss 2083.083 \n",
      "param_tail torch.Size([4096, 8]) tensor(63.7327, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6780.8501, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.6675, device='cuda:0') tensor(4094.3071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(63.7731, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3288.9419, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.5854, device='cuda:0') tensor(2950.1377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(63.8375, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6465.5327, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6216, device='cuda:0') tensor(2190.7458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(63.9239, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3111.6216, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.9590, device='cuda:0') tensor(1959.5682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(63.9825, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5229.0933, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.8521, device='cuda:0') tensor(2038.2782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(64.0050, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9762.8467, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9092, device='cuda:0') tensor(6182.8145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(63.9870, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2567.2419, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.0288, device='cuda:0') tensor(9102.7266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(63.9996, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2823.2820, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.5879, device='cuda:0') tensor(3551.7896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(64.0382, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9382.1084, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.0181, device='cuda:0') tensor(2589.2961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(64.0471, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3499.6570, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.6489, device='cuda:0') tensor(10144.7100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1860 | 88.24 ms/step | loss 10144.710 \n",
      "param_tail torch.Size([3712, 8]) tensor(64.0897, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3761.7056, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.5647, device='cuda:0') tensor(2000.1569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(64.0930, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(951.9530, device='cuda:0', grad_fn=<MaxBackward1>) tensor(926.1171, device='cuda:0') tensor(1395.6304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(64.1039, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3644.0552, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.5889, device='cuda:0') tensor(1546.4412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(64.0847, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5011.3911, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.5073, device='cuda:0') tensor(17290.1406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(64.0509, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5690.5693, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.9014, device='cuda:0') tensor(2539.1841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(63.9906, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1474.4692, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.4856, device='cuda:0') tensor(2654.3784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(63.9334, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7684.4463, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1440, device='cuda:0') tensor(8168.6699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(63.8658, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5216.6079, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.6035, device='cuda:0') tensor(1843.2462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(63.7999, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3406.7681, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.7583, device='cuda:0') tensor(1625.5913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(63.7058, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4126.2896, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.9563, device='cuda:0') tensor(1796.9388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1870 | 83.46 ms/step | loss 1796.939 \n",
      "param_tail torch.Size([4096, 8]) tensor(63.5940, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4750.8169, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.1973, device='cuda:0') tensor(2135.3416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(63.5246, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2137.2622, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.1555, device='cuda:0') tensor(1872.5159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(63.5008, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4730.1943, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.7134, device='cuda:0') tensor(3656.0317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(63.4806, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7841.3496, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4609, device='cuda:0') tensor(2854.9790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(63.4457, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(903.9606, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2040.3936, device='cuda:0') tensor(1537.5553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(63.4557, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4279.5635, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.5337, device='cuda:0') tensor(2073.6582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(63.4815, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2174.1970, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1996.2699, device='cuda:0') tensor(2089.8821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(63.5407, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3279.3599, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.5923, device='cuda:0') tensor(5336.2520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(63.6288, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4228.7910, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.6675, device='cuda:0') tensor(9121.7988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(63.7258, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(620.9642, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1153.9186, device='cuda:0') tensor(1373.0498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1880 | 67.43 ms/step | loss 1373.050 \n",
      "param_tail torch.Size([3712, 8]) tensor(63.8502, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4516.2017, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.7632, device='cuda:0') tensor(1468.5905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(63.9723, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1789.4343, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2042.4531, device='cuda:0') tensor(1765.4895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(64.1245, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2828.0337, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4043.0225, device='cuda:0') tensor(2915.4712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(64.2889, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4662.0605, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6209.8125, device='cuda:0') tensor(3750.2788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(64.4645, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1678.3804, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.7808, device='cuda:0') tensor(6129.8428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(64.6584, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2780.5073, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.0791, device='cuda:0') tensor(6873.7295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(64.8639, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1602.6960, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.7480, device='cuda:0') tensor(1541.4026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(65.0823, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3066.5830, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.2119, device='cuda:0') tensor(2415.4961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(65.3111, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5117.0190, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.0498, device='cuda:0') tensor(10259.7529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(65.5109, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5253.5181, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.9521, device='cuda:0') tensor(1674.9042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1890 | 78.21 ms/step | loss 1674.904 \n",
      "param_tail torch.Size([4096, 8]) tensor(65.6773, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4661.0103, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.2993, device='cuda:0') tensor(7239.9946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(65.8557, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4798.7544, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.4736, device='cuda:0') tensor(3936.6362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(65.9937, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3296.7043, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.5923, device='cuda:0') tensor(6588.5020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(66.1404, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8694.9014, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.4648, device='cuda:0') tensor(2001.0098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(66.2483, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5434.4009, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4038.8843, device='cuda:0') tensor(3035.3689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(66.3042, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5395.4136, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.1147, device='cuda:0') tensor(3365.1013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(66.3529, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2902.4556, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2258.3816, device='cuda:0') tensor(1485.2452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(66.3862, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6857.7456, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.5776, device='cuda:0') tensor(2907.8486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(66.4070, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1997.1047, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2039.2745, device='cuda:0') tensor(1568.0818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(66.4645, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4439.8203, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.0752, device='cuda:0') tensor(1464.9034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1900 | 79.27 ms/step | loss 1464.903 \n",
      "param_tail torch.Size([3712, 8]) tensor(66.5505, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3104.9309, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.2114, device='cuda:0') tensor(3799.2939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(66.6557, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8396.6562, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.4380, device='cuda:0') tensor(2323.8745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(66.7305, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1533.1307, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.5291, device='cuda:0') tensor(11740.8965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(66.8330, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3108.3560, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.4763, device='cuda:0') tensor(1609.2432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(66.9264, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(869.3488, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.2505, device='cuda:0') tensor(4584.6743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(67.0409, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7708.2256, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.0347, device='cuda:0') tensor(1608.4099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(67.1177, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5338.6802, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.2979, device='cuda:0') tensor(2320.9507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(67.1512, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4596.9863, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.8904, device='cuda:0') tensor(2425.2939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(67.1724, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5417.3037, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.0332, device='cuda:0') tensor(2098.5818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(67.1665, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1647.5299, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.2539, device='cuda:0') tensor(8524.6719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1910 | 62.69 ms/step | loss 8524.672 \n",
      "param_tail torch.Size([4096, 8]) tensor(67.1960, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3065.4868, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.7615, device='cuda:0') tensor(1938.5382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(67.2535, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1062.3170, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.5715, device='cuda:0') tensor(7156.0347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(67.3324, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7203.5615, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.6577, device='cuda:0') tensor(2060.7725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(67.4088, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1579.7925, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.5312, device='cuda:0') tensor(5071.1450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(67.5101, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4569.6665, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.7341, device='cuda:0') tensor(1531.1509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(67.6204, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5855.1250, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.6372, device='cuda:0') tensor(2855.2852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(67.6979, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8150.2520, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6538, device='cuda:0') tensor(2466.7109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(67.7545, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5719.2671, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3419.5640, device='cuda:0') tensor(2730.0598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(67.7790, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5705.4312, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6221, device='cuda:0') tensor(1991.1409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(67.8272, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1101.0974, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.8142, device='cuda:0') tensor(7322.0352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1920 | 78.11 ms/step | loss 7322.035 \n",
      "param_tail torch.Size([3712, 8]) tensor(67.8978, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1615.9685, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.9390, device='cuda:0') tensor(4750.0317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(67.9860, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2844.4587, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.1594, device='cuda:0') tensor(1758.2087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(68.0833, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3001.1685, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.6733, device='cuda:0') tensor(6840.2266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(68.1921, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2058.9763, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.3096, device='cuda:0') tensor(2788.0859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(68.3210, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8138.2344, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.0967, device='cuda:0') tensor(2991.8457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(68.4118, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5331.3579, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.3994, device='cuda:0') tensor(1793.4875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(68.5136, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2990.4619, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.1729, device='cuda:0') tensor(7740.9976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(68.6470, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3125.0337, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.7026, device='cuda:0') tensor(3751.1660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(68.7378, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(417.9045, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1558.1675, device='cuda:0') tensor(2913.7114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(68.8472, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2246.3750, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1561.1758, device='cuda:0') tensor(1805.7875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1930 | 64.21 ms/step | loss 1805.787 \n",
      "param_tail torch.Size([4096, 8]) tensor(68.9176, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7429.5361, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.3970, device='cuda:0') tensor(4629.9438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(68.9382, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4578.6587, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.2886, device='cuda:0') tensor(4494.1909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(68.9331, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1371.0985, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1995.3085, device='cuda:0') tensor(1618.7478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(68.9658, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3490.9861, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.9922, device='cuda:0') tensor(1810.4130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(69.0312, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2986.1060, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2611.0820, device='cuda:0') tensor(1668.6851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(69.1237, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4885.3350, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.4980, device='cuda:0') tensor(2224.7849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(69.2277, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8991.6494, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.7100, device='cuda:0') tensor(3195.4563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(69.2957, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2049.2878, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1559.2827, device='cuda:0') tensor(1367.0254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(69.3713, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5525.8877, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.9233, device='cuda:0') tensor(3783.2615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(69.4332, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6363.4238, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.3877, device='cuda:0') tensor(2928.2000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1940 | 80.02 ms/step | loss 2928.200 \n",
      "param_tail torch.Size([3712, 8]) tensor(69.4800, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3729.0942, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.1699, device='cuda:0') tensor(7327.4370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(69.5499, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2093.8569, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.4370, device='cuda:0') tensor(3146.3875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(69.6437, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3618.0110, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.7231, device='cuda:0') tensor(3062.1938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(69.7521, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1816.0288, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.1097, device='cuda:0') tensor(1656.9420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(69.8660, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7138.1284, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.1104, device='cuda:0') tensor(1900.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(69.9421, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2933.9700, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.9456, device='cuda:0') tensor(3070.8604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(70.0253, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6002.4873, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6826, device='cuda:0') tensor(4837.7319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(70.1348, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1896.8778, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2042.5675, device='cuda:0') tensor(1799.8132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(70.2138, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2255.4268, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.1755, device='cuda:0') tensor(1645.2224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(70.3016, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3782.7021, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.5771, device='cuda:0') tensor(2680.9131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1950 | 77.08 ms/step | loss 2680.913 \n",
      "param_tail torch.Size([4096, 8]) tensor(70.4072, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5648.9517, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.6943, device='cuda:0') tensor(4018.7297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(70.5288, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1084.2394, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1172.9661, device='cuda:0') tensor(1840.3058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(70.6838, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2267.3628, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.3027, device='cuda:0') tensor(5308.6519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(70.8565, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1510.6794, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.8442, device='cuda:0') tensor(2409.6672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(71.0529, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7973.5342, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.3892, device='cuda:0') tensor(4421.3154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(71.2037, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5146.0708, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.4897, device='cuda:0') tensor(3015.5103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(71.3665, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1982.9824, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1557.6566, device='cuda:0') tensor(1603.3179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(71.5345, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5523.0854, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3419.3335, device='cuda:0') tensor(2903.1296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(71.6511, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6031.7764, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.1143, device='cuda:0') tensor(8054.6079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(71.7732, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4354.3340, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4038.9714, device='cuda:0') tensor(2063.8647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1960 | 71.07 ms/step | loss 2063.865 \n",
      "param_tail torch.Size([3712, 8]) tensor(71.9077, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1188.3563, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1994.2806, device='cuda:0') tensor(1713.3680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(72.0797, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1954.1821, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.6431, device='cuda:0') tensor(3988.4204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(72.2623, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4404.8091, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.8088, device='cuda:0') tensor(2095.0415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(72.3977, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1229.6735, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.0928, device='cuda:0') tensor(2595.5444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(72.5462, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7798.5845, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.8745, device='cuda:0') tensor(2672.4143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(72.6527, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(179.6696, device='cuda:0', grad_fn=<MaxBackward1>) tensor(751.4302, device='cuda:0') tensor(1338.2084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(72.7938, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4839.3203, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.7290, device='cuda:0') tensor(2449.2163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(72.9035, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4730.7334, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.4263, device='cuda:0') tensor(3591.2124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(73.0238, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3090.0046, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4038.9626, device='cuda:0') tensor(6985.1426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(73.1671, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(308.9438, device='cuda:0', grad_fn=<MaxBackward1>) tensor(945.6382, device='cuda:0') tensor(1622.5829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1970 | 91.39 ms/step | loss 1622.583 \n",
      "param_tail torch.Size([4096, 8]) tensor(73.3094, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5111.1846, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.6836, device='cuda:0') tensor(3434.5505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(73.4357, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5207.2046, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.1345, device='cuda:0') tensor(2036.8992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(73.5115, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2413.3862, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1562, device='cuda:0') tensor(7323.9624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(73.6130, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1949.7134, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3415.0630, device='cuda:0') tensor(6542.5972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(73.7274, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1927.9066, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.7642, device='cuda:0') tensor(8224.5645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(73.8500, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6045.5161, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.1548, device='cuda:0') tensor(3885.1143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(73.9283, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3313.4746, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.1851, device='cuda:0') tensor(3073.9985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.0400, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4357.1846, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.7368, device='cuda:0') tensor(3318.9675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.1019, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7957.6826, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4844, device='cuda:0') tensor(7942.1582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.1585, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(722.7539, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1329.1360, device='cuda:0') tensor(2991.2285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1980 | 96.89 ms/step | loss 2991.229 \n",
      "param_tail torch.Size([3712, 8]) tensor(74.1881, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4110.2256, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.3042, device='cuda:0') tensor(2228.0330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.2411, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1403.2932, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.9395, device='cuda:0') tensor(10491.3389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.3209, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(777.7618, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.5461, device='cuda:0') tensor(2848.7476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.4281, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4510.2510, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.2407, device='cuda:0') tensor(4313.5029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(74.5513, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(248.5296, device='cuda:0', grad_fn=<MaxBackward1>) tensor(698.9022, device='cuda:0') tensor(2299.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.6242, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1529.4846, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.9644, device='cuda:0') tensor(12150.2930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.6949, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5093.6621, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.2344, device='cuda:0') tensor(2470.8557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.7525, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4557.7773, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6421, device='cuda:0') tensor(4444.7490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(74.8513, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4559.7900, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.1667, device='cuda:0') tensor(2209.2742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.9144, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4271.1245, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4874.3828, device='cuda:0') tensor(3107.2688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   1990 | 74.56 ms/step | loss 3107.269 \n",
      "param_tail torch.Size([4096, 8]) tensor(74.9966, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3675.9155, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.7271, device='cuda:0') tensor(2648.9937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(75.0663, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4719.5854, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.4124, device='cuda:0') tensor(2779.1990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(75.0943, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9745.5332, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.4409, device='cuda:0') tensor(5743.2261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(75.1019, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8258.5801, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.7065, device='cuda:0') tensor(3152.1980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(75.0673, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5537.0474, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.0566, device='cuda:0') tensor(6960.0322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(75.0048, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2405.6785, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1559.6515, device='cuda:0') tensor(2742.8345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(74.9249, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5491.1914, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.1182, device='cuda:0') tensor(2460.8572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.8166, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4498.9443, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.9512, device='cuda:0') tensor(2545.5525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.6985, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3673.7776, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.2097, device='cuda:0') tensor(2603.0210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.5718, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3118.6443, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.8252, device='cuda:0') tensor(4990.2246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2000 | 93.47 ms/step | loss 4990.225 \n",
      "param_tail torch.Size([3712, 8]) tensor(74.4783, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5836.7993, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1265, device='cuda:0') tensor(3934.8926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "checking 499\n",
      "(16000, 2) torch.Size([16000, 2]) 36.61969452883624 aloha\n",
      "param_tail torch.Size([4096, 8]) tensor(74.4140, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3155.6909, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2258.8677, device='cuda:0') tensor(3522.8274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.3322, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7394.9800, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.2017, device='cuda:0') tensor(2894.1714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.2301, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(943.0408, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.9885, device='cuda:0') tensor(15389.7002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(74.1673, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2170.1919, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2039.7660, device='cuda:0') tensor(1454.9542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.1228, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4059.3152, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.5176, device='cuda:0') tensor(1458.8090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.0560, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1170.9834, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.0513, device='cuda:0') tensor(4032.3833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.0204, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4658.4863, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.5559, device='cuda:0') tensor(4536.0840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(74.0067, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6753.7910, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9927, device='cuda:0') tensor(1529.2292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(73.9777, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1798.4670, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.4971, device='cuda:0') tensor(5410.0557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2010 | 233.38 ms/step | loss 5410.056 \n",
      "param_tail torch.Size([4096, 8]) tensor(73.9944, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6133.6133, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.8018, device='cuda:0') tensor(3520.3408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(73.9782, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1766.5286, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1558.8063, device='cuda:0') tensor(1688.9778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(73.9973, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2408.9607, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.4836, device='cuda:0') tensor(8740.5117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.0571, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5280.7153, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.3784, device='cuda:0') tensor(1694.2677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.1215, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4793.1362, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.4065, device='cuda:0') tensor(2626.7764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.1755, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(331.5676, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.4089, device='cuda:0') tensor(10136.6143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(74.2501, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2855.1904, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6209.9834, device='cuda:0') tensor(5411.1240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.3851, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8367.3701, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.5054, device='cuda:0') tensor(1923.3727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.4874, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3968.7881, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4038.7661, device='cuda:0') tensor(1774.8018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.5914, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3839.9814, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.2842, device='cuda:0') tensor(5754.4907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2020 | 79.86 ms/step | loss 5754.491 \n",
      "param_tail torch.Size([3712, 8]) tensor(74.6630, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5829.9868, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.4304, device='cuda:0') tensor(3255.7715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.7030, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2544.3401, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.1821, device='cuda:0') tensor(5622.7451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.7624, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1631.5479, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.5244, device='cuda:0') tensor(2515.1841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.8528, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4818.4556, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.1895, device='cuda:0') tensor(4380.4844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(74.8874, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5502.6016, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.6069, device='cuda:0') tensor(4222.2520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.8837, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1910.6078, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1558.4495, device='cuda:0') tensor(1969.8547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.8778, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3191.9551, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.8149, device='cuda:0') tensor(2470.2124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(74.9197, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5402.5444, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.0610, device='cuda:0') tensor(1706.6678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(74.9733, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3920.9509, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.6431, device='cuda:0') tensor(6167.0171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(75.0828, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6339.0991, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9614, device='cuda:0') tensor(1864.9200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2030 | 79.86 ms/step | loss 1864.920 \n",
      "param_tail torch.Size([4096, 8]) tensor(75.1969, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5044.6030, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.6509, device='cuda:0') tensor(1476.0291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(75.3128, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4261.9243, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4038.9172, device='cuda:0') tensor(3053.0564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(75.4381, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2530.6482, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.6052, device='cuda:0') tensor(3692.0898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(75.5747, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5310.0991, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9424, device='cuda:0') tensor(6124.0068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(75.6938, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4724.9668, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.1904, device='cuda:0') tensor(2908.4578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(75.8150, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5111.1982, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.0994, device='cuda:0') tensor(2173.8540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(75.8683, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1523.4814, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2042.4292, device='cuda:0') tensor(1925.2120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(75.9504, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5702.8330, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.2678, device='cuda:0') tensor(3247.3506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(75.9984, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3049.9612, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.1626, device='cuda:0') tensor(4426.6494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(76.0623, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2234.5574, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.8901, device='cuda:0') tensor(3113.9614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2040 | 64.07 ms/step | loss 3113.961 \n",
      "param_tail torch.Size([3712, 8]) tensor(76.1617, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3432.1174, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.0908, device='cuda:0') tensor(3039.8833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(76.2714, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5556.7686, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.1968, device='cuda:0') tensor(1793.9011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(76.3678, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7914.4346, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9517, device='cuda:0') tensor(1688.9088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(76.4200, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5664.4668, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.5586, device='cuda:0') tensor(2247.1523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(76.4309, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4701.8550, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.9934, device='cuda:0') tensor(3077.2917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(76.4179, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4177.1831, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.1990, device='cuda:0') tensor(1711.5095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(76.3905, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5355.1279, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.5229, device='cuda:0') tensor(2314.9390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(76.3211, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5742.4546, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.9565, device='cuda:0') tensor(2339.2085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(76.2341, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9668.5703, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.3359, device='cuda:0') tensor(3538.8521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(76.1141, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4285.6382, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.0283, device='cuda:0') tensor(7559.9092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2050 | 80.31 ms/step | loss 7559.909 \n",
      "param_tail torch.Size([4096, 8]) tensor(76.0356, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2466.9126, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2258.2498, device='cuda:0') tensor(1561.9167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(76.0282, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5239.4204, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.6660, device='cuda:0') tensor(3782.1611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(76.0485, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(182.2708, device='cuda:0', grad_fn=<MaxBackward1>) tensor(439.0453, device='cuda:0') tensor(1354.3857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(76.0998, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1290.3628, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.6311, device='cuda:0') tensor(6011.4487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(76.1699, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2650.6006, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4038.3494, device='cuda:0') tensor(10557.1582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(76.2769, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8781.8877, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6719, device='cuda:0') tensor(6156.8623, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(76.3361, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2512.1365, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.2908, device='cuda:0') tensor(1990.1442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(76.3445, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3289.0562, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.8794, device='cuda:0') tensor(4265.0479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(76.3696, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5766.5063, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.0249, device='cuda:0') tensor(2434.7710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(76.4328, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4184.7949, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.3291, device='cuda:0') tensor(4408.0430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2060 | 81.04 ms/step | loss 4408.043 \n",
      "param_tail torch.Size([3712, 8]) tensor(76.5057, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3771.3708, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.3481, device='cuda:0') tensor(2100.1885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(76.5969, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4975.0430, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.0442, device='cuda:0') tensor(2177.4849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(76.6412, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4817.2764, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.0176, device='cuda:0') tensor(1720.1805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(76.6902, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7275.4355, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.7646, device='cuda:0') tensor(1851.4014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(76.7272, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1817.2861, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2040.1606, device='cuda:0') tensor(1825.6161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(76.7993, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5442.4277, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.3335, device='cuda:0') tensor(5444.0938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(76.8720, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5182.6143, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.3977, device='cuda:0') tensor(1927.1375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(76.8713, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3473.4419, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.1938, device='cuda:0') tensor(2504.7529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(76.8877, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2728.3047, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.5405, device='cuda:0') tensor(4719.6216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(76.9354, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3099.4768, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2258.0933, device='cuda:0') tensor(1917.2842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2070 | 76.12 ms/step | loss 1917.284 \n",
      "param_tail torch.Size([4096, 8]) tensor(76.9685, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8219.7217, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.0874, device='cuda:0') tensor(11247.3115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(77.0015, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1206.6422, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.3969, device='cuda:0') tensor(2242.2380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(77.0588, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2388.5286, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.1206, device='cuda:0') tensor(1732.7632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(77.1489, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5430.0024, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.1472, device='cuda:0') tensor(6343.3613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(77.2026, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1940.6489, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2040.6146, device='cuda:0') tensor(1666.6074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(77.3134, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1144.6725, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1328.3000, device='cuda:0') tensor(1323.0867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(77.4512, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4398.1865, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9531, device='cuda:0') tensor(6262.2959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(77.6295, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4122.6440, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.8755, device='cuda:0') tensor(9991.6553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(77.7867, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1644.3307, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2039.5425, device='cuda:0') tensor(1547.5924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(77.9822, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3273.3940, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.4907, device='cuda:0') tensor(1994.0681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2080 | 87.33 ms/step | loss 1994.068 \n",
      "param_tail torch.Size([3712, 8]) tensor(78.1418, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3553.3711, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.9355, device='cuda:0') tensor(3204.2742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(78.3244, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4883.3008, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.6653, device='cuda:0') tensor(2386.2209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(78.4459, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3021.0613, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3117.9673, device='cuda:0') tensor(1974.7244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(78.5785, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5557.4673, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.3037, device='cuda:0') tensor(3030.7041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(78.6940, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6442.1704, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.1836, device='cuda:0') tensor(1869.8922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(78.7811, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1899.9049, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1994.9531, device='cuda:0') tensor(1497.7202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(78.8408, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5459.4102, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.6436, device='cuda:0') tensor(2254.7681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(78.9345, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2109.0256, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.5842, device='cuda:0') tensor(4086.2190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(79.0356, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4977.3750, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.4329, device='cuda:0') tensor(2803.5701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(79.1218, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7914.1943, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.7749, device='cuda:0') tensor(3244.9626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2090 | 69.62 ms/step | loss 3244.963 \n",
      "param_tail torch.Size([4096, 8]) tensor(79.1535, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(744.6455, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1330.8016, device='cuda:0') tensor(1576.8372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(79.2344, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5508.3599, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4038.7151, device='cuda:0') tensor(5158.1641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(79.2753, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1949.6359, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1559.1664, device='cuda:0') tensor(1198.7797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(79.2990, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8876.1318, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.3408, device='cuda:0') tensor(6258.0938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(79.3809, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3322.1428, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.3250, device='cuda:0') tensor(3561.3872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(79.4351, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2407.5127, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.9800, device='cuda:0') tensor(2105.7578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(79.5521, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3523.0232, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.3174, device='cuda:0') tensor(2248.6091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(79.6373, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1282.0812, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.1329, device='cuda:0') tensor(1835.4391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(79.8316, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4328.8110, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.7104, device='cuda:0') tensor(3286.6538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(80.0031, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3875.2844, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.2959, device='cuda:0') tensor(1751.6135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2100 | 108.57 ms/step | loss 1751.614 \n",
      "param_tail torch.Size([3712, 8]) tensor(80.2017, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4409.4565, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.0264, device='cuda:0') tensor(4912.8428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(80.3780, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1516.0089, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.7290, device='cuda:0') tensor(3637.7236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(80.6104, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1936.2744, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1557.6234, device='cuda:0') tensor(1713.0579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(80.7386, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8913.6973, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.8706, device='cuda:0') tensor(8052.2324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(80.8397, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4995.9990, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.5493, device='cuda:0') tensor(2645.9272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(80.9509, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4612.8037, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.5164, device='cuda:0') tensor(1616.7507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(80.9774, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3732.9065, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.9097, device='cuda:0') tensor(2825.3525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(80.9760, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5259.0034, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.5762, device='cuda:0') tensor(2103.9167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(81.0173, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5082.0850, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.1758, device='cuda:0') tensor(3017.0496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(81.1012, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2907.7981, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.7383, device='cuda:0') tensor(2695.7822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2110 | 86.77 ms/step | loss 2695.782 \n",
      "param_tail torch.Size([4096, 8]) tensor(81.2312, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4272.7061, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3118.9375, device='cuda:0') tensor(1481.0695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(81.3039, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8708.5771, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.3130, device='cuda:0') tensor(3239.7109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(81.3288, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1013.1844, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.0742, device='cuda:0') tensor(5758.4302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(81.4184, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5250.9355, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.9382, device='cuda:0') tensor(2785.4199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(81.4685, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5055.1338, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.4756, device='cuda:0') tensor(2569.3071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(81.5023, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3406.9326, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.1409, device='cuda:0') tensor(2881.1099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(81.5672, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1991.1353, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.4785, device='cuda:0') tensor(6704.5205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(81.6209, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4651.7725, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.2612, device='cuda:0') tensor(1991.6992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(81.6651, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1511.3806, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4874.2993, device='cuda:0') tensor(5109.7549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(81.7274, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2187.1829, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.6558, device='cuda:0') tensor(9891.6934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2120 | 65.72 ms/step | loss 9891.693 \n",
      "param_tail torch.Size([3712, 8]) tensor(81.8305, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4237.3135, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.7031, device='cuda:0') tensor(2195.6892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(81.9545, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5044.4785, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.3057, device='cuda:0') tensor(2950.7344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(81.9977, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4369.2549, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3118.8718, device='cuda:0') tensor(2691.7219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(82.0536, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6722.4541, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.7183, device='cuda:0') tensor(3007.8501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(82.1382, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4187.3521, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.1060, device='cuda:0') tensor(1433.8446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(82.1977, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4425.5835, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.9165, device='cuda:0') tensor(2676.2280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(82.3148, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2205.6826, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.1948, device='cuda:0') tensor(8964.8936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(82.5072, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5763.4619, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.3123, device='cuda:0') tensor(3373.7393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(82.5534, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(768.7813, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1129.0532, device='cuda:0') tensor(1548.5768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(82.7230, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(855.4666, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.3564, device='cuda:0') tensor(10537.0664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2130 | 82.53 ms/step | loss 10537.066 \n",
      "param_tail torch.Size([4096, 8]) tensor(82.8852, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3739.0920, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.2427, device='cuda:0') tensor(1543.9070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(83.0138, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4686.1875, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.5315, device='cuda:0') tensor(2369.5530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(83.1027, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5556.0762, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.5825, device='cuda:0') tensor(5033.5767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(83.1736, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(919.2048, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1154.6610, device='cuda:0') tensor(1270.7217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(83.2688, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1344.5443, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.3823, device='cuda:0') tensor(4790.8223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(83.4144, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3647.8306, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.6077, device='cuda:0') tensor(6864.6445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(83.5727, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3413.3274, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.0439, device='cuda:0') tensor(3591.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(83.7169, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6883.0078, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.0547, device='cuda:0') tensor(1408.6503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(83.9101, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4668.6221, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.8535, device='cuda:0') tensor(2585.8984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(84.0803, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5618.2412, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.7168, device='cuda:0') tensor(2956.8438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2140 | 81.38 ms/step | loss 2956.844 \n",
      "param_tail torch.Size([3712, 8]) tensor(84.2513, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(815.2981, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1995.6805, device='cuda:0') tensor(2406.7915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(84.3752, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(419.6928, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1127.4663, device='cuda:0') tensor(2195.8833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(84.5347, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4732.2095, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.7500, device='cuda:0') tensor(3547.9126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(84.7194, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2951.7603, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.3433, device='cuda:0') tensor(8943.0312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(84.8950, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4385.2231, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.5508, device='cuda:0') tensor(1713.8815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(85.0187, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9271.4609, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1562, device='cuda:0') tensor(4091.2063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(85.1260, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5266.1733, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3415.7139, device='cuda:0') tensor(2329.6113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(85.1415, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1527.5657, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2042.2314, device='cuda:0') tensor(1551.2283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(85.2137, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5441.8779, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.8584, device='cuda:0') tensor(2375.1370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(85.2442, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5400.5801, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.0024, device='cuda:0') tensor(7197.0366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2150 | 64.00 ms/step | loss 7197.037 \n",
      "param_tail torch.Size([4096, 8]) tensor(85.2186, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2701.6892, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2608.8862, device='cuda:0') tensor(1888.0986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(85.2756, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1793.6438, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.1313, device='cuda:0') tensor(1381.1365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(85.3137, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2076.4321, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.6880, device='cuda:0') tensor(6726.7769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(85.4492, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5146.2998, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.7185, device='cuda:0') tensor(1880.8672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(85.5401, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9002.7529, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9536, device='cuda:0') tensor(5610.3604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(85.6023, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3411.9141, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.7627, device='cuda:0') tensor(2304.6919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(85.6041, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2789.8955, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2259.1885, device='cuda:0') tensor(1684.2358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(85.6642, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5011.5732, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4038.3748, device='cuda:0') tensor(1821.2850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(85.6923, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1451.3813, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.6357, device='cuda:0') tensor(8733.9629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(85.7693, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3932.6855, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.4702, device='cuda:0') tensor(2203.6980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2160 | 79.44 ms/step | loss 2203.698 \n",
      "param_tail torch.Size([3712, 8]) tensor(85.8291, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1750.9280, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.9971, device='cuda:0') tensor(6285.9355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(85.9249, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4378.7046, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.5317, device='cuda:0') tensor(2656.0408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(85.9384, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4202.6309, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.0942, device='cuda:0') tensor(5396.4561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(86.0042, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6296.4229, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1191, device='cuda:0') tensor(1732.8109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(86.0600, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1753.2771, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.4781, device='cuda:0') tensor(3106.8523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(86.1360, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4203.4507, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.5234, device='cuda:0') tensor(2963.3154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(86.1889, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4491.9604, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.4185, device='cuda:0') tensor(2534.7678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(86.2418, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5213.6274, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.5972, device='cuda:0') tensor(1821.9547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(86.3328, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5137.4771, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.3174, device='cuda:0') tensor(11241.5527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(86.4285, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4814.4326, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.4429, device='cuda:0') tensor(2225.3774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2170 | 64.34 ms/step | loss 2225.377 \n",
      "param_tail torch.Size([4096, 8]) tensor(86.4897, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4046.9521, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.9910, device='cuda:0') tensor(1737.5515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(86.5518, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8536.5234, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.7036, device='cuda:0') tensor(3716.6040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(86.5522, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5174.2451, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.1294, device='cuda:0') tensor(1672.9984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(86.5483, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8327.9072, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.5806, device='cuda:0') tensor(2880.8560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(86.5652, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3381.7041, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.0134, device='cuda:0') tensor(3933.6555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(86.5884, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5144.2588, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.7197, device='cuda:0') tensor(2253.3840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(86.5592, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(464.1421, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.6594, device='cuda:0') tensor(11372.9717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(86.5562, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5059.7817, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.1523, device='cuda:0') tensor(1754.3325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(86.4886, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(445.1430, device='cuda:0', grad_fn=<MaxBackward1>) tensor(946.6028, device='cuda:0') tensor(1881.8831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(86.4525, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7970.6313, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.4434, device='cuda:0') tensor(1998.5660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2180 | 78.54 ms/step | loss 1998.566 \n",
      "param_tail torch.Size([3712, 8]) tensor(86.3396, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3449.9370, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.0991, device='cuda:0') tensor(7015.2212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(86.3339, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4831.9805, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.1284, device='cuda:0') tensor(2415.3979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(86.3776, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6800.1377, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.7861, device='cuda:0') tensor(1786.9448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(86.3324, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1813.2029, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2041.2533, device='cuda:0') tensor(2097.1853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(86.3536, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2595.4617, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2255.7334, device='cuda:0') tensor(1848.8969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(86.3664, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3252.4028, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.1514, device='cuda:0') tensor(3550.6123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(86.4371, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4748.6294, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.4209, device='cuda:0') tensor(3382.0723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(86.5092, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(195.2634, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.9556, device='cuda:0') tensor(7257.4824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(86.5648, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2247.1755, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.2051, device='cuda:0') tensor(9606.8721, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(86.6417, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2695.8623, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3122.3923, device='cuda:0') tensor(3541.1714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2190 | 78.81 ms/step | loss 3541.171 \n",
      "param_tail torch.Size([4096, 8]) tensor(86.7652, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8154.2227, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6209.7847, device='cuda:0') tensor(2371.6284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(86.8325, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1566.6520, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2040.5183, device='cuda:0') tensor(2288.8428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(86.9488, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4685.2021, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.3608, device='cuda:0') tensor(3798.8462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(87.0317, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1697.4941, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2258.8660, device='cuda:0') tensor(2176.2588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(87.2044, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1980.5636, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.8403, device='cuda:0') tensor(3396.7444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(87.3689, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4071.4199, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.5703, device='cuda:0') tensor(3094.9792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(87.5049, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3875.9736, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.3552, device='cuda:0') tensor(6536.7197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(87.7222, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4594.4727, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.6167, device='cuda:0') tensor(1625.6440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(87.8625, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1711.5164, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2040.8752, device='cuda:0') tensor(2273.1462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(88.0259, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5966.4736, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.2476, device='cuda:0') tensor(4627.8052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2200 | 63.28 ms/step | loss 4627.805 \n",
      "param_tail torch.Size([3712, 8]) tensor(88.1411, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3762.4292, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.8267, device='cuda:0') tensor(2523.1689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "checking 549\n",
      "(16000, 2) torch.Size([16000, 2]) 43.0909328258228 aloha\n",
      "param_tail torch.Size([4096, 8]) tensor(88.2229, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4428.0698, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9434, device='cuda:0') tensor(4068.5122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(88.3663, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5097.9038, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.8647, device='cuda:0') tensor(1958.7452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(88.4829, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2728.7424, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.6179, device='cuda:0') tensor(6147.3345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(88.6547, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1263.6078, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2608.8804, device='cuda:0') tensor(1602.1948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(88.8098, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5001.5332, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.0874, device='cuda:0') tensor(2158.3564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(88.9352, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8564.2998, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.2959, device='cuda:0') tensor(2389.8115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(89.0465, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2995.5171, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.3865, device='cuda:0') tensor(3640.9099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(89.0611, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2236.0874, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.0303, device='cuda:0') tensor(6188.3799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(89.2673, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5817.6846, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.6316, device='cuda:0') tensor(4277.9028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2210 | 255.32 ms/step | loss 4277.903 \n",
      "param_tail torch.Size([4096, 8]) tensor(89.3161, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5615.8545, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.7534, device='cuda:0') tensor(4815.0044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(89.2887, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(987.8092, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1328.6273, device='cuda:0') tensor(1772.9824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(89.3792, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3856.5107, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.8984, device='cuda:0') tensor(1931.9094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(89.4216, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(484.6870, device='cuda:0', grad_fn=<MaxBackward1>) tensor(698.6700, device='cuda:0') tensor(1385.0969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(89.5899, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5433.3701, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.1396, device='cuda:0') tensor(14932.9395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(89.6956, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(676.0074, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1993.0293, device='cuda:0') tensor(2093.1819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(89.8170, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(902.8123, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1128.0557, device='cuda:0') tensor(1698.7203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(89.9746, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2958.3115, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.6826, device='cuda:0') tensor(3671.1802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(90.1364, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4508.4673, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.7986, device='cuda:0') tensor(1671.2656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(90.3550, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1743.6093, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.7891, device='cuda:0') tensor(6451.7095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2220 | 78.99 ms/step | loss 6451.709 \n",
      "param_tail torch.Size([3712, 8]) tensor(90.5390, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5452.2612, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.4841, device='cuda:0') tensor(4000.1145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(90.6890, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3541.3833, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.5908, device='cuda:0') tensor(2454.1621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(90.8630, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1907.4170, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.7793, device='cuda:0') tensor(5204.9575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(90.9634, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5582.0488, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.9998, device='cuda:0') tensor(2959.9766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(91.0192, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3342.4441, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.9673, device='cuda:0') tensor(4854.3081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(91.1817, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(750.8014, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.9602, device='cuda:0') tensor(11022.4180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(91.3454, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6038.8428, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.9180, device='cuda:0') tensor(4444.5889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(91.3999, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(202.3563, device='cuda:0', grad_fn=<MaxBackward1>) tensor(946.6456, device='cuda:0') tensor(1282.5275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(91.5821, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3341.6982, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.3081, device='cuda:0') tensor(1776.7633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(91.6854, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2348.1821, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2611.1589, device='cuda:0') tensor(2848.8030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2230 | 62.44 ms/step | loss 2848.803 \n",
      "param_tail torch.Size([4096, 8]) tensor(91.8369, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(10662.4404, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.6777, device='cuda:0') tensor(4401.3101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(91.8847, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1651.0912, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.9143, device='cuda:0') tensor(6350.9258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(91.9643, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5252.4268, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.2646, device='cuda:0') tensor(2229.2239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(92.1288, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5328.3892, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3415.8779, device='cuda:0') tensor(4872.6548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(92.1160, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5131.5986, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.0020, device='cuda:0') tensor(2183.5767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(92.1164, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8397.9795, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.4297, device='cuda:0') tensor(4110.8057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(92.0846, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2223.0286, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.2429, device='cuda:0') tensor(1828.5756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(92.1477, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4980.5615, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.7366, device='cuda:0') tensor(2505.1682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(92.1814, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6195.9248, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.7822, device='cuda:0') tensor(1962.4744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(92.1692, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(991.1611, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1995.8052, device='cuda:0') tensor(2075.6118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2240 | 79.93 ms/step | loss 2075.612 \n",
      "param_tail torch.Size([3712, 8]) tensor(92.3099, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3623.2710, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.3916, device='cuda:0') tensor(2511.7214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(92.4600, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4297.0898, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.8352, device='cuda:0') tensor(4398.1855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(92.5399, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4959.8110, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.3257, device='cuda:0') tensor(4085.4009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(92.6570, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3398.6841, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.0244, device='cuda:0') tensor(1588.7334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(92.8654, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9215.4307, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.7085, device='cuda:0') tensor(2818.6348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(92.9300, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3054.7573, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2258.6443, device='cuda:0') tensor(1989.3712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(93.0032, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5080.5425, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.5947, device='cuda:0') tensor(13175.7734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(93.1568, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5964.1226, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.1582, device='cuda:0') tensor(2008.2476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(93.3450, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1801.0471, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.0725, device='cuda:0') tensor(4207.5630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(93.5470, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4061.6616, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.4155, device='cuda:0') tensor(6854.8706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2250 | 62.90 ms/step | loss 6854.871 \n",
      "param_tail torch.Size([4096, 8]) tensor(93.8183, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4362.9648, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1196, device='cuda:0') tensor(2588.5825, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(94.0011, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1145.9359, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1328.0022, device='cuda:0') tensor(2163.0608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(94.1936, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4499.2441, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.3667, device='cuda:0') tensor(1584.7201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(94.4543, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4388.1704, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4869.9663, device='cuda:0') tensor(1840.3871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(94.7365, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3057.7817, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.4089, device='cuda:0') tensor(11008.4668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(95.0034, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4223.5088, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.0537, device='cuda:0') tensor(1942.5253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(95.1765, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3651.7512, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.8320, device='cuda:0') tensor(3398.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(95.5328, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7370.5132, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1279, device='cuda:0') tensor(2673.1587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(95.6877, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3057.9312, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.8516, device='cuda:0') tensor(4660.5664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(96.0251, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4395.9062, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3419.3708, device='cuda:0') tensor(1770.4609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2260 | 78.24 ms/step | loss 1770.461 \n",
      "param_tail torch.Size([3712, 8]) tensor(96.3101, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(575.6015, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1994.3013, device='cuda:0') tensor(2061.4604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(96.5779, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(595.3532, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.9949, device='cuda:0') tensor(2821.3894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(96.8860, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3444.4995, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.5061, device='cuda:0') tensor(1949.3313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(97.2080, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6200.4219, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.9312, device='cuda:0') tensor(3198.4749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(97.4717, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2304.9175, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1993.4062, device='cuda:0') tensor(1904.2750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(97.6254, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4771.4688, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.6167, device='cuda:0') tensor(6324.1748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(97.7740, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5316.3096, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.9807, device='cuda:0') tensor(9633.5342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(97.9299, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1035.3962, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1328.9481, device='cuda:0') tensor(1406.9032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(98.1443, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3580.4326, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.2209, device='cuda:0') tensor(3256.4429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(98.2378, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5639.4121, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4829, device='cuda:0') tensor(3479.9141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2270 | 75.90 ms/step | loss 3479.914 \n",
      "param_tail torch.Size([4096, 8]) tensor(98.3980, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4251.1719, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.1863, device='cuda:0') tensor(2061.4685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(98.6611, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5221.1206, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.3149, device='cuda:0') tensor(1857.3032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(98.8307, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2930.9756, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.3889, device='cuda:0') tensor(1674.5800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(99.0437, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3624.3955, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3121.5681, device='cuda:0') tensor(1686.3384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(99.1726, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3172.1106, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.6904, device='cuda:0') tensor(4456.8984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(99.3321, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(675.0474, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1154.1782, device='cuda:0') tensor(2390.5859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(99.3713, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8597.0039, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.4146, device='cuda:0') tensor(6986.5269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(99.7127, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3208.8936, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.3154, device='cuda:0') tensor(2111.8286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(99.7705, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8979.9697, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.9756, device='cuda:0') tensor(2769.4463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(99.8045, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5056.1758, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.7500, device='cuda:0') tensor(2029.1779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2280 | 70.44 ms/step | loss 2029.178 \n",
      "param_tail torch.Size([3712, 8]) tensor(99.8158, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5110.8960, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.6543, device='cuda:0') tensor(2062.3684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(99.7907, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6443.3418, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.1704, device='cuda:0') tensor(3368.5476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(99.7909, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3704.3481, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.3489, device='cuda:0') tensor(1766.5688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(99.8997, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1986.4666, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.2676, device='cuda:0') tensor(1397.8201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(99.9610, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(924.7891, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1329.4261, device='cuda:0') tensor(1509.0571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(100.0985, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5127.2969, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.4541, device='cuda:0') tensor(2791.6362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(100.1121, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3156.6665, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.2129, device='cuda:0') tensor(6642.4834, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(100.2533, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(516.2178, device='cuda:0', grad_fn=<MaxBackward1>) tensor(699.1239, device='cuda:0') tensor(1400.2495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(100.3176, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1247.9653, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2039.5477, device='cuda:0') tensor(1643.0887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(100.5575, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5412.8345, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.9463, device='cuda:0') tensor(2465.0449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2290 | 77.62 ms/step | loss 2465.045 \n",
      "param_tail torch.Size([4096, 8]) tensor(100.7968, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1090.4463, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1327.4958, device='cuda:0') tensor(2018.2312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(101.0408, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(989.1655, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.7561, device='cuda:0') tensor(10723.2305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(101.2089, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5243.1006, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.3887, device='cuda:0') tensor(2665.9087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(101.3283, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3314.8911, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.5347, device='cuda:0') tensor(2131.4634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(101.4135, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2307., device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.8677, device='cuda:0') tensor(5487.8301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(101.5465, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2449.5959, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9883, device='cuda:0') tensor(13948.4229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(101.7856, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(220.9416, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1152.0240, device='cuda:0') tensor(1472.8818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(101.8589, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9516.0078, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.6201, device='cuda:0') tensor(10690.0107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(101.9701, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(619.9384, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1173.2124, device='cuda:0') tensor(1311.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(102.1252, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3997.5684, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.1274, device='cuda:0') tensor(2196.0393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2300 | 82.36 ms/step | loss 2196.039 \n",
      "param_tail torch.Size([3712, 8]) tensor(102.2177, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4996.4824, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.9875, device='cuda:0') tensor(5491.2275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(102.4750, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4935.5332, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.4946, device='cuda:0') tensor(1938.2091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(102.4785, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8621.5078, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.8540, device='cuda:0') tensor(3135.9399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(102.4701, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1228.1017, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.3760, device='cuda:0') tensor(1953.1560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(102.4646, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3833.8379, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.6328, device='cuda:0') tensor(4304.2383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(102.5508, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2430.7908, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9111, device='cuda:0') tensor(11795.1289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(102.7813, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1803.6857, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2258.4792, device='cuda:0') tensor(3124.1812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(102.8174, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5072.4082, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.4038, device='cuda:0') tensor(1732.4194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(103.1063, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4109.2202, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.3799, device='cuda:0') tensor(1605.4227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(103.2367, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8674.3936, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.4639, device='cuda:0') tensor(3600.4414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2310 | 66.55 ms/step | loss 3600.441 \n",
      "param_tail torch.Size([4096, 8]) tensor(103.2993, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4629.9756, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.9158, device='cuda:0') tensor(1986.1404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(103.3051, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1997.3418, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.4719, device='cuda:0') tensor(3275.1079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(103.3938, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4444.4170, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.2700, device='cuda:0') tensor(1667.8130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(103.4392, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8579.7871, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.7280, device='cuda:0') tensor(2342.2646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(103.4442, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5549.1392, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.7935, device='cuda:0') tensor(1690.1331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(103.4627, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4439.8486, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.2815, device='cuda:0') tensor(2028.9521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(103.4948, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(712.3262, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1992.6929, device='cuda:0') tensor(2117.4446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(103.5322, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4285.3135, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.5137, device='cuda:0') tensor(2526.0271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(103.5855, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4542.4238, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.5803, device='cuda:0') tensor(2808.7104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(103.5956, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4488.7646, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.4912, device='cuda:0') tensor(2418.5723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2320 | 87.14 ms/step | loss 2418.572 \n",
      "param_tail torch.Size([3712, 8]) tensor(103.5901, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2543.1101, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.5928, device='cuda:0') tensor(5302.2510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(103.6595, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5142.7090, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.0308, device='cuda:0') tensor(4753.3989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(103.6646, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2812.9209, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.3425, device='cuda:0') tensor(1474.6752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(103.7952, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4532.7314, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.6658, device='cuda:0') tensor(3011.3110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(104.0287, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2264.6606, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2256.9229, device='cuda:0') tensor(1915.3391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(104.1492, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3049.6155, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.2017, device='cuda:0') tensor(10489.2812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(104.2671, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5001.2866, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.7512, device='cuda:0') tensor(2494.4565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(104.4461, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4124.5757, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.1611, device='cuda:0') tensor(2597.4121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(104.5774, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(846.8834, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1174.0155, device='cuda:0') tensor(1683.4420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(104.6384, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5062.6006, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3416.9255, device='cuda:0') tensor(1881.5671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2330 | 71.15 ms/step | loss 1881.567 \n",
      "param_tail torch.Size([4096, 8]) tensor(104.7883, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4087.4590, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.5215, device='cuda:0') tensor(7386.8379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(104.8858, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4152.9434, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.8296, device='cuda:0') tensor(2009.9839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(105.1045, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1640.9233, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2259.1814, device='cuda:0') tensor(1291.0634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(105.2353, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2077.7297, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.5093, device='cuda:0') tensor(10492.4707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(105.4220, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3927.8169, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.4766, device='cuda:0') tensor(1414.0044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(105.7268, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4240.3350, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.1406, device='cuda:0') tensor(4102.0918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(105.8321, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2802.6040, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.3564, device='cuda:0') tensor(1642.6210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(106.1085, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4607.1743, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.8877, device='cuda:0') tensor(2059.1401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(106.1928, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(782.4366, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1174.3411, device='cuda:0') tensor(1584.7227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(106.6135, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6908.4717, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.2573, device='cuda:0') tensor(4982.3613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2340 | 120.53 ms/step | loss 4982.361 \n",
      "param_tail torch.Size([3712, 8]) tensor(106.7635, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4493.6982, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.6406, device='cuda:0') tensor(2692.8943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(106.9965, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5332.7378, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.4297, device='cuda:0') tensor(4482.8071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(107.2215, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2939.8223, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9082, device='cuda:0') tensor(4295.6318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(107.4783, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4318.9976, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.4282, device='cuda:0') tensor(6685.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(107.6390, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2590.8413, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.8350, device='cuda:0') tensor(1436.5903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(107.9438, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2681.1890, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.0820, device='cuda:0') tensor(3759.2429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(108.2082, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4725.5635, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.1897, device='cuda:0') tensor(2554.1372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(108.2731, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2440.8711, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.9102, device='cuda:0') tensor(4384.6577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(108.6211, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6066.1396, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.9172, device='cuda:0') tensor(2526.9094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(108.8359, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1040.3438, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1173.5585, device='cuda:0') tensor(1717.9211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2350 | 89.88 ms/step | loss 1717.921 \n",
      "param_tail torch.Size([4096, 8]) tensor(109.0563, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4259.0601, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.4736, device='cuda:0') tensor(2098.1565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(109.2559, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5893.1372, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.6875, device='cuda:0') tensor(3155.8633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(109.3339, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3800.0535, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.7473, device='cuda:0') tensor(12047.9111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(109.3672, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1429.6620, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1329.3573, device='cuda:0') tensor(1678.6465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(109.5495, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5136.6313, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.4478, device='cuda:0') tensor(1554.2661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(109.7328, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3979.1030, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.5850, device='cuda:0') tensor(4260.9932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(109.9749, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2565.6201, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.7839, device='cuda:0') tensor(3825.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(110.1345, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(732.6893, device='cuda:0', grad_fn=<MaxBackward1>) tensor(947.2776, device='cuda:0') tensor(1836.8450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(110.3386, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3341.7939, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.6875, device='cuda:0') tensor(6872.3652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(110.6651, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1695.4993, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2257.6609, device='cuda:0') tensor(2782.9973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2360 | 73.28 ms/step | loss 2782.997 \n",
      "param_tail torch.Size([3712, 8]) tensor(110.9330, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7894.0479, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.4458, device='cuda:0') tensor(4945.7832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.1143, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5214.3594, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.0967, device='cuda:0') tensor(5676.1333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.1190, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2940.9316, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.5439, device='cuda:0') tensor(5457.0239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.2641, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1995.3157, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2608.3635, device='cuda:0') tensor(4090.7585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(111.1875, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1464.0723, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9766, device='cuda:0') tensor(18658.0684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.3373, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5668.1587, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.7266, device='cuda:0') tensor(2731.8120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.3051, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9953.1660, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1270, device='cuda:0') tensor(4537.2100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.4773, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(6197.7925, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.1523, device='cuda:0') tensor(2886.3118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(111.4138, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1532.1068, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.2268, device='cuda:0') tensor(12979.3584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.3210, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2242.9041, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4039.9580, device='cuda:0') tensor(8455.7393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2370 | 79.96 ms/step | loss 8455.739 \n",
      "param_tail torch.Size([4096, 8]) tensor(111.4299, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5606.4209, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3415.9780, device='cuda:0') tensor(3772.0879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.4212, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1010.2031, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1993.8707, device='cuda:0') tensor(2283.0542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(111.3444, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5635.4746, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.1230, device='cuda:0') tensor(3063.9692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.4022, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5828.3633, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.5786, device='cuda:0') tensor(12016.3154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.3735, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1085.9299, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1328.6365, device='cuda:0') tensor(1500.0907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.4004, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1594.8282, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1556.8181, device='cuda:0') tensor(2006.5901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(111.4968, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5024.9121, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.0337, device='cuda:0') tensor(2518.5652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.5462, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2508.1135, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.6421, device='cuda:0') tensor(3333.5752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.7038, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4542.3237, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3419.5000, device='cuda:0') tensor(3052.8618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.7175, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5105.5986, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6210.3276, device='cuda:0') tensor(7958.0386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2380 | 80.34 ms/step | loss 7958.039 \n",
      "param_tail torch.Size([3712, 8]) tensor(111.7910, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(479.6314, device='cuda:0', grad_fn=<MaxBackward1>) tensor(752.1754, device='cuda:0') tensor(1524.7477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.8145, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5031.0786, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9185, device='cuda:0') tensor(11061.8086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.7814, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(852.2532, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.0632, device='cuda:0') tensor(3055.1421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.8409, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5174.4951, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.5884, device='cuda:0') tensor(3280.4983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(111.7337, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(26.1028, device='cuda:0', grad_fn=<MaxBackward1>) tensor(248.0075, device='cuda:0') tensor(1424.5781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.6454, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4744.4185, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.1670, device='cuda:0') tensor(10663.2119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.6701, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5849.7588, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4870.7476, device='cuda:0') tensor(2504.3687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.5637, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(776.6289, device='cuda:0', grad_fn=<MaxBackward1>) tensor(750.1125, device='cuda:0') tensor(1689.3533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(111.5807, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3581.3271, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.6040, device='cuda:0') tensor(2519.6934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.5691, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5452.6382, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4873.3018, device='cuda:0') tensor(2019.7036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2390 | 65.67 ms/step | loss 2019.704 \n",
      "param_tail torch.Size([4096, 8]) tensor(111.5924, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5410.8496, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.0217, device='cuda:0') tensor(1869.4427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.5532, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2947.1602, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3419.4070, device='cuda:0') tensor(6588.6426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(111.5489, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8301.6113, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.9727, device='cuda:0') tensor(2804.1848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.5348, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8094.3149, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6212.5283, device='cuda:0') tensor(2336.6519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.4940, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4433.0439, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3122.7710, device='cuda:0') tensor(2810.4531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.2618, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2747.5186, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.4338, device='cuda:0') tensor(2282.0085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(111.2944, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4575.3291, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3417.4768, device='cuda:0') tensor(2054.2651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.2879, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1032.2104, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.9863, device='cuda:0') tensor(2152.7876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.1049, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7533.5537, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6214.1162, device='cuda:0') tensor(1857.4580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.0130, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5340.8906, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4874.8926, device='cuda:0') tensor(2994.9214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2400 | 85.96 ms/step | loss 2994.921 \n",
      "param_tail torch.Size([3712, 8]) tensor(110.9207, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4775.9805, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.2327, device='cuda:0') tensor(3359.3906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "checking 599\n",
      "(16000, 2) torch.Size([16000, 2]) 37.88164171162481 aloha\n",
      "param_tail torch.Size([4096, 8]) tensor(110.7767, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3084.9226, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.0088, device='cuda:0') tensor(9357.7031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(110.7052, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5021.8091, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.6021, device='cuda:0') tensor(2288.6243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(110.7377, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1771.6777, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.1797, device='cuda:0') tensor(7015.8789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(110.6094, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(238.1618, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1327.2889, device='cuda:0') tensor(2011.4113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(110.5320, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7227.0801, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.7764, device='cuda:0') tensor(2214.5417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(110.5028, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3136.6406, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2609.1399, device='cuda:0') tensor(1836.8708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(110.3937, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1248.0452, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4041.2939, device='cuda:0') tensor(11641.7490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(110.3299, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3646.2070, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.9370, device='cuda:0') tensor(4555.2437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(110.3187, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1920.5448, device='cuda:0', grad_fn=<MaxBackward1>) tensor(1559.2064, device='cuda:0') tensor(1687.4551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2410 | 233.58 ms/step | loss 1687.455 \n",
      "param_tail torch.Size([4096, 8]) tensor(110.3996, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(5103.2598, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4040.6289, device='cuda:0') tensor(3330.4839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(110.4042, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(565.8099, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.4282, device='cuda:0') tensor(4962.5996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(110.4742, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8165.9136, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.5337, device='cuda:0') tensor(4158.5103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(110.6278, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4505.1689, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.4565, device='cuda:0') tensor(2412.5056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(110.6303, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3918.5012, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3120.4878, device='cuda:0') tensor(2017.3654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(110.6968, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3947.7180, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3418.3301, device='cuda:0') tensor(1497.8589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(110.8386, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3941.4976, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.5347, device='cuda:0') tensor(10676.3057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(110.7624, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3699.2175, device='cuda:0', grad_fn=<MaxBackward1>) tensor(3119.8149, device='cuda:0') tensor(1908.4973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(110.9153, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(1400.2917, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6211.7090, device='cuda:0') tensor(16313.3418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.0059, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4519.0776, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4871.9595, device='cuda:0') tensor(10126.9414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "| iter   2420 | 85.49 ms/step | loss 10126.941 \n",
      "param_tail torch.Size([3712, 8]) tensor(111.0773, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3343.0918, device='cuda:0', grad_fn=<MaxBackward1>) tensor(2610.4285, device='cuda:0') tensor(1601.7987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.2879, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2983.6716, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4042.0623, device='cuda:0') tensor(4940.6328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.3653, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4329.8730, device='cuda:0', grad_fn=<MaxBackward1>) tensor(4872.1973, device='cuda:0') tensor(4051.6997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([4096, 8]) tensor(111.6469, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(8090.1895, device='cuda:0', grad_fn=<MaxBackward1>) tensor(6213.2729, device='cuda:0') tensor(2519.9138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "param_tail torch.Size([3712, 8]) tensor(111.7978, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(150.0953, device='cuda:0', grad_fn=<MaxBackward1>) tensor(699.8488, device='cuda:0') "
     ]
    }
   ],
   "source": [
    "\n",
    "# train\n",
    "start_time = time.time()\n",
    "min_loss=9999999999\n",
    "\n",
    "for iI in range(iterations):\n",
    "    loss_epoch=0\n",
    "    for data in train_loader:\n",
    "        optim.zero_grad()\n",
    "        optim2.zero_grad()\n",
    "\n",
    "        x_1=data[0].float().to(device)   #batch x 20\n",
    "        x_0 = torch.randn_like(x_1).float().to(device) #batch x 20\n",
    "\n",
    "        # print(\"x_shape\",x_0.shape,x_1.shape,x_1.mean())\n",
    "\n",
    "        if iI<(3*iterations)//4:\n",
    "            t = 1-torch.sqrt(1-torch.rand(x_1.shape[0])).to(device) #best\n",
    "        else:\n",
    "            t= -torch.log(1 - torch.rand(x_1.shape[0]) * (1 - torch.exp(torch.tensor(-1)))).to(device)\n",
    "\n",
    "        path_sample = path.sample(t=t, x_0=x_0, x_1=x_1)\n",
    "        x_t,time_t,dx_t=path_sample.x_t,path_sample.t,path_sample.dx_t  #x_t- B X 20\n",
    "        # print(\"x_t\",x_t.shape)\n",
    "        if approach==1:\n",
    "            if option_model=='simplemodel':\n",
    "                prefinal_vf=model(x_t,time_t)\n",
    "            else:\n",
    "                prefinal_vf=model(x_t.unsqueeze(1),time_t,extra=[])  #B X 1 X 20\n",
    "            # print(prefinal_vf.shape)\n",
    "            prefinal_vf=prefinal_vf.reshape(prefinal_vf.shape[0],-1) #B X 20\n",
    "        # print(\"hello\",prefinal_vf.shape)\n",
    "\n",
    "        ones=torch.zeros(x_t.shape).to(device)+time_t.unsqueeze(1) #B X 20\n",
    "        # print(\"ones\",ones.shape,time_t.shape)\n",
    "\n",
    "        if approach==2:\n",
    "            if option=='simpletail':\n",
    "                param_tail=Tail_paramNet(time_t.unsqueeze(1)) #BX80\n",
    "\n",
    "                True_timederiv=get_t_dir(dim,noise2data,Tail_paramNet,x_t,time_t)\n",
    "                param_grad=True_timederiv[1] #time derive\n",
    "                # print(\"PARAM---\",param_grad.min(),param_grad.max())\n",
    "                # print(time_t.shape,True_timederiv[0].shape,True_timederiv[1].shape,param_tail.shape,param_grad.shape,\"hallelja\")\n",
    "            else:\n",
    "                param_tail=Tail_paramNet(ones.unsqueeze(1),time_t,extra=[])  # B X 4 X 20 Generating Parameters of Tail net for each time step\n",
    "\n",
    "            print(\"param_tail\",param_tail.shape,param_tail.max())\n",
    "            param_tail=param_tail.reshape(param_tail.shape[0],-1)\n",
    "            param_tail_pre_eps=param_tail\n",
    "\n",
    "\n",
    "            phi_t=noise2data.inverse(x_t,param_tail,False,None,None)  #phi_t(x_0)  B X 20\n",
    "            # print(\"phi_t\",phi_t.shape,param_tail.shape) #BATCH X 2\n",
    "            # print(a)\n",
    "\n",
    "             \n",
    "            if option_model=='simplemodel':\n",
    "                prefinal_vf=model(phi_t,time_t)\n",
    "            else:\n",
    "                prefinal_vf=model(phi_t,time_t,extra=[])  #B X 1 X 20\n",
    "            # print(prefinal_vf.shape)\n",
    "            prefinal_vf=prefinal_vf.reshape(prefinal_vf.shape[0],-1) #B X 20        \n",
    "\n",
    "            jacobian_phi=noise2data.fwd_dTTF_dz(phi_t, param_tail) #B X 20 X 20\n",
    "            # print(\"jac_phi\",jacobian_phi.shape)\n",
    "            jacobian_param_tail=(noise2data.dTTF_dtailparam(phi_t, param_tail)) #list of 4  ,BX20\n",
    "            # print(jacobian_param_tail[0].shape,\"JPT0\")\n",
    "\n",
    "\n",
    "            '''\n",
    "            epsilon=1e-4\n",
    "            if option=='simpletail':\n",
    "                param_tail_eps=Tail_paramNet(time_t.unsqueeze(1)+epsilon) \n",
    "            else:\n",
    "                param_tail_eps=Tail_paramNet(ones.unsqueeze(1)+epsilon,time_t+epsilon,extra=[])\n",
    "            param_tail_eps=param_tail_eps.reshape(param_tail_eps.shape[0],-1)\n",
    "            # print(\"param_tail_pre_eps and param_tail_ems\",param_tail_pre_eps.shape,param_tail_eps.shape)\n",
    "\n",
    "            dummy_tail_param=param_tail_pre_eps.reshape(param_tail_pre_eps.shape[0],4,dimension)\n",
    "            _unc_pos_tail,_unc_neg_tail,shift,_unc_scale =dummy_tail_param[:,0,:],dummy_tail_param[:,1,:],dummy_tail_param[:,2,:],dummy_tail_param[:,3,:]\n",
    "            '''\n",
    "\n",
    "\n",
    "            # _unc_pos_tail,_unc_neg_tail,shift,_unc_scale, = param_tail_pre_eps[:,0:dimx],param_tail_pre_eps[:,dimx:2*dimx],param_tail_pre_eps[:,2*dimx:3*dimx],param_tail_pre_eps[:,3*dimx:4*dimx]\n",
    "            # _unc_pos_tail2,_unc_neg_tail2,shift2,_unc_scale2, = param_tail_eps[:,0:dimx],param_tail_eps[:,dimx:2*dimx],param_tail_eps[:,2*dimx:3*dimx],param_tail_eps[:,3*dimx:4*dimx]\n",
    "\n",
    "            '''\n",
    "            dummy_tail_param2=param_tail_eps.reshape(param_tail_eps.shape[0],4,dimension)\n",
    "            _unc_pos_tail2,_unc_neg_tail2,shift2,_unc_scale2, = dummy_tail_param2[:,0,:],dummy_tail_param2[:,1,:],dummy_tail_param2[:,2,:],dummy_tail_param2[:,3,:]\n",
    "\n",
    "            D1=(noise2data.pos_tail(_unc_pos_tail2)-noise2data.pos_tail(_unc_pos_tail))/epsilon\n",
    "            D2=(noise2data.neg_tail(_unc_neg_tail2)-noise2data.neg_tail(_unc_neg_tail))/epsilon\n",
    "            D3=(shift2-shift)/epsilon\n",
    "            D4=(noise2data.scale(_unc_scale2)-noise2data.scale(_unc_scale))/epsilon\n",
    "\n",
    "            param_grad=torch.cat([D1,D2,D3,D4],1) \n",
    "            '''\n",
    "\n",
    "            # print(\"Param_grad\",param_grad.shape) #BX80\n",
    "            first_part=param_grad[:,0:dim]*jacobian_param_tail[0]+param_grad[:,dim:2*dim]*jacobian_param_tail[1]+param_grad[:,2*dim:3*dim]*jacobian_param_tail[2]+param_grad[:,3*dim:4*dim]*jacobian_param_tail[3]\n",
    "            second_part=torch.bmm(jacobian_phi,prefinal_vf.unsqueeze(2)).squeeze(2)\n",
    "            # velocity_field=torch.bmm(jacobian_param_tail,param_grad)+torch.bmm(jacobian_phi,prefinal_vf.unsqueeze(2))\n",
    "            # print(first_part.shape,second_part.shape)\n",
    "            velocity_field=first_part+second_part\n",
    "        else:\n",
    "            velocity_field=prefinal_vf\n",
    "\n",
    "        \n",
    "        loss = torch.pow( velocity_field - dx_t, 2).mean()#/(0.001+torch.abs(dx_t.max()))# remove the max division for math correct\n",
    "        \n",
    "        print(velocity_field.max(),dx_t.max(),loss)\n",
    "\n",
    "        loss_scaler(\n",
    "            loss,\n",
    "            optim,\n",
    "            optim2,\n",
    "            parameters=model.parameters(),\n",
    "            parameters2=Tail_paramNet.parameters(),\n",
    "            update_grad=True,\n",
    "            approach=approach\n",
    "            )      \n",
    "        # scheduler.step()\n",
    "        # scheduler2.step()\n",
    "\n",
    "    # log loss\n",
    "        jo=jo+1\n",
    "        if (jo+1) % print_every == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| iter {:6d} | {:5.2f} ms/step | loss {:8.3f} '\n",
    "                .format(jo+1, elapsed*1000/print_every, loss.item()))\n",
    "            start_time = time.time()\n",
    "    if (iI+1)%50==0: \n",
    "        print(\"checking\",iI)   \n",
    "        model.eval()\n",
    "        Tail_paramNet.eval()\n",
    "        loss_epoch=calc_Wassertein(model,Tail_paramNet,noise2data,full_data_val,dimension)\n",
    "        if loss_epoch<min_loss:\n",
    "            min_loss=loss_epoch\n",
    "            print(\"saving iteration-\",iI)\n",
    "            torch.save(Tail_paramNet.state_dict(), 'tailmodel_NEW.pth')\n",
    "            torch.save(model.state_dict(),\"model_NEW.pth\")\n",
    "            model.train()\n",
    "            Tail_paramNet.train()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tail_paramNet.load_state_dict(torch.load('tailmodel_NEW.pth'))\n",
    "model.load_state_dict(torch.load(\"model_NEW.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10479957477009223\n"
     ]
    }
   ],
   "source": [
    "print(min_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP_TailParam2(\n",
       "  (main): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=64, bias=True)\n",
       "    (1): Swish()\n",
       "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (3): Swish()\n",
       "    (4): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (5): Swish()\n",
       "    (6): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (7): Swish()\n",
       "    (8): Linear(in_features=8, out_features=80, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "Tail_paramNet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(Tail_paramNet.state_dict(), 'tailmodelv3.pth')\n",
    "# torch.save(vf.state_dict(),\"modelv3.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Combo=combined(Tail_paramNet,model,noise2data)\n",
    "# print(a)\n",
    "class WrappedModel(ModelWrapper):\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor, **extras):\n",
    "        return self.model(x, t)\n",
    "\n",
    "# print(a)\n",
    "wrapped_vf = WrappedModel(Combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5832,  0.7807,  0.7220,  0.8736,  0.4692,  1.1462,  0.6698,  0.9992,\n",
       "          1.0199,  0.8344, -1.0664, -0.6937, -1.1529, -0.4770, -0.8559, -0.8295,\n",
       "         -0.8502, -1.4535, -1.4239, -2.4777]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(wrapped_vf.parameters())\n",
    "a,b=torch.rand(1,dimension),torch.rand(1)\n",
    "# print(z)\n",
    "# Tail_paramNet(b.unsqueeze(1).to(device))\n",
    "Combo(a.to(device),b.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step size for ode solver\n",
    "step_size = 0.05\n",
    "\n",
    "norm = cm.colors.Normalize(vmax=50, vmin=0)\n",
    "\n",
    "batch_size = full_data_test.shape[0]  # batch size\n",
    "eps_time = 1e-2\n",
    "T = torch.linspace(0,1,10)  # sample times\n",
    "T = T.to(device=device)\n",
    "# print(a)\n",
    "\n",
    "x_init = torch.randn((batch_size, dimension), dtype=torch.float32, device=device)\n",
    "solver = ODESolver(velocity_model=wrapped_vf)  # create an ODESolver class\n",
    "sol = solver.sample(time_grid=T, x_init=x_init, method='midpoint', step_size=step_size, return_intermediates=True)  # sample from the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sol)\n",
    "# sol[0,:,0]=x_tst\n",
    "x_tst=full_data_test\n",
    "\n",
    "\n",
    "sol = sol.cpu().numpy()\n",
    "T = T.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 11 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "RR=x_lim\n",
    "fig, axs = plt.subplots(1, 11,figsize=(20,20))\n",
    "\n",
    "for i in range(11):\n",
    "    # if i==10:\n",
    "    #     H = axs[i].hist2d(x_tst[:,0], x_tst[:,1], 300, range=((-1*RR,RR), (-1*RR,RR)), norm=norm)\n",
    "    # else:\n",
    "    #     H= axs[i].hist2d(sol[i,:,0], sol[i,:,1], 300, range=((-1*RR,RR), (-1*RR,RR)), norm=norm)\n",
    "\n",
    "    cmin = 0.0\n",
    "    cmax = 0.99#torch.quantile(torch.from_numpy(H[0]), 0.99).item()\n",
    "\n",
    "    norm = cm.colors.Normalize(vmax=cmax, vmin=cmin)\n",
    "    if i==10:\n",
    "        _ = axs[i].hist2d(x_tst[:,0], x_tst[:,1], 300, range=((-1*RR,RR), (-1*RR,RR)), norm=norm)\n",
    "    else:\n",
    "        _ = axs[i].hist2d(sol[i,:,0], sol[i,:,1], 300, range=((-1*RR,RR), (-1*RR,RR)), norm=norm)\n",
    "\n",
    "    axs[i].set_aspect('equal')\n",
    "    axs[i].axis('off')\n",
    "    if i==10:\n",
    "        axs[i].set_title('Target')\n",
    "    else:\n",
    "\n",
    "        axs[i].set_title('t= %.2f' % (T[i]))\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.text(0.5, 0.45, 'Time Var. Velocity ', ha='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_test\n",
    "generated_data=sol[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_22116\\405170638.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_1=torch.tensor(x_tst)[0:1000,:].to(device).float()\n"
     ]
    }
   ],
   "source": [
    "# sample with likelihood\n",
    "\n",
    "T = torch.tensor([1., 0.])  # sample times\n",
    "T = T.to(device=device)\n",
    "\n",
    "# grid_size = 200\n",
    "# x_1 = torch.meshgrid(torch.linspace(-60, 60, grid_size), torch.linspace(-60, 60, grid_size))\n",
    "# x_1 = torch.stack([x_1[0].flatten(), x_1[1].flatten()], dim=1).to(device)\n",
    "x_1=torch.tensor(x_tst)[0:1000,:].to(device).float()\n",
    "print(x_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(full_data_test[:,0],full_data_test[:,1])\n",
    "plt.ylim((-1*y_lim,y_lim))\n",
    "plt.xlim((-x_lim,x_lim))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "full_data_test.max()\n",
    "plt.hist(full_data_test[:,0],density=True,bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGiCAYAAAASgEe5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAtwUlEQVR4nO3df3BU9b3/8dcGkg0BsiHkxwYbMICCiKJwJUaFEU0haKlUL6O2Wuh1sMWAF4JVUhWMikHwqq1FsE4Fe52q9TtftVjlW0RBW4NUNKUB4QINhh/ZQInZhSgbSM73D25W1vwgIbt78tl9PmbOTPfsJ7vvw5rsq+fzy2FZliUAAABDxdldAAAAQFcQZgAAgNEIMwAAwGiEGQAAYDTCDAAAMBphBgAAGI0wAwAAjEaYAQAARiPMAAAAoxFmAACA0cIaZkpLS3XZZZepb9++ysjI0NSpU7Vz586gNsePH1dhYaH69++vPn366KabblJNTU04ywIAAFEkrGFm48aNKiws1KZNm7Ru3TqdOHFCEydOVH19faDNvHnztGbNGr322mvauHGjDh48qBtvvDGcZQEAgCjiiORGk4cPH1ZGRoY2btyo8ePHy+v1Kj09Xb///e/17//+75KkHTt26IILLlBZWZkuv/zySJUGAAAM1TOSb+b1eiVJqampkqQtW7boxIkTys/PD7QZPny4Bg4c2GaY8fv98vv9gcdNTU2qra1V//795XA4wnwFAAAgFCzL0tGjRzVgwADFxXWtoyhiYaapqUlz587VlVdeqZEjR0qSPB6PEhISlJKSEtQ2MzNTHo+n1dcpLS1VSUlJuMsFAAARsG/fPn3nO9/p0mtELMwUFhaqoqJCf/nLX7r0OsXFxSoqKgo89nq9GjhwoPbt26fk5OSulgkAACLA5/MpOztbffv27fJrRSTMzJ49W2+99ZY++OCDoPTldrvV0NCgurq6oLszNTU1crvdrb6W0+mU0+lscT45OZkwAwCAYUIxRCSss5ksy9Ls2bP1+uuv67333lNOTk7Q82PGjFF8fLzWr18fOLdz505VVVUpLy8vnKUBAIAoEdY7M4WFhfr973+vN998U3379g2Mg3G5XOrVq5dcLpfuuOMOFRUVKTU1VcnJyZozZ47y8vKYyQQAADokrFOz27p1tGrVKs2YMUPSqUXz5s+fr5dffll+v1+TJk3Ss88+22Y307f5fD65XC55vV66mQAAMEQov78jus5MOBBmAAAwTyi/v9mbCQAAGI0wAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGI8wAAACjEWYAAIDRCDMAAMBohBkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKMRZgAAgNEIMwAAwGiEGQAAYDTCDAAAMBphBgAAGI0wAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGC2uY+eCDDzRlyhQNGDBADodDb7zxRtDzM2bMkMPhCDoKCgrCWRIAAIgyYQ0z9fX1GjVqlJYvX95mm4KCAlVXVweOl19+OZwlAQCAKNMznC8+efJkTZ48ud02TqdTbrc7nGUAAIAoZvuYmQ0bNigjI0PDhg3TrFmzdOTIkXbb+/1++Xy+oAMAAMQuW8NMQUGBfve732n9+vV6/PHHtXHjRk2ePFmNjY1t/kxpaalcLlfgyM7OjmDFAACgu3FYlmVF5I0cDr3++uuaOnVqm23++c9/asiQIXr33Xd17bXXttrG7/fL7/cHHvt8PmVnZ8vr9So5OTnUZQMAgDDw+XxyuVwh+f62vZvpdIMHD1ZaWpp2797dZhun06nk5OSgAwAAxK5uFWb279+vI0eOKCsry+5SAACAIcI6m+nYsWNBd1kqKytVXl6u1NRUpaamqqSkRDfddJPcbrf27Nmje++9V0OHDtWkSZPCWRYAAIgiYQ0zn3zyiSZMmBB4XFRUJEmaPn26VqxYoa1bt+rFF19UXV2dBgwYoIkTJ+qRRx6R0+kMZ1kAACCKRGwAcLiEcgARAACIjKgdAAwAANBZhBkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKMRZgAAgNEIMwAAwGiEGQAAYDTCDAAAMBphBgAAGI0wAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGI8wAAACjEWYAAIDRCDMAAMBohBkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKMRZgAAgNEIMwAAwGiEGQAAYDTCDAAAMFpYw8wHH3ygKVOmaMCAAXI4HHrjjTeCnrcsSwsXLlRWVpZ69eql/Px87dq1K5wlAQCAKBPWMFNfX69Ro0Zp+fLlrT6/dOlS/epXv9LKlSv18ccfq3fv3po0aZKOHz8ezrIAAEAU6RnOF588ebImT57c6nOWZenpp5/WAw88oBtuuEGS9Lvf/U6ZmZl64403dMstt4SzNAAAECVsGzNTWVkpj8ej/Pz8wDmXy6Xc3FyVlZW1+XN+v18+ny/oAAAAscu2MOPxeCRJmZmZQeczMzMDz7WmtLRULpcrcGRnZ4e1TgAA0L0ZN5upuLhYXq83cOzbt8/ukgAAgI1sCzNut1uSVFNTE3S+pqYm8FxrnE6nkpOTgw4AABC7bAszOTk5crvdWr9+feCcz+fTxx9/rLy8PLvKAgAAhgnrbKZjx45p9+7dgceVlZUqLy9XamqqBg4cqLlz5+rRRx/Veeedp5ycHD344IMaMGCApk6dGs6yAABAFAlrmPnkk080YcKEwOOioiJJ0vTp07V69Wrde++9qq+v15133qm6ujpdddVVWrt2rRITE8NZFgAAiCIOy7Isu4voCp/PJ5fLJa/Xy/gZAAAMEcrvb+NmMwEAAJyOMAMAAIxGmAEAAEYjzAAAAKMRZgAAgNEIMwAAwGiEGQAAYDTCDAAAMBphBgAAGI0wAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACM1tPuAgAgWjU2WdpcWatDR48ro2+ixuakqkecw+6ygKhDmAGAMFhbUa2SNdtV7T0eOJflStSiKSNUMDLLxsqA6EM3EwCE2NqKas166dOgICNJHu9xzXrpU62tqLapMiA6EWYAIIQamyyVrNkuq5Xnms+VrNmuxqbWWgA4G4QZAAihzZW1Le7InM6SVO09rs2VtZErCohyhBkACKFDR9sOMmfTDsCZEWYAIIQy+iaGtB2AMyPMAEAIjc1JVZYrUW1NwHbo1KymsTmpkSwLiGqEGQAIoR5xDi2aMkKSWgSa5seLpoxgvRkghAgzABBiBSOztOK20XK7gruS3K5ErbhtNOvMACHGonkAEAYFI7P03RFuba6slcf7tWrrG5TaxylXrwQ1NlncmQFCiDADAGHSI84h79cNWvr/drISMBBGdDMBQIg1Nlkq23NED6/Zpp+xEjAQdtyZAYCz0NYmkq3tyfRtlk4NBi5Zs13fHeGmywnoIsIMAHRSa4EltXeCLs12af2Owx16jdNXAs4b0j9MlQKxgTADAB3U2GTp1+/t1lPv/k+L52rrGzocZE7HSsBA1xFmAKAD1lZU66E/bpPH5w/p67ISMNB1hBkAOIO1FdWa9dKnre6E3RUpSfGsBAyEgO2zmR566CE5HI6gY/jw4XaXBQCSTnUtlazZHvIgI7VcIRjA2ekWd2YuvPBCvfvuu4HHPXt2i7IAxIC2ZiU121xZ2+7MpK748qsTDAAGQqBbpIaePXvK7XZ3qK3f75ff/02ftc/nC1dZAKJca7OSvr2gXbgH6DIAGOg627uZJGnXrl0aMGCABg8erB/96Eeqqqpqs21paalcLlfgyM7OjmClAKJF8ziYMy1oF+4BugwABrrO9jCTm5ur1atXa+3atVqxYoUqKys1btw4HT16tNX2xcXF8nq9gWPfvn0RrhiAKZpX4n2z/IDK9hxRY5MVON/WOJjmcyVrtqvhZJNOnmxSH2ePTr1vcydVUkLbP+fQqbtADAAGus5hWVY4xrWdtbq6Og0aNEhPPvmk7rjjjjO29/l8crlc8nq9Sk5OjkCFAEzQXheSq1eCbn1+0xlfo7ezh+r9jZ1+7+b3kaRZL30qSUHBqTnssIM2Ylkov7+7xZiZ06WkpOj888/X7t277S4FgKHamkrd3IU06cKOjdE7myDz4PUXaMaVOYFBxCtuG90iVLnZaBIIqW4XZo4dO6Y9e/bo9ttvt7sUAAbqSBfS2m2esL1/Wl9n0GyogpFZ+u4Id7szpgB0je1h5p577tGUKVM0aNAgHTx4UIsWLVKPHj1066232l0aAAOFcyp1R7Q2oLdHnCNk06/PNJUciEW2h5n9+/fr1ltv1ZEjR5Senq6rrrpKmzZtUnp6ut2lATCQXVOdHZIyk51qsiy9WX6g3aBxtoGkI1PJgVjU7QYAdxYDgAGcrmzPkQ4N7g2H3gk9VN/wzTib1oLG2QaStsYBMZgYpgrl97ftU7MBIJTGDOonu3pdTg8yUss1azq6ts23dXQqefPUcyDWEGYARJUtX3yp7vKdbv3vcf/rFfq6ofGsA8mZxgFZkqq9x7W5sjYEVQPmIcwAiCrdcXuAI/UNGvvYurMOJB29pu547UAkEGYARJW9//oqLK876juuLv380eMdW7OmtUDS0S0P2BoBsYowAyBqrK2o1tPv/k9YXntfbXhC0re1FkjG5qQqy5WotoYCsTUCYh1hBkBUaG+QbCjUfnUiTK98SnuBpEecI7A9wrcDTfPjRVNGsN4MYhZhBoDRmjeTfGrdTlsXy+uKjgSSgpFZWnHbaLldwXdu3K5EpmUj5tm+aB4AnK23t1brgTcrVFvfYHcpnZLaOyGo5o7u1cTWCEDrCDMAjLT4T9v1/IeVdpfRKQ6dCi4bfz5BW7748qwCSSi3RgCiBWEGgHEW/2mbnv9wr91ldJqlU11JCT3jCCRACDFmBoBR3t560MggI0mTR7rl6pXASr1AiHFnBoAxGpssPfBmhd1lnLV3Kjx6p8LD5pBAiHFnBoAxNlfWqrY+vFOkI+FMezEB6BzCDABjRMty/WwOCYQWYQaAMaJpuf729mJqXjvnzfIDKttzhMADnAFjZgAY48v6BsU51G12xQ6Fb99tWltRrZI124MWAGSMDdA+7swAMMLaimrd9ftPoyrISMF3m9ZWVGvWS5+2WMmYMTZA+wgzALq9xiZL8//wd7vLCKlv78XU3t5SjLEB2keYAdDtPbP+f1Tf0Gh3GSHT2l5Mmytr291bqr0xNkCsY8wMgG6tscnSbz78p91lhFRrezF1dKZWtMzoAkKJMAOg22pssrT6r5X6qqHJ7lJC4q6rh2jceemt7sXU0Zla0TSjCwgVwgyAbqm1WT0mc0iam3++Enq23rs/NidVWa5EebzHWx0307xJZfMYGwDfYMwMgG6nrVk9JrMkbfniyzaf7xHn0KIpIyR9M6amWWtjbAB8gzADoFtpbLK04P/+o9W7E6Y703iXgpFZWnHbaLldwV1JbleiVtw2mnVmgDbQzQSgW5n7yqeq+8r8/Zda05HxLgUjs/TdEW5trqzVoaPHldE3sdUxNgC+QZgB0G28vbVaa7Z67C4jLFJ7x3d4vEuPOIfyhvQPc0VA9KCbCUC30Nhk6YE3K+wuI2wevWEkd1eAMCHMAOgWNlfWqra+we4ywuKn43N03cUD7C4DiFp0MwHoFqrrvra7hJBLTuypJTderOsuZuAuEE6EGQC2W/ynbXr+w712lxFSqb3jtak4v811ZQCEDmEGgC0amyxtrqzV4j9tU8XBo3aXEzLNo2Ie+8FFBBkgQggzACIumlb3TUmKD5pK3tq+SwDCizADIGIamyz9+r1deurdXXaX0mVZ/xtaWBMGsB9hBkBYNHcjNX/Jf1nfoJK3tqnG57e7tC5xOKTfzRirK85LC4QW1oQB7EWYARASp4eXysPH9GLZXn351Um7ywq5O8flaNywdLvLAHCabhFmli9frmXLlsnj8WjUqFF65plnNHbsWLvLAtBB0TQGpi1xDmnmuBwVXzfC7lIAfIvtYebVV19VUVGRVq5cqdzcXD399NOaNGmSdu7cqYyMDLvLA3AGb2+t1l2//9TuMsIiMT5OuTmpGn9eum7PO5fZSUA35bAsy9bNaXNzc3XZZZfp17/+tSSpqalJ2dnZmjNnjhYsWNCivd/vl9//TZ+7z+dTdna2vF6vkpOTI1Y3EK2+PdalvQGtb5Uf1JxXP5O9f0VCb9b4wbrqvHRdPqQ/g3mBMPH5fHK5XCH5/rb1zkxDQ4O2bNmi4uLiwLm4uDjl5+errKys1Z8pLS1VSUlJpEoEYkpr3UXu5ERdNbS/kpw9NSg1KXCHIhoXupNObT1w33UX2F0GgE6wNcz861//UmNjozIzM4POZ2ZmaseOHa3+THFxsYqKigKPm+/MAOiatRXVmvXSp/r2TRaP77j+z6cHAo8f/dPnyklL0j//9VVkCwwzxsQA5rJ9zExnOZ1OOZ1Ou8sAokrDySb94vWKFkGmNZZkdJC5+5ohys1Jk8f7tcr310ly6Nz+SYyJAQxma5hJS0tTjx49VFNTE3S+pqZGbrfbpqqA2LK2olq/eP0fqq0/cebGhsrul6iHp4zU+OEZQWNgbvo37uoC0cDW/xuSkJCgMWPGaP369YFzTU1NWr9+vfLy8mysDIgNzV1L0Rxkfjo+Rx/ed60mjMhkMC8QpWzvZioqKtL06dP1b//2bxo7dqyefvpp1dfX6yc/+YndpQFRrbHJUsma7R3qWjJRau94PXrDSF138QC7SwEQZraHmZtvvlmHDx/WwoUL5fF4dMkll2jt2rUtBgUDCK3NlbVRt8jd5Tn9dPNlA+V29WKPJCCG2B5mJGn27NmaPXu23WUAMeXQ0egJMgk9HHr65kt13cXsVA3Eom4RZgBE3l6DZySd7u5rhug/84dxFwaIYYQZIAY1Nll6eXOV3WV02bz88/Sf+efbXQYAm7GoAhCDNlfWyuMzu5sptXe8Zl9znt1lAOgGCDNADIqG8TKP3jCSriUAkggzQEzK6JtodwldcvX56Uy5BhBAmAFi0NicVGW5zA00485Ls7sEAN0IYQaIMY1NljZX1uqCrL52l3LWUnsn2F0CgG6E2UxADFlbUa2SNduNXyzP7epldwkAuhHCDBAjmvdhMn37gixXosbmpNpdBoBuhG4mIAZE0z5Mi6aMYBYTgCCEGSAGRMM+TCm9emrlbaNVMJItCwAEo5sJiAGmryvzvYuz9MtbLuWODIBWEWaAGGDyujK/vuUSfe+Sc+wuA0A3RpgBokDDySb9d9lefVH7lQalJun2vHOV0PObXuQv6xtsrO7szb32PIIMgDMizACGK317u57/sFJNp43uXfz255o5LkfF141QY5OlR/603b4CuyAnvbfdJQAwAGEGMFjp29v13AeVLc43WQqcv3pYprGDf03uHgMQOcxmAgzVcLJJz3/YMsic7vkPK3Xwy68iVFFosZ4MgI4izACG+u+yvUFdS61psqTy/XURqSfUWE8GQEcRZgBDfVHb0TsuDuP2MpqXfz7ryQDoMMIMYKhBqUkdandu/yRNvWRAmKsJHXeyU7OvGWp3GQAMQpgBDHV73rk6Uy9MnONUu++OcEemqC5ySHro+xfSvQSgUwgzgKESesZp5ricdtvMHJejhJ5xGpuTqixX954ZlNIrXivYrgDAWSDMAAYrvm6Efjo+p8UdmjiH9NPxp9aZkaQecQ4tmjJC3fl+x/IfEWQAnB2HZVlGb6Tr8/nkcrnk9XqVnJxsdzmALc60AnCztRXVKlmzvdutO5PlStRf7ruG7iUghoTy+5tF84AokNAzTneMG3zGdgUjs/TdEW5trqzV78oq9U5FTQSqOzOmYQPoCrqZgBjTI86hvCH99esfjrF9yna/pHitZJwMgC7izgwQo3rEOXTT6HPOuIpwKM25ZohOdWyfClSXD+7PHRkAXUaYAWJUY5Olt7ZWR+S9MvsmqOSGkdyBARAWhBkgRm2urI3IQOB5+edr9jVDuQMDIGwIM0CMOnQ0MkHmP/PPC/v7AIhtDAAGYlRG3/AuopeaFM+2BAAigjADxKixOalyJ4cv0Dw69SK6lgBEBGEGiFE94hy6dezAs/rZpIQe7T7/0/E5uu5iBvsCiAzGzAAx7Ny0ju28ndIrXj+5MkfnpiUpo2+ixuak6v9VePTAmxWqrW8ItEvtHa9Hbxip6y42Z5duAOYjzAAxrKPjZpb/cLSuPC8t6Nx1F2dp0shTqwkfOno8EHLoWgIQabZ2M5177rlyOBxBx5IlS+wsCYgpHd1N2/v1iVbPN68mfMMl5yhvCAvgAbCH7WNmHn74YVVXVweOOXPm2F0SEDN6xDn04PUXnLHdI3/arsYmo/ekBRDFbO9m6tu3r9xut91lADGrX2/nGdtUe49rc2Wt8ob0j0BFANA5tt+ZWbJkifr3769LL71Uy5Yt08mTJ9tt7/f75fP5gg4AZ6+ji+dFYpE9ADgbtt6ZufvuuzV69Gilpqbqo48+UnFxsaqrq/Xkk0+2+TOlpaUqKSmJYJVAdOvoIOBwL7IHAGfLYVlWSDvCFyxYoMcff7zdNp9//rmGDx/e4vwLL7ygn/70pzp27JicztZvffv9fvn9/sBjn8+n7Oxseb1eJScnd614IAY1Nlm66vH35PEeV2t/DByS3K5E/eW+axjgCyBkfD6fXC5XSL6/Qx5mDh8+rCNHjrTbZvDgwUpISGhxftu2bRo5cqR27NihYcOGdej9QvmPAcSqtRXVmvXSp5IUFGiao8uK20az4zWAkArl93fIu5nS09OVnp5+Vj9bXl6uuLg4ZWRkhLgqAO0pGJmlFbeNVsma7UE7abtdiVo0ZQRBBkC3ZtuYmbKyMn388ceaMGGC+vbtq7KyMs2bN0+33Xab+vXrZ1dZQMwqGJml745gETwA5rEtzDidTr3yyit66KGH5Pf7lZOTo3nz5qmoqMiukoCY17wIHgCYxLYwM3r0aG3atMmutwcAAFHC9nVmAAAAuoIwAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGI8wAAACjEWYAAIDRCDMAAMBohBkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKMRZgAAgNEIMwAAwGiEGQAAYDTCDAAAMBphBgAAGI0wAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGC1uYWbx4sa644golJSUpJSWl1TZVVVW6/vrrlZSUpIyMDP385z/XyZMnw1USAACIQj3D9cINDQ2aNm2a8vLy9Nvf/rbF842Njbr++uvldrv10Ucfqbq6Wj/+8Y8VHx+vxx57LFxlAQCAKOOwLMsK5xusXr1ac+fOVV1dXdD5d955R9/73vd08OBBZWZmSpJWrlyp++67T4cPH1ZCQkKHXt/n88nlcsnr9So5OTnU5QMAgDAI5fe3bWNmysrKdNFFFwWCjCRNmjRJPp9P27Zta/Pn/H6/fD5f0AEAAGKXbWHG4/EEBRlJgccej6fNnystLZXL5Qoc2dnZYa0TAAB0b50KMwsWLJDD4Wj32LFjR7hqlSQVFxfL6/UGjn379oX1/QAAQPfWqQHA8+fP14wZM9ptM3jw4A69ltvt1ubNm4PO1dTUBJ5ri9PplNPp7NB7AACA6NepMJOenq709PSQvHFeXp4WL16sQ4cOKSMjQ5K0bt06JScna8SIESF5DwAAEP3CNjW7qqpKtbW1qqqqUmNjo8rLyyVJQ4cOVZ8+fTRx4kSNGDFCt99+u5YuXSqPx6MHHnhAhYWF3HkBAAAdFrap2TNmzNCLL77Y4vz777+vq6++WpL0xRdfaNasWdqwYYN69+6t6dOna8mSJerZs+MZi6nZAACYJ5Tf32FfZybcCDMAAJgnKtaZAQAACAXCDAAAMBphBgAAGI0wAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGI8wAAACjEWYAAIDRCDMAAMBohBkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKMRZgAAgNEIMwAAwGiEGQAAYDTCDAAAMBphBgAAGI0wAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYLWxhZvHixbriiiuUlJSklJSUVts4HI4WxyuvvBKukgAAQBTqGa4Xbmho0LRp05SXl6ff/va3bbZbtWqVCgoKAo/bCj4AAACtCVuYKSkpkSStXr263XYpKSlyu93hKgMAAEQ528fMFBYWKi0tTWPHjtULL7wgy7Labe/3++Xz+YIOAAAQu8J2Z6YjHn74YV1zzTVKSkrSn//8Z9111106duyY7r777jZ/prS0NHDXBwAAwGGd6VbIaRYsWKDHH3+83Taff/65hg8fHni8evVqzZ07V3V1dWd8/YULF2rVqlXat29fm238fr/8fn/gsc/nU3Z2trxer5KTk898EQAAwHY+n08ulysk39+dujMzf/58zZgxo902gwcPPuticnNz9cgjj8jv98vpdLbaxul0tvkcAACIPZ0KM+np6UpPTw9XLSovL1e/fv0IKwAAoMPCNmamqqpKtbW1qqqqUmNjo8rLyyVJQ4cOVZ8+fbRmzRrV1NTo8ssvV2JiotatW6fHHntM99xzT7hKAgAAUShsYWbhwoV68cUXA48vvfRSSdL777+vq6++WvHx8Vq+fLnmzZsny7I0dOhQPfnkk5o5c2a4SgIAAFGoUwOAu6NQDiACAACREcrvb9vXmQEAAOgKwgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKMRZgAAgNEIMwAAwGiEGQAAYDTCDAAAMBphBgAAGI0wAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGI8wAAACjEWYAAIDRCDMAAMBohBkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKMRZgAAgNEIMwAAwGiEGQAAYDTCDAAAMBphBgAAGI0wAwAAjBa2MLN3717dcccdysnJUa9evTRkyBAtWrRIDQ0NQe22bt2qcePGKTExUdnZ2Vq6dGm4SgIAAFGoZ7heeMeOHWpqatJzzz2noUOHqqKiQjNnzlR9fb2eeOIJSZLP59PEiROVn5+vlStX6h//+If+4z/+QykpKbrzzjvDVRoAAIgiDsuyrEi92bJly7RixQr985//lCStWLFC999/vzwejxISEiRJCxYs0BtvvKEdO3a0+hp+v19+vz/w2Ov1auDAgdq3b5+Sk5PDfxEAAKDLfD6fsrOzVVdXJ5fL1aXXCtudmdZ4vV6lpqYGHpeVlWn8+PGBICNJkyZN0uOPP64vv/xS/fr1a/EapaWlKikpaXE+Ozs7PEUDAICwOXLkiDlhZvfu3XrmmWcCXUyS5PF4lJOTE9QuMzMz8FxrYaa4uFhFRUWBx3V1dRo0aJCqqqq6/I9hkuZEG2t3pLhurjsWcN1cdyxo7lk5/SbH2ep0mFmwYIEef/zxdtt8/vnnGj58eODxgQMHVFBQoGnTpmnmzJmdr/I0TqdTTqezxXmXyxVT/xE0S05O5rpjCNcdW7ju2BKr1x0X1/W5SJ0OM/Pnz9eMGTPabTN48ODA/z548KAmTJigK664Qr/5zW+C2rndbtXU1ASda37sdrs7WxoAAIhBnQ4z6enpSk9P71DbAwcOaMKECRozZoxWrVrVIn3l5eXp/vvv14kTJxQfHy9JWrdunYYNG9ZqFxMAAMC3hW2dmQMHDujqq6/WwIED9cQTT+jw4cPyeDzyeDyBNj/84Q+VkJCgO+64Q9u2bdOrr76qX/7yl0FjYs7E6XRq0aJFrXY9RTOum+uOBVw31x0LuO6uX3fYpmavXr1aP/nJT1p97vS33Lp1qwoLC/W3v/1NaWlpmjNnju67775wlAQAAKJQRNeZAQAACDX2ZgIAAEYjzAAAAKMRZgAAgNEIMwAAwGjGhpm9e/fqjjvuUE5Ojnr16qUhQ4Zo0aJFamhoCGq3detWjRs3TomJicrOztbSpUttqjh0Fi9erCuuuEJJSUlKSUlptY3D4WhxvPLKK5EtNMQ6ct1VVVW6/vrrlZSUpIyMDP385z/XyZMnI1tomJ177rktPtslS5bYXVbILV++XOeee64SExOVm5urzZs3211S2D300EMtPtvTV1OPFh988IGmTJmiAQMGyOFw6I033gh63rIsLVy4UFlZWerVq5fy8/O1a9cue4oNoTNd94wZM1p8/gUFBfYUGyKlpaW67LLL1LdvX2VkZGjq1KnauXNnUJvjx4+rsLBQ/fv3V58+fXTTTTe1WFD3TIwNMzt27FBTU5Oee+45bdu2TU899ZRWrlypX/ziF4E2Pp9PEydO1KBBg7RlyxYtW7ZMDz30UIuViE3T0NCgadOmadasWe22W7VqlaqrqwPH1KlTI1NgmJzpuhsbG3X99deroaFBH330kV588UWtXr1aCxcujHCl4ffwww8HfbZz5syxu6SQevXVV1VUVKRFixbp008/1ahRozRp0iQdOnTI7tLC7sILLwz6bP/yl7/YXVLI1dfXa9SoUVq+fHmrzy9dulS/+tWvtHLlSn388cfq3bu3Jk2apOPHj0e40tA603VLUkFBQdDn//LLL0ewwtDbuHGjCgsLtWnTJq1bt04nTpzQxIkTVV9fH2gzb948rVmzRq+99po2btyogwcP6sYbb+zcG1lRZOnSpVZOTk7g8bPPPmv169fP8vv9gXP33XefNWzYMDvKC7lVq1ZZLper1eckWa+//npE64mUtq777bfftuLi4iyPxxM4t2LFCis5OTnovwHTDRo0yHrqqafsLiOsxo4daxUWFgYeNzY2WgMGDLBKS0ttrCr8Fi1aZI0aNcruMiLq23+rmpqaLLfbbS1btixwrq6uznI6ndbLL79sQ4Xh0drf6OnTp1s33HCDLfVEyqFDhyxJ1saNGy3LOvXZxsfHW6+99lqgzeeff25JssrKyjr8usbemWmN1+sN2n2zrKxM48ePV0JCQuDcpEmTtHPnTn355Zd2lBhRhYWFSktL09ixY/XCCy8ELVYYjcrKynTRRRcFdl6XTn3ePp9P27Zts7Gy0FuyZIn69++vSy+9VMuWLYuqrrSGhgZt2bJF+fn5gXNxcXHKz89XWVmZjZVFxq5duzRgwAANHjxYP/rRj1RVVWV3SRFVWVkpj8cT9Pm7XC7l5ubGxOe/YcMGZWRkaNiwYZo1a5aOHDlid0kh5fV6JSnwXb1lyxadOHEi6PMePny4Bg4c2KnPu9N7M3VXu3fv1jPPPKMnnngicM7j8SgnJyeoXfMXncfjier9nx5++GFdc801SkpK0p///GfdddddOnbsmO6++267Swsbj8cTFGSk4M87Wtx9990aPXq0UlNT9dFHH6m4uFjV1dV68skn7S4tJP71r3+psbGx1c9yx44dNlUVGbm5uVq9erWGDRum6upqlZSUaNy4caqoqFDfvn3tLi8imn9XW/v8o+n3uDUFBQW68cYblZOToz179ugXv/iFJk+erLKyMvXo0cPu8rqsqalJc+fO1ZVXXqmRI0dKOvV5JyQktBgH2dnPu9vdmVmwYEGrg1dPP779B+3AgQMqKCjQtGnTNHPmTJsq75qzue72PPjgg7ryyit16aWX6r777tO9996rZcuWhfEKzk6or9tUnfl3KCoq0tVXX62LL75YP/vZz/Rf//VfeuaZZ+T3+22+CnTV5MmTNW3aNF188cWaNGmS3n77bdXV1ekPf/iD3aUhAm655RZ9//vf10UXXaSpU6fqrbfe0t/+9jdt2LDB7tJCorCwUBUVFWGZjNLt7szMnz9fM2bMaLfN4MGDA//74MGDmjBhgq644ooWA3vdbneLEdHNj91ud2gKDpHOXndn5ebm6pFHHpHf7+9Wm5mF8rrdbneLGS/d9fP+tq78O+Tm5urkyZPau3evhg0bFobqIistLU09evRo9Xe3u3+OoZaSkqLzzz9fu3fvtruUiGn+jGtqapSVlRU4X1NTo0suucSmquwxePBgpaWlaffu3br22mvtLqdLZs+erbfeeksffPCBvvOd7wTOu91uNTQ0qK6uLujuTGd/37tdmElPT1d6enqH2h44cEATJkzQmDFjtGrVKsXFBd9oysvL0/33368TJ04oPj5ekrRu3ToNGzas23Uxdea6z0Z5ebn69evXrYKMFNrrzsvL0+LFi3Xo0CFlZGRIOvV5Jycna8SIESF5j3Dpyr9DeXm54uLiAtdsuoSEBI0ZM0br168PzMBramrS+vXrNXv2bHuLi7Bjx45pz549uv322+0uJWJycnLkdru1fv36QHjx+Xz6+OOPzziDM9rs379fR44cCQp1prEsS3PmzNHrr7+uDRs2tBj6MWbMGMXHx2v9+vW66aabJEk7d+5UVVWV8vLyOvVGRtq/f781dOhQ69prr7X2799vVVdXB45mdXV1VmZmpnX77bdbFRUV1iuvvGIlJSVZzz33nI2Vd90XX3xhffbZZ1ZJSYnVp08f67PPPrM+++wz6+jRo5ZlWdYf//hH6/nnn7f+8Y9/WLt27bKeffZZKykpyVq4cKHNlXfNma775MmT1siRI62JEyda5eXl1tq1a6309HSruLjY5spD56OPPrKeeuopq7y83NqzZ4/10ksvWenp6daPf/xju0sLqVdeecVyOp3W6tWrre3bt1t33nmnlZKSEjRTLRrNnz/f2rBhg1VZWWn99a9/tfLz8620tDTr0KFDdpcWUkePHg38/kqynnzySeuzzz6zvvjiC8uyLGvJkiVWSkqK9eabb1pbt261brjhBisnJ8f6+uuvba68a9q77qNHj1r33HOPVVZWZlVWVlrvvvuuNXr0aOu8886zjh8/bnfpZ23WrFmWy+WyNmzYEPQ9/dVXXwXa/OxnP7MGDhxovffee9Ynn3xi5eXlWXl5eZ16H2PDzKpVqyxJrR6n+/vf/25dddVVltPptM455xxryZIlNlUcOtOnT2/1ut9//33LsizrnXfesS655BKrT58+Vu/eva1Ro0ZZK1eutBobG+0tvIvOdN2WZVl79+61Jk+ebPXq1ctKS0uz5s+fb504ccK+okNsy5YtVm5uruVyuazExETrggsusB577DGj/9i15ZlnnrEGDhxoJSQkWGPHjrU2bdpkd0lhd/PNN1tZWVlWQkKCdc4551g333yztXv3brvLCrn333+/1d/l6dOnW5Z1anr2gw8+aGVmZlpOp9O69tprrZ07d9pbdAi0d91fffWVNXHiRCs9Pd2Kj4+3Bg0aZM2cOdP4AN/W9/SqVasCbb7++mvrrrvusvr162clJSVZP/jBD4JuTHSE43/fDAAAwEjdbjYTAABAZxBmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGI8wAAACjEWYAAIDRCDMAAMBo/x9wESeIdI8mzgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "29.52"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(generated_data[:,0],generated_data[:,1])\n",
    "plt.ylim((-1*y_lim,y_lim))\n",
    "plt.xlim((-x_lim,x_lim))\n",
    "plt.show()\n",
    "generated_data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "plt.hist(generated_data[:,0],density=True,bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-3.3534, dtype=torch.float64), -6.124042)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data_test[:,0].min(),generated_data.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x2800 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_kde_subplots(test_data, gen_data, n_cols=3, figsize=(15, 4), suptitle=None):\n",
    "    \"\"\"\n",
    "    Plots KDE comparisons between test and generated data for each dimension.\n",
    "\n",
    "    Parameters:\n",
    "    - test_data: np.ndarray of shape (batch, dim)\n",
    "    - gen_data: np.ndarray of shape (batch, dim)\n",
    "    - n_cols: Number of columns in subplot grid\n",
    "    - figsize: Tuple (width, height) for each subplot row\n",
    "    - suptitle: Optional super title for the figure\n",
    "    \"\"\"\n",
    "    assert test_data.shape == gen_data.shape, \"test_data and gen_data must have the same shape\"\n",
    "    \n",
    "    batch, dim = test_data.shape\n",
    "    n_rows = (dim + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(figsize[0], figsize[1]*n_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(dim):\n",
    "        ax = axes[i]\n",
    "        sns.kdeplot(np.clip(test_data[:, i],-200,200), ax=ax, label='Test', color='blue')\n",
    "        sns.kdeplot(np.clip(gen_data[:, i],-200,200), ax=ax, label='Generated', color='orange')\n",
    "        ax.set_title(f'Dimension {i}')\n",
    "        ax.legend()\n",
    "\n",
    "    # Remove unused axes\n",
    "    for j in range(dim, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    if suptitle:\n",
    "        plt.suptitle(suptitle, fontsize=16)\n",
    "        plt.subplots_adjust(top=0.92)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_kde_subplots(full_data_test,generated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.hist(generated_data[:,0],density=True,bins=100,color='red',histtype='step')\n",
    "plt.hist(full_data_test[:,0],density=True,bins=100,color='blue',histtype='step')\n",
    "ax = plt.gca()  # Get current Axes\n",
    "ax.set_yscale('log')\n",
    "# plt.xlim(-200,200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -23.3230,  -22.5302,  -22.9963,  -33.7671,  -20.1489,  -28.7526,\n",
      "        -108.9987,  -19.6882,  -23.3277,  -30.6470,  -28.1543,  -20.3957,\n",
      "         -22.8530,  -19.2652,  -20.4460,  -19.7092,  -31.0736,  -22.9353,\n",
      "         -18.3783,  -41.9288,  -33.7404,  -27.6418,  -19.4644,  -19.9568,\n",
      "         -19.8209,  -19.9091,  -19.6254,  -20.9324,  -71.2074,  -18.9759,\n",
      "         -20.5596,  -19.2353,  -20.3808,  -20.4497, -150.1938,  -19.4555,\n",
      "         -75.5280,  -19.9393,  -22.1016,  -20.5609,  -37.0366,  -20.7586,\n",
      "         -63.4001,  -19.3118,  -20.2830,  -19.8875,  -63.5860,  -50.5472,\n",
      "         -19.8977,  -20.7144,  -22.2497,  -20.4349,  -19.7943,  -20.8372,\n",
      "         -43.0051,  -19.9017,  -33.0987,  -19.9351,  -19.2778,  -20.6917,\n",
      "         -96.2869,  -20.0420,  -20.1158,  -77.7617,  -34.0616,  -19.1335,\n",
      "         -85.3271,  -21.1814,  -20.0854,  -20.7491,  -19.1937,  -20.0762,\n",
      "         -34.2255, -124.8126,  -19.1211,  -24.2557,  -26.7574,  -20.2758,\n",
      "        -105.2342,  -58.8290,  -21.8432,  -19.9939,  -95.8834,  -19.2585,\n",
      "         -29.6625,  -20.6817,  -20.3431,  -22.9538,  -19.5930,  -19.1335,\n",
      "         -22.5751,  -26.7869,  -86.0311,  -28.2817,  -23.1158,  -23.9822,\n",
      "         -20.0005,  -67.3090,  -18.5218,  -82.3957,  -24.7722,  -19.4055,\n",
      "         -28.1962,  -20.3716,  -20.4232,  -19.4447,  -19.7881,  -42.2492,\n",
      "         -21.5938,  -92.3855,  -22.9755,  -19.5753,  -22.8890,  -19.9655,\n",
      "         -26.0354,  -21.2001,  -21.2321,  -19.3975,  -87.9470,  -21.1399,\n",
      "         -19.0810,  -21.0659,  -22.2087,  -21.5795,  -28.1882,  -21.0011,\n",
      "         -21.5161,  -21.8257,  -21.5728,  -23.4523,  -21.3858,  -23.8432,\n",
      "         -25.5728,  -19.3055, -112.1721,  -27.3168,  -25.3479,  -20.9310,\n",
      "         -20.3936,  -19.5210,  -19.9091,  -19.3643,  -23.6742,  -26.4493,\n",
      "         -26.4133,  -27.0593,  -20.4123,  -20.8280,  -33.0561,  -20.1591,\n",
      "         -19.8929,  -35.3412,  -20.5131,  -20.7605,  -19.7118,  -20.2540,\n",
      "         -19.4515,  -20.2208,  -49.0112,  -26.1679,  -21.6395,  -19.4172,\n",
      "         -19.6145,  -20.5268,  -18.9250,  -21.3486,  -19.1894,  -22.1699,\n",
      "         -22.4971,  -20.8947,  -19.3823,  -22.1572,  -29.3829,  -24.8585,\n",
      "         -19.0872,  -22.6872,  -21.0421,  -19.2172,  -19.1354,  -21.9081,\n",
      "         -22.7386,  -19.4807,  -20.7401,  -19.7355,  -20.8062,  -21.8024,\n",
      "         -18.5384,  -20.9761,  -46.8000,  -20.7984,  -34.1370,  -21.5357,\n",
      "         -21.3472,  -19.1160,  -21.2014,  -25.3333,  -24.1245,  -34.1643,\n",
      "         -29.4988,  -19.7721,  -23.1679,  -18.9465,  -21.2256,  -24.6460,\n",
      "         -19.1876,  -19.8031,  -24.5577,  -20.4354,  -19.4748,  -23.9959,\n",
      "         -19.1851,  -23.1920,  -18.7800,  -22.8290,  -18.4356,  -20.1027,\n",
      "         -21.6865,  -19.6719, -107.5206,  -19.3673,  -24.5467,  -21.3769,\n",
      "         -19.8149,  -20.0955,  -20.9942,  -21.6410,  -69.8030,  -20.8503,\n",
      "         -50.0020,  -27.5013,  -24.1857,  -20.5765,  -18.8916,  -18.6428,\n",
      "         -23.6437,  -20.6127,  -34.4233,  -19.8606,  -30.3313,  -26.7453,\n",
      "         -19.3556,  -22.2153,  -21.0094,  -24.8296,  -64.6382,  -18.5622,\n",
      "         -20.8084,  -25.7341,  -22.8446,  -22.8080,  -20.0758,  -23.5632,\n",
      "         -20.0936,  -19.3522,  -22.6555,  -23.2434,  -19.9913,  -46.7442,\n",
      "         -19.1271,  -20.6128,  -23.6181,  -23.1801,  -20.2307,  -74.1311,\n",
      "         -27.5333,  -19.3912,  -21.9721,  -69.4846,  -22.8767,  -19.7087,\n",
      "         -20.0066,  -32.0917,  -51.2888,  -19.1594,  -27.8891,  -23.3974,\n",
      "         -33.8144,  -19.9722,  -21.9208,  -24.0748,  -21.3907,  -34.8646,\n",
      "         -26.6796,  -27.5290,  -23.8346,  -28.4387,  -23.3064,  -24.4068,\n",
      "         -19.3539,  -21.1761,  -20.3466,  -27.3688,  -43.0841,  -22.5685,\n",
      "         -18.8887,  -47.6640,  -34.2746,  -22.6835,  -20.3606, -152.1936,\n",
      "        -174.7464,  -22.1030,  -27.4842,  -26.9206,  -25.8939,  -18.5734,\n",
      "         -22.6828,  -25.3817, -174.9175,  -24.3684,  -47.1799, -106.3432,\n",
      "         -25.4491,  -20.7019,  -54.6280,  -22.8063,  -21.3326,  -29.1223,\n",
      "        -155.4863,  -18.2964,  -56.3040,  -20.3802,  -98.1792,  -33.5382,\n",
      "         -42.8776,  -29.6180,  -25.8916,  -27.3663, -143.8220,  -25.4122,\n",
      "         -25.8932,  -30.9842,  -19.0954,  -29.3542,  -69.7555,  -44.0587,\n",
      "         -24.6283,  -30.1494,  -23.6583,  -87.8343,  -24.0772,  -29.9407,\n",
      "         -19.2746,  -19.0289,  -28.2495,  -27.2109,  -31.3529,  -20.7008,\n",
      "         -19.4515,  -19.8884,  -22.0196,  -21.9530,  -22.0503,  -21.3767,\n",
      "        -116.7190,  -29.1069,  -39.9888,  -26.0118,  -20.5627,  -23.2233,\n",
      "         -27.9910,  -26.5202,  -20.4856,  -88.2341,  -21.9057,  -19.0933,\n",
      "         -19.2802, -136.2093,  -22.8540, -137.8591,  -36.3531,  -18.6732,\n",
      "        -132.6967,  -19.1301,  -19.6277,  -19.0776,  -33.4193,  -19.3939,\n",
      "         -18.9947,  -22.7378,  -19.6059,  -61.7021,  -23.1947,  -59.6296,\n",
      "         -19.9139,  -20.5272,  -20.6136,  -26.7648,  -22.4843,  -18.7946,\n",
      "         -26.3883, -149.1055,  -20.3663,  -24.5262,  -18.6917,  -38.9333,\n",
      "         -20.8911,  -21.6698,  -21.4976,  -33.1043,  -20.2242,  -22.3055,\n",
      "         -19.3014,  -55.4241,  -19.9979,  -19.1687,  -19.2931,  -19.6826,\n",
      "         -23.8166,  -24.8398,  -21.4909,  -22.9176,  -20.0135,  -19.9707,\n",
      "         -19.4031,  -21.0517, -130.8718,  -24.5522,  -19.5732, -117.7965,\n",
      "         -21.4466,  -23.9665,  -19.2038,  -21.0293,  -20.8948,  -75.3782,\n",
      "         -19.6014,  -19.4333,  -18.9198,  -21.3682,  -23.0019,  -20.0990,\n",
      "         -19.6858,  -18.5461,  -19.8094,  -23.5095,  -19.9485,  -21.0563,\n",
      "         -19.1513,  -22.6057,  -29.9506,  -20.0854,  -21.2070,  -28.3308,\n",
      "         -27.4247,  -21.2796,  -33.3969,  -20.3054,  -21.4455,  -26.3653,\n",
      "         -20.8942,  -19.7874,  -28.2923,  -18.8820,  -20.3270,  -24.1526,\n",
      "         -18.8907,  -19.8954,  -18.6928,  -22.9783,  -27.2662,  -19.1594,\n",
      "         -20.6053,  -36.6941,  -24.3846,  -28.6123,  -19.8530,  -19.7074,\n",
      "         -20.8484,  -19.3462,  -20.9721,  -18.7642,  -19.5822,  -21.1941,\n",
      "         -20.1349,  -18.8247,  -20.3150,  -19.8421,  -21.1264,  -20.6622,\n",
      "         -21.6651,  -19.3344,  -24.7396,  -28.9673,  -23.3233,  -30.7269,\n",
      "         -26.8640,  -22.8489,  -22.2925,  -19.4487,  -25.7079,  -30.9016,\n",
      "         -21.7912,  -21.1651,  -21.0165,  -22.1837,  -30.4374,  -21.9518,\n",
      "         -19.0638,  -27.4791,  -29.3511,  -27.8048,  -19.2852,  -21.6095,\n",
      "         -29.7502,  -25.2738,  -34.8723,  -78.5353,  -34.1090,  -21.7966,\n",
      "         -19.2957,  -36.9280,  -24.3378,  -23.5706,  -19.4314,  -20.9721,\n",
      "         -19.1718,  -24.6650,  -22.4677,  -96.1834,  -19.1710,  -77.5929,\n",
      "         -19.8263,  -23.4120,  -22.4491,  -18.9998,  -19.9748,  -22.3157,\n",
      "         -28.5778,  -23.8442,  -19.0531,  -39.4076,  -23.3635,  -19.1148,\n",
      "         -20.5619,  -21.2099,  -19.7370,  -18.7735,  -20.8136,  -38.4928,\n",
      "         -23.2384,  -20.4375,  -33.9021,  -24.6968,  -26.2550,  -20.6686,\n",
      "         -22.2008,  -21.4833,  -29.8847,  -20.2680,  -36.3961,  -28.1281,\n",
      "         -40.5298,  -45.7205,  -19.2784,  -29.8799,  -18.3737,  -23.1634,\n",
      "         -53.9998,  -36.7887,  -36.5037,  -51.9332,  -28.4148,  -36.9146,\n",
      "         -40.5636,  -19.9857,  -20.1631,  -35.0559,  -30.0454,  -29.1529,\n",
      "         -42.6080,  -18.4099,  -43.1758,  -31.9928,  -25.3505,  -19.7877,\n",
      "        -145.5741,  -48.0642,  -20.6110,  -20.2267,  -19.8371,  -19.6845,\n",
      "         -21.5838,  -86.2375,  -21.7868,  -26.5239,  -39.2554,  -23.3527,\n",
      "         -21.5723, -106.2301,  -23.7014,  -22.4445,  -19.9239,  -19.9091,\n",
      "         -50.0986,  -20.1986,  -41.1054,  -20.0788,  -20.0766, -161.3955,\n",
      "         -35.2978,  -24.8900, -115.2885,  -26.5768,  -24.3400,  -19.9304,\n",
      "        -112.2380,  -21.3495,  -22.0445,  -28.6713,  -20.4030,  -19.8259,\n",
      "        -162.6386,  -19.9531,  -20.1814,  -18.6751,  -25.4377,  -19.5696,\n",
      "         -18.6948,  -20.1406,  -18.7800,  -19.7741,  -23.6331,  -20.0291,\n",
      "         -51.6917,  -23.2206,  -23.8461,  -22.6506,  -34.4845,  -20.3254,\n",
      "         -19.2843,  -99.5768,  -21.1758,  -20.3968,  -25.2795,  -19.3677,\n",
      "         -27.7096,  -99.4673,  -18.9801,  -18.8786,  -19.8698,  -24.4662,\n",
      "         -18.2054,  -61.2742,  -21.7754,  -20.1090,  -24.5413,  -21.0561,\n",
      "         -22.2950,  -20.2071,  -23.2629,  -58.1690,  -24.3476, -113.6686,\n",
      "         -22.8208,  -41.3683,  -41.6113,  -32.6462,  -30.2076,  -31.4662,\n",
      "         -22.6299,  -36.8819,  -66.6029,  -35.2545,  -23.1101,  -20.9992,\n",
      "         -41.0517,  -44.7567,  -19.2326,  -43.8593,  -23.5044,  -29.3603,\n",
      "         -36.0651, -109.3946,  -28.3831,  -25.7009,  -25.3043,  -20.3162,\n",
      "         -43.0429,  -21.3706,  -65.7378,  -35.8837,  -92.8268,  -96.3103,\n",
      "         -72.6455,  -30.8736,  -36.2439,  -41.8721,  -19.6871,  -22.5518,\n",
      "         -22.9370,  -20.6509,  -20.5628,  -20.6628,  -29.8296,  -20.3498,\n",
      "         -21.2159,  -22.1826, -123.9419,  -19.4643,  -23.5984,  -19.4352,\n",
      "         -58.7932,  -20.5209,  -20.0662,  -24.7413,  -23.4557,  -20.1461,\n",
      "         -21.4622,  -37.7053,  -19.7286,  -25.7876,  -18.9584,  -24.9343,\n",
      "         -35.6788,  -19.0029,  -22.4647,  -27.6652,  -18.9257,  -19.9162,\n",
      "         -23.0924,  -19.0763,  -24.8629,  -23.0401,  -19.3344,  -21.4248,\n",
      "         -32.7938,  -19.1653,  -21.7719,  -20.6398,  -20.6796,  -25.3978,\n",
      "         -22.4108,  -20.2485,  -18.8673,  -20.1537,  -19.3028,  -19.7091,\n",
      "         -30.2685,  -27.8337,  -65.7978,  -25.2321,  -25.0381,  -20.6633,\n",
      "         -22.7473,  -21.3244,  -25.3699,  -28.1753,  -23.5916,  -20.1852,\n",
      "         -20.0942,  -19.1743,  -20.9264,  -21.3963,  -62.3057,  -20.6147,\n",
      "         -19.9480,  -25.8230,  -20.1759,  -29.9904,  -27.6863,  -19.3042,\n",
      "         -23.2030,  -19.0941,  -46.8272,  -19.6465,  -19.9606,  -21.7014,\n",
      "         -20.7429,  -23.1231,  -44.0994,  -18.8685,  -20.7456,  -60.4294,\n",
      "         -20.2574,  -21.7191,  -65.7021,  -20.0438,  -99.6271,  -21.2896,\n",
      "         -56.8085,  -20.4166,  -21.5983,  -21.8795,  -32.2993,  -21.4515,\n",
      "         -27.8301,  -37.3689,  -19.4077,  -29.1828,  -25.1985,  -25.5912,\n",
      "         -20.3327,  -19.0693,  -43.2282,  -52.0090,  -42.1268, -154.4225,\n",
      "         -28.7413,  -18.5041,  -26.2995,  -20.0056,  -33.0711,  -56.7705,\n",
      "         -30.6377,  -23.3820,  -24.2049,  -27.9823,  -25.8926,  -21.5505,\n",
      "         -34.2298,  -34.7311,  -19.8098,  -19.3378,  -19.5089,  -91.5492,\n",
      "         -19.6648,  -20.5525,  -21.6422,  -30.3924,  -21.0884,  -18.6003,\n",
      "         -30.3272,  -21.5773,  -26.1523,  -19.5419,  -25.4666, -119.2913,\n",
      "         -21.0005,  -20.0509,  -19.1670,  -20.8140,  -24.3567,  -22.5745,\n",
      "         -21.8159,  -19.0195,  -29.9397,  -29.5655,  -34.9239,  -26.0892,\n",
      "         -25.7921,  -31.1485,  -20.7669,  -27.9653,  -21.3162,  -37.7853,\n",
      "         -32.2011,  -20.1653,  -37.2855,  -49.8464,  -21.4950,  -22.6104,\n",
      "         -32.2390,  -28.9533,  -26.8197,  -20.6235,  -32.4945,  -32.5047,\n",
      "         -19.7767,  -25.2270,  -20.7809,  -34.7991,  -20.8270,  -25.4540,\n",
      "         -22.4775,  -21.5569,  -25.4351,  -19.3640,  -23.0159,  -26.3016,\n",
      "         -30.7390,  -37.4459,  -24.7978,  -19.4188,  -26.4917,  -21.3293,\n",
      "         -19.9879,  -25.8509,  -20.5181,  -23.9699,  -22.5518,  -20.0625,\n",
      "         -45.0453,  -22.1616,  -21.5193,  -20.5635,  -19.2829,  -26.5055,\n",
      "         -19.3531,  -20.2134,  -25.9777,  -30.7805,  -25.6380,  -21.9607,\n",
      "         -34.3079,  -20.3218,  -19.8129,  -19.4629,  -26.8506,  -26.3147,\n",
      "         -37.7613,  -20.0914,  -35.9546,  -22.0461,  -19.0768,  -22.7370,\n",
      "         -19.0523,  -21.2150,  -19.5379,  -21.2756,  -25.5038,  -18.8638,\n",
      "         -22.5616,  -28.5421,  -20.3887,  -19.1402,  -20.0750,  -26.2252,\n",
      "         -32.9073,  -19.4976,  -22.8416,  -23.1313,  -34.4322,  -26.9672,\n",
      "         -19.4115,  -22.0044,  -19.5263,  -24.6827,  -31.1484,  -22.7704,\n",
      "         -20.7310,  -33.0940,  -29.8138,  -20.0631,  -21.8925,  -25.5211,\n",
      "         -22.2247,  -19.9887,  -21.1964,  -23.8131,  -26.9586,  -20.0545,\n",
      "         -19.4961,  -19.0573,  -22.7296,  -25.7867,  -28.3678,  -18.8421,\n",
      "         -19.5719,  -19.5316,  -19.6921,  -23.9791,  -24.8151,  -19.3479,\n",
      "         -20.7698,  -27.0647,  -20.7730,  -21.6626,  -25.7229,  -28.9289,\n",
      "         -24.4934,  -25.1252,  -21.0298,  -20.5313,  -22.5164,  -31.5350,\n",
      "         -20.4007,  -21.5518,  -22.1095,  -25.1845,  -19.9510,  -19.6763,\n",
      "         -27.7600,  -25.4811,  -20.9023,  -29.9206,  -20.3563,  -22.1785,\n",
      "         -30.8411,  -26.1547,  -21.0216,  -21.9602,  -30.8951,  -23.0006,\n",
      "         -23.8953,  -26.4416,  -19.2021,  -35.9100,  -19.3879,  -31.5549,\n",
      "         -29.4822,  -21.2928,  -20.7370,  -19.7160,  -24.5811,  -20.6990,\n",
      "         -31.3424,  -23.5410,  -26.8429,  -19.3955], device='cuda:0')\n",
      "tensor([ -26.5625,  -23.7657,  -21.9070,  -30.9004,  -21.7416,  -25.1731,\n",
      "        -130.9719,  -20.6086,  -20.7811,  -33.8198,  -26.1520,  -22.2183,\n",
      "         -19.0415,  -26.5155,  -20.0837,  -25.4729,  -31.5910,  -19.7924,\n",
      "         -18.6272,  -35.4401,  -38.7724,  -23.2027,  -23.1954,  -24.2441,\n",
      "         -21.3819,  -19.4017,  -26.5432,  -19.8529,  -69.0133,  -21.5280,\n",
      "         -20.1052,  -21.9276,  -23.7165,  -28.3974, -150.5925,  -20.5369,\n",
      "         -76.8463,  -19.9678,  -18.9173,  -19.5531,  -22.7892,  -20.1289,\n",
      "         -72.6382,  -24.5419,  -34.0799,  -19.0488,  -66.7070,  -66.4013,\n",
      "         -20.1749,  -27.9032,  -19.7360,  -20.8623,  -25.3150,  -20.6038,\n",
      "         -19.9913,  -19.6384,  -26.5048,  -18.7584,  -18.5176,  -20.8604,\n",
      "         -94.9102,  -20.3864,  -26.1127,  -79.3783,  -21.9153,  -22.0408,\n",
      "         -79.9215,  -26.2553,  -19.7609,  -27.8030,  -20.0078,  -32.5041,\n",
      "         -20.2279, -123.0315,  -20.8235,  -23.7986,  -19.4074,  -23.6811,\n",
      "        -112.5455,  -61.5161,  -19.8918,  -19.2422,  -93.9182,  -23.2927,\n",
      "         -27.6036,  -19.7315,  -22.1843,  -20.9986,  -28.8383,  -20.1539,\n",
      "         -26.8217,  -21.5257,  -90.3255,  -26.4417,  -20.7374,  -22.9979,\n",
      "         -19.8335,  -60.9584,  -18.6169,  -75.2647,  -19.5285,  -19.4806,\n",
      "         -23.8981,  -19.5749,  -20.5567,  -19.5008,  -20.3860,  -40.6388,\n",
      "         -22.1247,  -65.2218,  -32.6064,  -19.6472,  -22.1372,  -20.5780,\n",
      "         -19.8409,  -20.2295,  -23.6940,  -20.5554,  -90.4024,  -29.1512,\n",
      "         -30.8319,  -22.2815,  -20.5926,  -21.1667,  -19.2608,  -23.2296,\n",
      "         -23.1292,  -20.3347,  -24.6455,  -19.0676,  -19.4629,  -21.7250,\n",
      "         -19.9974,  -19.5339,  -99.5778,  -19.3450,  -22.9640,  -19.8969,\n",
      "         -20.1440,  -20.4718,  -19.8224,  -25.0638,  -20.7494,  -25.9939,\n",
      "         -19.3996,  -19.1039,  -20.2611,  -18.7056,  -22.3544,  -19.5096,\n",
      "         -19.4259,  -34.6801,  -21.4690,  -20.3334,  -30.0588,  -20.7955,\n",
      "         -19.5613,  -24.9870,  -49.0171,  -19.5809,  -19.4872,  -18.8778,\n",
      "         -19.0898,  -19.4445,  -22.2685,  -18.8035,  -23.8385,  -19.8786,\n",
      "         -23.8903,  -20.2121,  -19.2829,  -18.6519,  -20.3997,  -24.1801,\n",
      "         -19.4832,  -27.8563,  -19.4281,  -33.7291,  -19.2895,  -19.9286,\n",
      "         -25.7429,  -25.1434,  -19.0670,  -19.9833,  -19.4051,  -19.8135,\n",
      "         -18.9883,  -18.9940,  -44.9420,  -19.5687,  -20.6672,  -19.4161,\n",
      "         -19.1623,  -19.7869,  -18.4861,  -22.7224,  -19.6828,  -30.8337,\n",
      "         -20.7392,  -20.2380,  -20.8639,  -19.7800,  -18.4038,  -20.3955,\n",
      "         -20.4917,  -19.7471,  -21.4585,  -19.1037,  -18.8352,  -20.5688,\n",
      "         -19.1768,  -23.9331,  -19.8589,  -29.6263,  -18.9104,  -20.5371,\n",
      "         -21.5461,  -19.4635,  -99.0426,  -21.7016,  -18.7999,  -22.6678,\n",
      "         -21.8545,  -20.0419,  -20.3918,  -21.2067,  -70.7855,  -23.0824,\n",
      "         -50.1914,  -28.6475,  -18.3573,  -20.1579,  -19.5836,  -18.7312,\n",
      "         -20.0353,  -19.0922,  -35.4358,  -20.6100,  -19.9036,  -30.7793,\n",
      "         -20.0911,  -20.8960,  -18.9803,  -25.0873,  -61.8442,  -20.0402,\n",
      "         -18.5089,  -33.5319,  -20.7344,  -19.6645,  -20.8522,  -23.5872,\n",
      "         -22.0641,  -20.2227,  -23.6073,  -25.6947,  -20.3613,  -61.8259,\n",
      "         -21.9314,  -24.2114,  -19.0887,  -21.9536,  -25.5757,  -72.6852,\n",
      "         -22.3399,  -19.9269,  -22.2217,  -63.1189,  -21.6440,  -19.6804,\n",
      "         -20.9809,  -31.6118,  -53.1374,  -19.7603,  -21.3543,  -19.7266,\n",
      "         -21.9047,  -19.6005,  -20.7937,  -20.6889,  -20.8358,  -35.2110,\n",
      "         -26.3132,  -20.7029,  -22.0635,  -19.7318,  -20.2468,  -21.9470,\n",
      "         -19.4599,  -20.4187,  -20.4345,  -20.7457,  -43.4983,  -20.7444,\n",
      "         -19.8636,  -53.4224,  -28.7254,  -24.1378,  -24.7841, -151.7832,\n",
      "        -177.2886,  -19.1207,  -21.1563,  -27.1495,  -25.3337,  -19.1623,\n",
      "         -22.0041,  -19.8049, -177.5453,  -23.4072,  -47.3539, -103.2625,\n",
      "         -28.1908,  -24.4268,  -53.0814,  -21.1757,  -25.6159,  -23.5410,\n",
      "        -156.3466,  -18.7643,  -57.1107,  -19.2818,  -96.9770,  -37.5654,\n",
      "         -35.6126,  -25.9706,  -25.7723,  -28.1481, -145.5863,  -23.3956,\n",
      "         -23.3382,  -25.9787,  -19.4688,  -25.5449,  -79.2642,  -43.6008,\n",
      "         -26.4716,  -31.2483,  -24.0142,  -89.5023,  -28.2540,  -28.1604,\n",
      "         -19.1575,  -18.8483,  -20.3495,  -40.8387,  -19.6570,  -19.4467,\n",
      "         -22.3800,  -23.2251,  -22.3558,  -21.7491,  -27.7838,  -25.7903,\n",
      "        -118.6502,  -22.4984,  -23.0517,  -33.7050,  -19.7846,  -31.6238,\n",
      "         -24.8287,  -22.3907,  -20.0572,  -87.4731,  -22.7758,  -22.4615,\n",
      "         -18.5792, -132.3385,  -22.3576, -136.7827,  -30.9666,  -19.3304,\n",
      "        -132.4189,  -20.4112,  -20.4691,  -22.1931,  -22.2082,  -23.1413,\n",
      "         -22.2032,  -20.2090,  -20.2645,  -69.2609,  -31.3993,  -60.7726,\n",
      "         -19.9658,  -20.2631,  -19.1540,  -21.2355,  -20.7023,  -20.7679,\n",
      "         -29.8032, -152.1846,  -23.2432,  -25.3282,  -19.3198,  -19.3014,\n",
      "         -20.2063,  -19.9605,  -19.3871,  -23.9996,  -22.6480,  -23.4296,\n",
      "         -20.1897,  -47.0165,  -27.5906,  -22.0813,  -20.2724,  -19.6613,\n",
      "         -21.1848,  -28.9523,  -18.9640,  -29.0476,  -22.4310,  -24.0016,\n",
      "         -18.8147,  -19.6176, -131.2448,  -20.2776,  -20.9028, -102.9815,\n",
      "         -20.2633,  -31.3188,  -25.6833,  -19.1141,  -20.4761,  -73.7286,\n",
      "         -19.6881,  -22.2501,  -19.6499,  -19.2093,  -21.8415,  -19.3506,\n",
      "         -23.7134,  -25.5943,  -19.9817,  -22.5210,  -19.3314,  -19.9948,\n",
      "         -21.6361,  -18.6446,  -30.4211,  -21.1773,  -23.6459,  -28.3694,\n",
      "         -23.7775,  -23.2991,  -20.0147,  -19.4954,  -23.1514,  -26.5671,\n",
      "         -19.8445,  -19.6785,  -33.9053,  -26.0771,  -20.5250,  -22.8835,\n",
      "         -19.1322,  -19.8015,  -18.8773,  -21.9537,  -25.7516,  -21.6894,\n",
      "         -19.6739,  -22.6994,  -19.8532,  -20.7784,  -20.6155,  -19.9890,\n",
      "         -18.8854,  -22.0547,  -18.8696,  -19.6926,  -24.5914,  -19.3132,\n",
      "         -19.4261,  -29.6760,  -27.0399,  -32.7712,  -20.2717,  -19.3509,\n",
      "         -21.6702,  -20.3044,  -24.4950,  -29.6575,  -24.2989,  -35.3525,\n",
      "         -25.9722,  -23.0762,  -24.0664,  -18.6847,  -20.3037,  -30.2297,\n",
      "         -21.0948,  -24.9738,  -22.7990,  -20.5947,  -21.0641,  -20.1303,\n",
      "         -18.6218,  -38.8254,  -25.7424,  -19.1775,  -20.7711,  -20.0048,\n",
      "         -38.8388,  -25.2919,  -21.6557,  -72.0815,  -18.8274,  -26.8513,\n",
      "         -23.7949,  -42.6413,  -20.9878,  -21.6961,  -19.8907,  -18.6622,\n",
      "         -34.6377,  -19.9888,  -31.9396,  -98.0681,  -22.6296,  -80.7494,\n",
      "         -19.4208,  -19.7088,  -18.6120,  -18.6378,  -25.2328,  -22.7275,\n",
      "         -22.5857,  -25.4925,  -19.6647,  -39.4759,  -27.2584,  -24.3497,\n",
      "         -20.4880,  -26.0419,  -18.9625,  -19.4302,  -19.5103,  -37.4094,\n",
      "         -20.7771,  -20.0562,  -33.7039,  -19.4199,  -29.8002,  -20.2521,\n",
      "         -23.2279,  -19.0491,  -30.0132,  -26.7654,  -35.3624,  -29.0008,\n",
      "         -35.0415,  -43.9236,  -22.0208,  -26.6651,  -20.1415,  -24.0143,\n",
      "         -59.1356,  -34.3781,  -35.4543,  -63.9266,  -30.0976,  -20.4264,\n",
      "         -39.7771,  -19.7458,  -19.2325,  -35.2203,  -35.7255,  -29.5831,\n",
      "         -41.2936,  -23.4248,  -43.1125,  -31.7805,  -26.0764,  -19.2740,\n",
      "        -144.1282,  -47.5060,  -23.2155,  -20.1029,  -19.3608,  -19.1908,\n",
      "         -28.4530,  -83.5355,  -21.1686,  -19.8162,  -20.3741,  -20.6400,\n",
      "         -23.7104, -109.1531,  -22.5685,  -27.1739,  -22.3898,  -19.6424,\n",
      "         -48.1116,  -22.9678,  -42.5949,  -25.1904,  -22.0422, -155.2933,\n",
      "         -19.3862,  -19.1950,  -95.1554,  -28.4998,  -19.5507,  -20.4589,\n",
      "        -108.2546,  -22.7654,  -22.8227,  -24.0757,  -32.1082,  -20.9852,\n",
      "        -160.6546,  -18.9267,  -20.0407,  -18.5216,  -20.2471,  -20.1235,\n",
      "         -19.8413,  -21.8137,  -19.9694,  -20.2865,  -19.2429,  -20.1279,\n",
      "         -56.5631,  -20.8094,  -19.1450,  -19.5004,  -20.1420,  -19.3726,\n",
      "         -22.2878, -105.9289,  -18.8589,  -23.3098,  -19.4910,  -20.2237,\n",
      "         -23.7329,  -97.7361,  -21.5656,  -23.2252,  -19.9260,  -18.9583,\n",
      "         -18.5762,  -61.0186,  -23.1442,  -19.8070,  -25.9964,  -21.0339,\n",
      "         -20.4508,  -20.0116,  -23.2635,  -75.0664,  -21.7319, -109.3741,\n",
      "         -23.6175,  -38.8604,  -42.7567,  -38.7682,  -30.1991,  -30.2477,\n",
      "         -24.9225,  -39.5952,  -67.7099,  -38.0335,  -20.6149,  -21.8921,\n",
      "         -40.7548,  -53.7186,  -19.4525,  -46.4725,  -26.1252,  -26.4403,\n",
      "         -37.1003,  -93.6563,  -34.9027,  -26.8915,  -27.4912,  -21.3506,\n",
      "         -50.7359,  -20.3249,  -63.2050,  -39.3898,  -91.0145,  -95.8525,\n",
      "        -114.0566,  -20.5825,  -47.4933,  -44.5355,  -19.9745,  -25.8029,\n",
      "         -28.9709,  -20.9817,  -21.2860,  -20.7803,  -25.1280,  -20.8677,\n",
      "         -22.5249,  -21.9218, -125.0904,  -25.9235,  -26.8231,  -21.1852,\n",
      "         -58.4071,  -21.4820,  -18.9116,  -32.6261,  -30.1315,  -22.5038,\n",
      "         -23.1751,  -42.0082,  -20.6548,  -21.6131,  -19.4262,  -20.4563,\n",
      "         -19.6850,  -20.6785,  -27.1364,  -18.6846,  -18.4620,  -22.9462,\n",
      "         -19.4059,  -20.0391,  -26.6191,  -20.5346,  -19.9001,  -20.9092,\n",
      "         -20.5465,  -19.4524,  -19.4528,  -20.5441,  -25.6838,  -19.3467,\n",
      "         -22.7141,  -22.4240,  -19.1547,  -24.4619,  -19.4446,  -26.1675,\n",
      "         -26.7221,  -22.8731,  -62.5018,  -21.1842,  -20.2645,  -20.6674,\n",
      "         -19.7612,  -20.1409,  -21.5840,  -23.8148,  -21.2975,  -20.7301,\n",
      "         -20.0089,  -19.3133,  -19.8448,  -25.5449,  -66.1481,  -19.3335,\n",
      "         -21.1794,  -19.9072,  -19.9307,  -20.3191,  -20.8315,  -20.1711,\n",
      "         -23.9362,  -19.7439,  -54.7145,  -20.2136,  -19.8761,  -20.4942,\n",
      "         -23.9818,  -20.8826,  -39.0397,  -20.0600,  -20.2520,  -63.3915,\n",
      "         -20.4929,  -19.9965,  -66.1601,  -24.1325, -102.2746,  -19.4646,\n",
      "         -63.3197,  -19.9071,  -21.4355,  -24.3199,  -31.6910,  -20.1340,\n",
      "         -27.9963,  -37.5890,  -25.6692,  -27.1037,  -27.3187,  -20.9449,\n",
      "         -20.6664,  -22.6640,  -44.1701,  -50.1764,  -39.9493, -152.0214,\n",
      "         -21.4617,  -18.4200,  -25.6022,  -20.7423,  -24.2029,  -57.8951,\n",
      "         -29.9348,  -23.2694,  -24.3304,  -27.0232,  -30.7872,  -22.7741,\n",
      "         -24.5067,  -31.4919,  -22.3043,  -18.7662,  -19.6223,  -96.5905,\n",
      "         -25.3697,  -20.0629,  -21.5764,  -31.7331,  -19.2714,  -38.8800,\n",
      "         -30.4357,  -27.7995,  -28.7196,  -18.9083,  -21.3309, -122.9728,\n",
      "         -21.0085,  -20.3143,  -23.5604,  -26.0328,  -29.1581,  -20.1450,\n",
      "         -23.5657,  -20.5942,  -31.9255,  -32.2931,  -34.7655,  -27.5817,\n",
      "         -26.2462,  -31.1498,  -20.5603,  -31.4044,  -31.6008,  -26.5798,\n",
      "         -25.2568,  -21.7682,  -34.8406,  -59.4243,  -21.1645,  -24.1071,\n",
      "         -48.4743,  -22.0927,  -20.6531,  -22.6500,  -34.6163,  -31.1005,\n",
      "         -21.6031,  -22.9784,  -20.4500,  -32.6895,  -24.5846,  -24.5066,\n",
      "         -22.3078,  -21.3202,  -20.9854,  -19.7043,  -22.4321,  -28.0021,\n",
      "         -22.0835,  -37.4419,  -24.6954,  -19.6669,  -28.8542,  -19.0384,\n",
      "         -20.9091,  -22.5712,  -21.2989,  -22.9580,  -19.9981,  -21.1815,\n",
      "         -54.9161,  -22.1687,  -20.8145,  -20.8540,  -18.9530,  -31.4649,\n",
      "         -22.1762,  -18.9611,  -23.7599,  -35.8653,  -21.1834,  -20.0781,\n",
      "         -30.4951,  -21.8854,  -21.0133,  -20.7816,  -25.6511,  -29.7428,\n",
      "         -30.6864,  -19.3660,  -38.2075,  -24.5361,  -21.8650,  -19.7085,\n",
      "         -20.3310,  -28.7922,  -27.1095,  -22.1310,  -26.9112,  -21.7677,\n",
      "         -20.3484,  -30.9008,  -24.8422,  -20.2546,  -20.3198,  -24.1811,\n",
      "         -18.0398,  -29.2855,  -20.2195,  -19.9925,  -33.7367,  -22.3403,\n",
      "         -19.1863,  -30.0454,  -22.5980,  -21.3577,  -21.8081,  -19.8710,\n",
      "         -19.8615,  -32.9892,  -28.7488,  -20.3271,  -19.3446,  -35.2792,\n",
      "         -21.9810,  -20.6851,  -19.5872,  -22.1361,  -29.9893,  -20.9968,\n",
      "         -19.3840,  -19.3547,  -19.0156,  -26.3542,  -22.2075,  -20.7500,\n",
      "         -20.3514,  -21.0174,  -20.1209,  -23.3051,  -25.1839,  -19.6679,\n",
      "         -24.4271,  -28.0076,  -18.9989,  -20.4168,  -27.3292,  -28.8907,\n",
      "         -20.5702,  -19.6016,  -22.3717,  -21.1066,  -22.7708,  -32.9059,\n",
      "         -24.7617,  -20.2461,  -22.1989,  -26.6405,  -20.8215,  -20.9331,\n",
      "         -25.8760,  -26.7540,  -24.5075,  -29.6614,  -20.9891,  -19.1442,\n",
      "         -30.3023,  -23.5329,  -20.0265,  -22.7262,  -19.6036,  -24.0493,\n",
      "         -22.1573,  -24.7667,  -19.5849,  -35.7106,  -19.9795,  -30.4596,\n",
      "         -27.4220,  -20.1147,  -23.9442,  -24.7669,  -22.8226,  -19.2161,\n",
      "         -32.6947,  -23.1682,  -29.3204,  -20.5564], device='cuda:0')\n",
      "tensor([ -23.7414,  -22.1944,  -21.5923,  -31.3262,  -21.7462,  -26.1315,\n",
      "        -100.2950,  -26.1784,  -18.2866,  -33.0886,  -28.1147,  -21.8549,\n",
      "         -20.6827,  -21.2304,  -22.2701,  -22.8345,  -30.5351,  -21.9056,\n",
      "         -19.7940,  -40.4490,  -33.6399,  -19.9623,  -22.6336,  -19.2288,\n",
      "         -27.6668,  -19.3825,  -34.5789,  -22.7021,  -72.1895,  -23.6700,\n",
      "         -33.4818,  -18.4824,  -22.7495,  -20.9327, -149.7608,  -21.8276,\n",
      "         -76.4961,  -19.0053,  -28.1329,  -20.6291,  -21.0875,  -23.0994,\n",
      "         -64.9365,  -19.3918,  -20.7344,  -22.5534,  -63.8739,  -64.6611,\n",
      "         -23.6421,  -28.1551,  -18.6924,  -19.5680,  -24.2062,  -24.1298,\n",
      "         -19.8269,  -27.3693,  -18.6904,  -19.9173,  -21.8631,  -18.7460,\n",
      "         -95.2120,  -19.7282,  -19.0632,  -77.1853,  -20.6254,  -18.7858,\n",
      "         -86.2019,  -21.7587,  -21.0146,  -17.9202,  -19.4895,  -19.3449,\n",
      "         -22.4431, -124.6332,  -23.1227,  -23.0661,  -25.8018,  -20.3117,\n",
      "        -104.5565,  -66.7656,  -21.8452,  -19.7122, -101.3635,  -27.9182,\n",
      "         -24.4723,  -30.8813,  -22.2704,  -20.8605,  -18.9863,  -19.3238,\n",
      "         -20.6932,  -19.1760,  -88.7190,  -25.2485,  -24.4449,  -25.7591,\n",
      "         -19.0116,  -64.9340,  -20.9496,  -75.9431,  -19.3933,  -21.1560,\n",
      "         -26.2815,  -22.8171,  -22.2934,  -28.1422,  -22.3144,  -44.6443,\n",
      "         -22.2807, -100.4950,  -20.3536,  -23.1206,  -20.2822,  -20.1207,\n",
      "         -20.3270,  -19.6984,  -21.4886,  -19.9562,  -95.8247,  -27.1985,\n",
      "         -20.2123,  -20.4122,  -24.9122,  -19.5747,  -19.0987,  -20.7567,\n",
      "         -21.8934,  -37.1076,  -28.9098,  -20.4314,  -20.0010,  -20.9667,\n",
      "         -20.2757,  -19.1978, -102.3321,  -20.4352,  -21.5385,  -19.8483,\n",
      "         -28.1579,  -19.4214,  -24.7131,  -20.2068,  -21.1694,  -18.4708,\n",
      "         -23.1581,  -21.2778,  -30.2930,  -21.8183,  -21.7256,  -21.9639,\n",
      "         -20.7441,  -34.2780,  -18.6355,  -20.8106,  -21.3620,  -21.0888,\n",
      "         -19.8231,  -19.5293,  -47.9469,  -21.0338,  -21.1827,  -19.3773,\n",
      "         -19.0683,  -22.8054,  -20.8993,  -19.4933,  -19.3830,  -20.2240,\n",
      "         -21.9060,  -21.1461,  -21.2468,  -19.0864,  -20.0063,  -19.9582,\n",
      "         -18.9694,  -20.6037,  -19.9375,  -20.0510,  -19.7359,  -22.1711,\n",
      "         -22.4164,  -19.8075,  -19.6328,  -20.0135,  -20.5082,  -27.0731,\n",
      "         -20.6052,  -18.9876,  -44.9016,  -18.8821,  -22.2365,  -19.7098,\n",
      "         -19.4894,  -22.1581,  -23.8110,  -23.0362,  -19.3510,  -20.4927,\n",
      "         -18.1591,  -20.3849,  -19.1518,  -20.4607,  -33.8068,  -20.5930,\n",
      "         -33.3645,  -19.9179,  -20.7844,  -26.3770,  -27.4119,  -21.9481,\n",
      "         -19.4362,  -26.3123,  -19.4656,  -22.6428,  -21.7990,  -20.6888,\n",
      "         -21.1696,  -19.6336, -101.6030,  -19.7376,  -22.3002,  -24.1875,\n",
      "         -24.3905,  -20.4437,  -22.8758,  -20.8827,  -84.2105,  -28.1681,\n",
      "         -45.8418,  -28.6827,  -19.2185,  -21.9385,  -18.3058,  -26.2388,\n",
      "         -18.9301,  -19.4348,  -37.6613,  -20.1693,  -20.5777,  -27.2523,\n",
      "         -20.0408,  -20.4640,  -23.5224,  -24.5021,  -59.2280,  -19.0883,\n",
      "         -19.9834,  -25.3811,  -40.8559,  -28.0609,  -20.2718,  -23.6181,\n",
      "         -19.0702,  -24.3386,  -20.8027,  -19.3693,  -22.6715,  -50.7610,\n",
      "         -20.0461,  -19.8889,  -21.9150,  -20.8957,  -20.3668,  -70.9649,\n",
      "         -23.8905,  -19.8870,  -19.5899,  -62.9324,  -22.9893,  -26.3887,\n",
      "         -25.3759,  -32.1976,  -50.1747,  -18.9028,  -23.5855,  -23.5225,\n",
      "         -22.1377,  -20.3001,  -20.4324,  -21.0393,  -29.1660,  -37.5379,\n",
      "         -28.8290,  -20.5675,  -20.9063,  -21.1314,  -19.8421,  -26.9104,\n",
      "         -19.1395,  -22.8301,  -20.3106,  -20.8052,  -44.6920,  -26.0168,\n",
      "         -33.0927,  -53.5103,  -26.9268,  -23.7141,  -20.5091, -151.4717,\n",
      "        -174.1595,  -18.8753,  -20.3203,  -31.0325,  -25.6894,  -22.1943,\n",
      "         -21.7276,  -20.7835, -175.9625,  -23.7787,  -48.7145, -106.6399,\n",
      "         -23.7528,  -22.2945,  -56.5090,  -24.2472,  -21.3694,  -21.8074,\n",
      "        -146.6731,  -19.1199,  -57.4118,  -22.5152, -101.2430,  -37.3953,\n",
      "         -35.3522,  -26.5454,  -42.8660,  -26.3090, -145.4625,  -29.1862,\n",
      "         -23.0904,  -27.0734,  -21.2941,  -28.9167,  -73.7934,  -44.5230,\n",
      "         -33.2268,  -35.2465,  -21.8084,  -87.3878,  -22.9724,  -28.9157,\n",
      "         -19.3171,  -18.3591,  -20.2626,  -28.6784,  -19.5301,  -19.3397,\n",
      "         -19.1800,  -20.0951,  -23.4907,  -23.8931,  -20.8609,  -21.9984,\n",
      "        -114.1596,  -26.1279,  -33.5870,  -25.4836,  -23.4087,  -21.9996,\n",
      "         -29.8411,  -21.6610,  -18.1367,  -90.5724,  -22.2380,  -19.3422,\n",
      "         -27.7955, -134.6287,  -19.2656, -133.2681,  -28.8018,  -20.1687,\n",
      "        -134.7085,  -29.4272,  -20.1294,  -19.4458,  -27.7151,  -19.2755,\n",
      "         -20.0543,  -25.3528,  -21.8238,  -61.0433,  -22.0123,  -61.7280,\n",
      "         -22.6415,  -19.6758,  -19.6755,  -19.4931,  -20.0363,  -18.7383,\n",
      "         -21.1171, -154.1292,  -21.7866,  -20.3177,  -20.7875,  -19.4832,\n",
      "         -20.4092,  -19.7100,  -20.2614,  -20.3276,  -21.6872,  -28.2009,\n",
      "         -19.6449,  -51.1601,  -20.0763,  -28.4117,  -19.3265,  -28.2985,\n",
      "         -19.9328,  -19.2246,  -19.3038,  -32.1100,  -20.1427,  -19.3364,\n",
      "         -21.3504,  -22.0447, -133.4671,  -21.4379,  -20.0113, -107.7600,\n",
      "         -28.3683,  -19.1812,  -18.2694,  -19.2871,  -22.3131,  -72.5126,\n",
      "         -34.7079,  -19.6880,  -20.6370,  -19.4775,  -21.4377,  -21.6081,\n",
      "         -20.7930,  -20.3527,  -23.4464,  -24.4618,  -19.0895,  -26.1103,\n",
      "         -40.1690,  -18.8397,  -37.0436,  -21.9244,  -19.5606,  -32.1535,\n",
      "         -20.0806,  -21.3113,  -19.7222,  -21.3002,  -22.6928,  -28.2896,\n",
      "         -19.4963,  -20.6048,  -28.8562,  -22.6983,  -23.6444,  -25.2453,\n",
      "         -21.7288,  -21.0360,  -19.8519,  -21.3111,  -20.0147,  -19.0973,\n",
      "         -21.3854,  -21.0057,  -20.4829,  -30.3466,  -27.2073,  -19.4102,\n",
      "         -19.1798,  -26.7581,  -19.3576,  -18.8751,  -20.4489,  -19.1546,\n",
      "         -22.2169,  -33.6666,  -22.7893,  -20.6002,  -19.8046,  -20.0437,\n",
      "         -20.6498,  -19.0110,  -21.9998,  -28.6332,  -28.5102,  -30.2868,\n",
      "         -27.5831,  -23.5578,  -39.4255,  -25.0840,  -27.3828,  -29.4508,\n",
      "         -22.8128,  -22.3044,  -19.9049,  -22.1901,  -18.9488,  -20.4462,\n",
      "         -19.9733,  -29.4948,  -26.9733,  -21.5068,  -22.1812,  -19.4503,\n",
      "         -39.2696,  -28.4229,  -19.6263,  -73.2426,  -19.2871,  -20.3311,\n",
      "         -33.5857,  -37.8264,  -21.3390,  -22.4278,  -22.2234,  -20.2279,\n",
      "         -20.1801,  -22.6617,  -20.6226,  -95.7987,  -26.4037,  -81.1960,\n",
      "         -19.2782,  -18.7131,  -26.0387,  -18.4909,  -20.1511,  -20.6988,\n",
      "         -22.3968,  -27.6256,  -19.2034,  -39.3492,  -22.0357,  -22.4424,\n",
      "         -21.8971,  -20.1715,  -21.5944,  -20.1451,  -29.7755,  -37.8247,\n",
      "         -20.0457,  -21.5545,  -34.1017,  -18.9858,  -20.5555,  -21.7028,\n",
      "         -18.7967,  -21.4029,  -32.4159,  -18.9316,  -36.8436,  -34.4400,\n",
      "         -39.2693,  -40.0283,  -20.3400,  -26.2175,  -19.1651,  -22.5676,\n",
      "         -59.1217,  -32.5178,  -32.1854,  -45.1102,  -29.0959,  -20.1835,\n",
      "         -47.2305,  -20.0415,  -19.1026,  -36.8951,  -28.9440,  -26.0516,\n",
      "         -55.8916,  -30.3050,  -43.9063,  -29.6385,  -23.6563,  -20.2183,\n",
      "        -142.4949,  -46.6739,  -19.4209,  -19.4493,  -19.8115,  -21.0999,\n",
      "         -20.3583,  -75.3214,  -20.9740,  -22.2800,  -19.7145,  -22.3922,\n",
      "         -21.2739, -105.6106,  -22.5935,  -21.7448,  -20.8040,  -20.9518,\n",
      "         -48.9499,  -22.1826,  -38.2393,  -24.1734,  -20.4445, -155.3555,\n",
      "         -21.8349,  -20.4803, -101.7673,  -39.9383,  -19.7493,  -19.7547,\n",
      "         -96.1497,  -27.4081,  -19.7928,  -26.1223,  -20.9850,  -22.1198,\n",
      "        -164.0090,  -23.7266,  -20.2741,  -20.8542,  -19.3130,  -18.5765,\n",
      "         -18.4736,  -19.7222,  -19.8598,  -23.6801,  -19.4130,  -23.2369,\n",
      "         -50.5035,  -20.8314,  -18.8535,  -20.1235,  -19.1815,  -19.0637,\n",
      "         -19.9687, -100.1921,  -19.2957,  -21.2485,  -22.1561,  -18.8291,\n",
      "         -28.8213,  -96.7011,  -25.1511,  -19.1884,  -21.4991,  -21.5184,\n",
      "         -24.1631,  -68.3329,  -24.8263,  -21.5353,  -23.3771,  -20.3200,\n",
      "         -20.6656,  -19.4622,  -23.5372,  -67.6326,  -21.8246, -119.0867,\n",
      "         -20.9487,  -48.1161,  -41.3495,  -31.7043,  -31.8113,  -32.8392,\n",
      "         -22.6101,  -36.8577,  -75.7076,  -39.8487,  -20.3503,  -21.2714,\n",
      "         -38.6643,  -46.7160,  -20.1295,  -43.7026,  -25.2021,  -24.5763,\n",
      "         -39.7539,  -93.0381,  -28.9783,  -25.5122,  -23.8943,  -35.0147,\n",
      "         -40.2334,  -19.5845,  -65.0284,  -39.2429,  -93.3872,  -99.4968,\n",
      "         -68.9711,  -24.9067,  -51.7292,  -49.9878,  -28.1462,  -25.4262,\n",
      "         -23.4704,  -21.0553,  -20.0336,  -21.6009,  -25.1922,  -22.2561,\n",
      "         -22.5074,  -20.8250, -129.7567,  -22.3028,  -22.6299,  -18.8519,\n",
      "         -66.0573,  -31.7073,  -19.3462,  -22.2653,  -20.3919,  -19.9153,\n",
      "         -22.1200,  -32.8977,  -19.9058,  -24.3435,  -19.4474,  -20.6267,\n",
      "         -20.4624,  -18.7744,  -20.6682,  -22.0794,  -23.7434,  -21.2041,\n",
      "         -20.4555,  -19.2850,  -26.5584,  -22.8401,  -19.2047,  -21.0420,\n",
      "         -19.9349,  -22.8513,  -24.4339,  -18.7657,  -24.9281,  -20.6694,\n",
      "         -19.2806,  -19.9179,  -18.8917,  -19.9511,  -28.9936,  -21.8214,\n",
      "         -22.3235,  -25.0222,  -61.8866,  -26.0933,  -19.0418,  -24.8628,\n",
      "         -21.3634,  -35.5124,  -21.2871,  -20.1774,  -18.8432,  -19.9284,\n",
      "         -20.8744,  -20.1297,  -19.2175,  -21.0829,  -60.7937,  -19.0154,\n",
      "         -20.7212,  -19.3701,  -19.9208,  -20.6003,  -23.3193,  -19.6421,\n",
      "         -20.7851,  -18.3520,  -47.6663,  -20.9653,  -28.8184,  -20.0164,\n",
      "         -20.9625,  -19.8256,  -35.5769,  -34.7962,  -27.0133,  -62.2022,\n",
      "         -19.6906,  -21.7157,  -74.0612,  -24.3455,  -99.0810,  -19.3960,\n",
      "         -58.9041,  -19.9178,  -22.1360,  -22.4715,  -34.1431,  -26.0304,\n",
      "         -19.1659,  -37.5076,  -22.3934,  -32.1883,  -35.3240,  -20.9052,\n",
      "         -22.1050,  -25.1280,  -45.1890,  -49.6412,  -39.1204, -153.2749,\n",
      "         -21.5313,  -18.4928,  -27.3913,  -22.3539,  -23.2397,  -63.7217,\n",
      "         -29.5059,  -27.3700,  -28.1675,  -19.9788,  -22.6990,  -22.2408,\n",
      "         -30.4664,  -35.8323,  -22.0893,  -19.3286,  -19.5886,  -92.8310,\n",
      "         -21.8584,  -19.8559,  -23.9354,  -30.5432,  -21.4382,  -22.3612,\n",
      "         -30.9615,  -26.2535,  -28.7665,  -20.3325,  -31.9217, -124.2435,\n",
      "         -21.2168,  -22.1333,  -20.9169,  -35.6882,  -25.0455,  -22.9842,\n",
      "         -22.5008,  -19.6798,  -29.6025,  -27.8907,  -36.1069,  -29.5258,\n",
      "         -31.3315,  -27.8750,  -20.9382,  -25.3721,  -21.6554,  -37.0185,\n",
      "         -26.3242,  -19.3159,  -42.9715,  -49.5710,  -21.3503,  -21.2778,\n",
      "         -34.4319,  -20.9991,  -20.5961,  -20.5735,  -34.1989,  -38.8158,\n",
      "         -20.9126,  -20.6092,  -24.8232,  -32.6064,  -22.4800,  -22.0278,\n",
      "         -21.9607,  -20.3865,  -20.9435,  -19.1484,  -24.4922,  -25.4131,\n",
      "         -20.7309,  -43.3316,  -25.6628,  -24.5368,  -30.9110,  -19.6151,\n",
      "         -24.5932,  -21.1648,  -21.2181,  -21.4293,  -19.0993,  -26.3071,\n",
      "         -45.4552,  -20.0552,  -24.4747,  -23.2210,  -19.6061,  -25.5967,\n",
      "         -23.9187,  -22.2924,  -19.9407,  -33.0696,  -19.9665,  -22.0013,\n",
      "         -35.0539,  -25.5286,  -20.7760,  -18.7839,  -26.8678,  -20.9056,\n",
      "         -33.9515,  -21.4294,  -40.3991,  -21.4611,  -18.9037,  -19.1374,\n",
      "         -18.6408,  -19.7507,  -21.9757,  -19.7454,  -30.4574,  -26.5345,\n",
      "         -20.1327,  -26.8578,  -19.6878,  -20.1110,  -22.5045,  -23.9619,\n",
      "         -21.9502,  -22.1214,  -20.7424,  -20.7369,  -34.0704,  -21.5231,\n",
      "         -22.5330,  -28.0617,  -21.3775,  -20.5648,  -25.1925,  -21.8052,\n",
      "         -20.2256,  -33.6437,  -30.9762,  -24.6121,  -22.4565,  -19.2410,\n",
      "         -19.4463,  -18.8098,  -19.3076,  -32.0710,  -26.4763,  -20.2993,\n",
      "         -19.2297,  -27.9167,  -24.4022,  -28.1947,  -21.6182,  -19.6301,\n",
      "         -23.7662,  -21.3795,  -22.4178,  -23.1910,  -29.6790,  -20.2760,\n",
      "         -21.5071,  -26.6255,  -20.4326,  -20.8704,  -25.1431,  -34.2541,\n",
      "         -20.6542,  -31.4647,  -19.4008,  -19.3451,  -22.2031,  -31.6904,\n",
      "         -21.6193,  -19.8021,  -20.9036,  -27.7156,  -21.6759,  -20.8354,\n",
      "         -26.0192,  -30.3399,  -26.3047,  -32.0497,  -20.3212,  -20.5938,\n",
      "         -30.8238,  -28.1920,  -20.7216,  -23.6297,  -19.2866,  -24.4851,\n",
      "         -20.7279,  -23.4868,  -25.1581,  -36.9746,  -21.2095,  -33.4180,\n",
      "         -28.2128,  -21.6136,  -21.5430,  -21.3251,  -21.3329,  -19.5341,\n",
      "         -32.5495,  -23.3990,  -27.8918,  -20.3835], device='cuda:0')\n",
      "tensor([ -23.5909,  -22.0925,  -23.9266,  -34.9562,  -18.8722,  -34.7511,\n",
      "        -104.7360,  -19.2351,  -19.0234,  -28.8051,  -26.9534,  -22.0472,\n",
      "         -21.1185,  -19.7851,  -20.1340,  -27.1393,  -46.1104,  -19.6972,\n",
      "         -19.1018,  -39.2456,  -42.5239,  -19.6776,  -22.2845,  -21.3681,\n",
      "         -20.9574,  -19.9966,  -20.0342,  -22.2727,  -74.2815,  -21.8391,\n",
      "         -21.6455,  -20.3909,  -21.5330,  -19.5818, -152.1294,  -27.2063,\n",
      "         -74.8469,  -19.1246,  -20.7747,  -22.7387,  -18.7031,  -22.7647,\n",
      "         -69.4725,  -19.4436,  -19.0110,  -18.4853,  -63.6024,  -50.4270,\n",
      "         -28.1826,  -23.8818,  -19.2914,  -27.8855,  -18.9491,  -21.7492,\n",
      "         -20.0075,  -20.1897,  -22.4998,  -19.7013,  -18.9726,  -20.5458,\n",
      "         -99.7998,  -19.8253,  -19.6447,  -76.6075,  -19.7095,  -21.8185,\n",
      "         -74.5782,  -21.9594,  -20.6584,  -19.5255,  -19.2290,  -20.3035,\n",
      "         -22.1913, -125.0887,  -20.9106,  -23.5461,  -26.0817,  -19.7074,\n",
      "        -109.5823,  -58.2396,  -18.6046,  -20.0791,  -94.4413,  -21.0712,\n",
      "         -21.4952,  -20.0501,  -21.5937,  -20.2418,  -19.2751,  -20.0468,\n",
      "         -19.7702,  -28.2131,  -86.7291,  -26.1686,  -21.4097,  -20.2724,\n",
      "         -19.2837,  -61.3693,  -18.3721,  -78.5267,  -19.2285,  -19.4650,\n",
      "         -18.6019,  -25.4528,  -19.8551,  -19.1169,  -24.5494,  -42.6910,\n",
      "         -20.0534,  -67.6345,  -27.1378,  -19.1005,  -19.3660,  -19.8853,\n",
      "         -20.3922,  -22.8953,  -19.9521,  -19.2754,  -88.5872,  -23.8530,\n",
      "         -19.5209,  -20.2846,  -21.6447,  -19.9120,  -21.3117,  -24.3971,\n",
      "         -23.9226,  -19.7683,  -30.3918,  -22.4884,  -23.1669,  -20.2074,\n",
      "         -20.0816,  -21.2031, -106.7016,  -23.3054,  -24.3260,  -19.8786,\n",
      "         -21.5988,  -21.8179,  -22.5497,  -21.2498,  -20.0863,  -20.1191,\n",
      "         -19.8226,  -24.4811,  -21.7749,  -19.1113,  -25.1671,  -20.1295,\n",
      "         -21.2518,  -34.5822,  -25.2459,  -22.0559,  -19.9472,  -19.4987,\n",
      "         -19.6465,  -21.0161,  -47.9381,  -21.4284,  -20.5579,  -21.0243,\n",
      "         -19.4673,  -20.5438,  -18.7290,  -25.3907,  -30.1307,  -21.6287,\n",
      "         -20.1422,  -19.7873,  -19.4947,  -20.1167,  -25.4335,  -34.7992,\n",
      "         -19.6666,  -22.6439,  -18.8027,  -19.2995,  -22.3205,  -22.6838,\n",
      "         -21.2084,  -20.4106,  -23.6771,  -20.2229,  -25.9532,  -31.8206,\n",
      "         -20.4767,  -20.6291,  -44.6862,  -25.8539,  -19.8768,  -25.8386,\n",
      "         -19.0085,  -19.2685,  -19.0953,  -21.5217,  -19.2895,  -20.1572,\n",
      "         -22.2878,  -18.8308,  -22.3017,  -22.1145,  -21.6837,  -20.8343,\n",
      "         -19.2638,  -19.3281,  -21.3654,  -19.4685,  -20.4426,  -30.0686,\n",
      "         -26.3558,  -31.4773,  -22.1636,  -20.4455,  -22.1565,  -20.2145,\n",
      "         -20.9624,  -20.6908, -106.5350,  -22.3091,  -21.6411,  -21.3218,\n",
      "         -20.0813,  -22.5298,  -20.3291,  -21.9393,  -70.6516,  -20.1738,\n",
      "         -46.8777,  -28.3748,  -20.1131,  -23.2197,  -22.5360,  -18.8234,\n",
      "         -18.8134,  -19.7524,  -36.9311,  -20.2166,  -19.0596,  -26.8815,\n",
      "         -21.2716,  -19.7624,  -21.6006,  -24.6553,  -62.1631,  -23.3222,\n",
      "         -19.7774,  -24.6173,  -23.5764,  -21.1248,  -24.5573,  -25.3310,\n",
      "         -20.7523,  -21.9951,  -23.3281,  -19.7891,  -20.4794,  -46.7617,\n",
      "         -19.4248,  -20.3278,  -23.4004,  -24.9395,  -20.7852,  -76.1212,\n",
      "         -20.6262,  -19.3684,  -23.0629,  -62.1270,  -21.0118,  -22.3130,\n",
      "         -20.6674,  -31.7901,  -49.3846,  -20.4029,  -21.0313,  -20.7719,\n",
      "         -22.7778,  -24.0129,  -20.9815,  -21.5039,  -20.1517,  -36.1085,\n",
      "         -26.9151,  -30.5367,  -22.6157,  -27.9181,  -22.0126,  -23.9248,\n",
      "         -19.5358,  -20.8048,  -21.6377,  -22.5578,  -44.4015,  -22.6435,\n",
      "         -18.8920,  -47.6170,  -37.8621,  -22.4837,  -20.1531, -154.9145,\n",
      "        -176.1105,  -19.4079,  -19.4651,  -27.4184,  -25.3013,  -18.9921,\n",
      "         -21.7751,  -20.8863, -183.2320,  -33.0430,  -48.6315, -108.8499,\n",
      "         -22.4218,  -20.8468,  -58.1696,  -21.3594,  -22.2209,  -33.4972,\n",
      "        -148.7354,  -20.5927,  -57.1802,  -19.5996,  -96.8765,  -34.4609,\n",
      "         -35.0151,  -26.4860,  -26.5044,  -26.4511, -146.7798,  -22.0000,\n",
      "         -29.2285,  -26.7779,  -19.0842,  -30.4758,  -71.5049,  -43.4849,\n",
      "         -24.3398,  -35.6150,  -21.7254,  -87.9955,  -21.9081,  -32.4640,\n",
      "         -18.9307,  -21.7789,  -22.6585,  -23.7272,  -23.0583,  -26.8516,\n",
      "         -19.5579,  -24.1141,  -22.8271,  -32.7408,  -22.9565,  -20.2374,\n",
      "        -118.0842,  -21.9686,  -23.8616,  -22.1125,  -20.6408,  -21.3805,\n",
      "         -33.6761,  -23.7336,  -18.6722,  -88.3597,  -20.7717,  -19.3785,\n",
      "         -18.8794, -135.3350,  -19.8783, -138.0171,  -27.4580,  -23.5459,\n",
      "        -136.7342,  -22.0889,  -27.3857,  -19.3350,  -24.6082,  -19.5582,\n",
      "         -21.5939,  -28.1127,  -32.7053,  -60.5212,  -22.2086,  -61.5502,\n",
      "         -22.1971,  -20.0796,  -29.8098,  -19.3373,  -22.4991,  -18.5365,\n",
      "         -22.2518, -149.6328,  -26.1863,  -19.0842,  -23.3041,  -20.0857,\n",
      "         -21.6104,  -18.9598,  -20.6304,  -20.6295,  -20.4265,  -23.6002,\n",
      "         -28.1189,  -46.6901,  -19.4660,  -20.5828,  -19.5093,  -20.5026,\n",
      "         -26.9064,  -21.2723,  -19.5430,  -24.5475,  -23.0986,  -20.7371,\n",
      "         -18.3918,  -20.0393, -133.5581,  -21.1979,  -20.5938, -105.0447,\n",
      "         -22.1397,  -21.7869,  -18.8067,  -18.5296,  -21.3310,  -85.8459,\n",
      "         -22.3616,  -27.3571,  -25.2037,  -21.0483,  -21.3116,  -20.1643,\n",
      "         -22.0709,  -19.2519,  -19.2434,  -23.0007,  -21.1818,  -21.2777,\n",
      "         -19.7270,  -18.8401,  -32.7330,  -23.7056,  -18.9379,  -32.7566,\n",
      "         -24.6232,  -24.5439,  -19.7711,  -19.5983,  -20.0749,  -26.5480,\n",
      "         -22.5452,  -19.4731,  -29.8426,  -21.0390,  -20.2569,  -23.1194,\n",
      "         -19.1422,  -21.6683,  -22.4330,  -20.0449,  -45.3881,  -19.3237,\n",
      "         -19.0485,  -19.9134,  -19.4075,  -21.9088,  -23.1947,  -19.4259,\n",
      "         -20.3858,  -19.0344,  -18.5932,  -19.5285,  -19.1220,  -19.7362,\n",
      "         -18.9950,  -18.6714,  -24.7253,  -19.5256,  -20.4735,  -19.9533,\n",
      "         -25.4842,  -19.7906,  -22.6675,  -36.1526,  -26.7358,  -41.5946,\n",
      "         -26.6179,  -30.2230,  -21.7972,  -19.9865,  -23.8893,  -30.7369,\n",
      "         -20.6707,  -20.8064,  -19.8535,  -27.8756,  -20.1471,  -20.7804,\n",
      "         -19.1653,  -26.5137,  -29.9676,  -23.7481,  -19.9050,  -21.0049,\n",
      "         -29.0861,  -23.9883,  -22.8729,  -73.1796,  -21.6653,  -22.1925,\n",
      "         -25.3621,  -38.8882,  -23.3918,  -22.6431,  -23.0006,  -22.2684,\n",
      "         -19.7687,  -20.3986,  -21.4983,  -96.0694,  -23.7529,  -79.0975,\n",
      "         -19.5948,  -19.1313,  -20.8197,  -23.8123,  -20.1202,  -24.6711,\n",
      "         -21.1482,  -26.1616,  -18.7139,  -39.7543,  -27.4817,  -20.6058,\n",
      "         -19.7638,  -22.0635,  -18.6094,  -22.5561,  -25.1959,  -44.6739,\n",
      "         -32.2930,  -19.3367,  -31.0937,  -22.8678,  -29.7390,  -24.7989,\n",
      "         -22.3864,  -20.3239,  -35.9527,  -18.8358,  -39.3992,  -22.6192,\n",
      "         -42.5459,  -49.0614,  -20.0368,  -24.3105,  -19.6040,  -23.9628,\n",
      "         -60.1454,  -36.3494,  -34.1166,  -55.2442,  -29.2039,  -20.4719,\n",
      "         -42.0218,  -21.2212,  -22.3271,  -46.5877,  -37.3840,  -28.5262,\n",
      "         -41.0984,  -19.1401,  -50.8713,  -31.1137,  -24.9477,  -22.8719,\n",
      "        -143.9394,  -50.1328,  -21.5299,  -21.0739,  -18.7598,  -19.5553,\n",
      "         -20.5943,  -77.1797,  -20.4034,  -25.4474,  -21.9093,  -21.2113,\n",
      "         -20.0095, -106.5833,  -24.3559,  -27.4528,  -25.2534,  -20.0446,\n",
      "         -46.8137,  -20.6942,  -46.5368,  -21.3139,  -19.9083, -156.4562,\n",
      "         -20.0261,  -20.4828,  -98.2985,  -38.3405,  -20.7294,  -23.1866,\n",
      "         -99.8218,  -20.4220,  -19.9444,  -27.3385,  -18.9056,  -25.7753,\n",
      "        -160.1639,  -21.2459,  -20.5436,  -18.6532,  -20.9086,  -18.6572,\n",
      "         -20.0589,  -22.6656,  -18.7191,  -19.7253,  -20.0278,  -21.0280,\n",
      "         -51.0700,  -25.2477,  -19.2556,  -20.7532,  -20.1178,  -20.7728,\n",
      "         -18.3496, -105.8177,  -27.3612,  -19.7333,  -19.6418,  -18.6996,\n",
      "         -19.6147,  -95.4039,  -21.3295,  -19.5211,  -19.7080,  -19.2456,\n",
      "         -19.6743,  -68.7045,  -21.7216,  -19.5544,  -23.0277,  -22.8079,\n",
      "         -20.8794,  -20.6431,  -24.2413,  -58.8615,  -22.9797, -110.8200,\n",
      "         -23.4202,  -41.2566,  -41.4874,  -31.1501,  -31.5765,  -31.2392,\n",
      "         -23.2045,  -41.6223,  -67.7661,  -35.3940,  -30.0558,  -21.5598,\n",
      "         -44.7198,  -53.2260,  -19.2639,  -46.8579,  -25.7755,  -26.8167,\n",
      "         -44.3432,  -96.4450,  -33.2533,  -24.6761,  -27.1874,  -19.9322,\n",
      "         -47.5764,  -23.0738,  -65.1827,  -36.5249,  -91.7225, -105.7050,\n",
      "         -66.3289,  -24.6094,  -50.9047,  -58.1807,  -21.0429,  -27.8296,\n",
      "         -25.3712,  -21.2974,  -20.6291,  -21.9861,  -26.6473,  -34.3679,\n",
      "         -21.0041,  -21.5322, -125.0838,  -20.1856,  -27.2323,  -20.8849,\n",
      "         -60.5060,  -23.7379,  -19.3954,  -20.0066,  -21.3461,  -25.7047,\n",
      "         -21.9991,  -25.6220,  -22.5980,  -20.9367,  -19.1178,  -21.7644,\n",
      "         -22.3782,  -19.6307,  -19.7102,  -21.0489,  -23.7092,  -19.0662,\n",
      "         -19.2992,  -19.2062,  -19.8924,  -20.4596,  -20.7231,  -19.8171,\n",
      "         -18.9859,  -22.9914,  -19.8238,  -18.9244,  -22.2530,  -20.0385,\n",
      "         -19.4688,  -27.3771,  -18.9684,  -19.4978,  -18.6925,  -30.2730,\n",
      "         -21.4499,  -18.8236,  -61.8740,  -19.4786,  -19.7719,  -20.3304,\n",
      "         -20.5061,  -19.8992,  -20.4835,  -22.8579,  -22.2556,  -19.8492,\n",
      "         -19.6982,  -20.3031,  -21.4857,  -26.7636,  -61.1636,  -19.7367,\n",
      "         -19.4462,  -29.1682,  -22.3296,  -27.2082,  -24.6199,  -19.3481,\n",
      "         -23.6438,  -19.9952,  -52.7685,  -20.5150,  -22.7904,  -21.0231,\n",
      "         -21.4422,  -24.1797,  -37.3283,  -20.0907,  -26.6999,  -60.9013,\n",
      "         -23.3295,  -19.4010,  -65.5339,  -23.1071, -101.4655,  -20.0711,\n",
      "         -57.8397,  -21.4357,  -21.4898,  -28.9238,  -30.5938,  -19.0467,\n",
      "         -22.6218,  -37.3324,  -19.4151,  -38.3724,  -24.8173,  -21.3290,\n",
      "         -20.4897,  -19.4656,  -45.3132,  -50.4714,  -39.7768, -147.6956,\n",
      "         -21.7870,  -40.0637,  -34.6965,  -22.3233,  -24.7047,  -55.7501,\n",
      "         -29.8161,  -23.0772,  -26.8542,  -19.6913,  -30.9772,  -23.2079,\n",
      "         -23.1663,  -33.8283,  -27.7522,  -18.8911,  -20.9107, -105.7233,\n",
      "         -19.8288,  -22.7563,  -21.3852,  -31.0951,  -19.4110,  -18.9883,\n",
      "         -31.3406,  -21.1383,  -29.6603,  -22.9717,  -21.3282, -120.0515,\n",
      "         -21.4485,  -25.6965,  -21.6597,  -18.7496,  -25.0650,  -22.7172,\n",
      "         -22.3938,  -22.4510,  -32.3680,  -37.1907,  -33.1168,  -27.3559,\n",
      "         -25.8733,  -36.1384,  -20.1764,  -27.6855,  -21.5835,  -27.0205,\n",
      "         -23.2347,  -32.4923,  -42.0425,  -53.6991,  -22.3742,  -21.0183,\n",
      "         -40.8064,  -30.2703,  -22.3528,  -21.4151,  -33.5875,  -32.8075,\n",
      "         -20.7390,  -21.0433,  -20.5397,  -32.6350,  -21.0924,  -21.6025,\n",
      "         -22.4720,  -20.8448,  -24.8583,  -18.9537,  -22.1782,  -31.0085,\n",
      "         -23.1015,  -37.3432,  -24.7929,  -18.9591,  -24.9815,  -22.0720,\n",
      "         -20.3835,  -22.3126,  -19.9303,  -21.3947,  -20.3235,  -20.8509,\n",
      "         -59.9033,  -19.2188,  -23.0285,  -19.8191,  -19.4634,  -25.1794,\n",
      "         -25.2522,  -21.3853,  -19.7964,  -31.0206,  -30.2900,  -20.4809,\n",
      "         -37.7223,  -21.4867,  -20.8275,  -20.7424,  -25.4084,  -20.9505,\n",
      "         -31.8808,  -22.9800,  -42.0221,  -22.1562,  -19.2021,  -20.8585,\n",
      "         -19.2639,  -30.5577,  -19.1689,  -19.5225,  -30.8039,  -24.0015,\n",
      "         -19.0389,  -25.1109,  -26.6872,  -19.3881,  -20.4918,  -26.8639,\n",
      "         -18.8696,  -19.5737,  -19.8257,  -23.7416,  -33.4685,  -24.2130,\n",
      "         -18.9888,  -32.6229,  -19.4094,  -20.6217,  -19.5506,  -21.0505,\n",
      "         -22.2654,  -39.9510,  -29.3492,  -20.4471,  -21.2296,  -21.9878,\n",
      "         -21.7158,  -19.3249,  -19.6440,  -20.8358,  -27.3304,  -21.1874,\n",
      "         -19.7546,  -22.8225,  -25.9535,  -27.5270,  -24.6907,  -20.3325,\n",
      "         -24.3438,  -19.5558,  -22.1224,  -22.1117,  -24.9396,  -30.4653,\n",
      "         -22.8905,  -26.1996,  -21.6838,  -20.2666,  -25.8939,  -30.5519,\n",
      "         -21.1403,  -22.9302,  -20.6259,  -23.4859,  -21.9325,  -30.6320,\n",
      "         -19.7577,  -20.7840,  -20.3429,  -25.1898,  -31.5656,  -21.7107,\n",
      "         -33.9404,  -25.9243,  -32.1173,  -32.6748,  -20.7304,  -19.0792,\n",
      "         -29.4560,  -26.8223,  -20.9398,  -22.3252,  -24.4552,  -24.9827,\n",
      "         -19.8953,  -24.7858,  -20.4453,  -34.0017,  -20.0112,  -34.4059,\n",
      "         -30.0798,  -21.2864,  -24.0691,  -23.9348,  -19.9997,  -19.8602,\n",
      "         -32.3338,  -22.8836,  -33.2714,  -20.2214], device='cuda:0')\n",
      "tensor([ -28.0735,  -20.2133,  -23.6639,  -42.9810,  -19.1305,  -26.2575,\n",
      "        -100.0328,  -21.5758,  -20.7946,  -40.1988,  -26.7856,  -20.1369,\n",
      "         -21.3327,  -19.2855,  -22.0449,  -20.3281,  -38.7126,  -19.9391,\n",
      "         -21.4644,  -35.6442,  -37.1005,  -20.0746,  -22.8571,  -30.5853,\n",
      "         -21.3790,  -26.1413,  -24.7825,  -18.8752,  -72.9488,  -20.0887,\n",
      "         -21.9213,  -27.5610,  -22.2767,  -21.0572, -150.4258,  -19.8052,\n",
      "         -78.4949,  -24.7200,  -29.1699,  -20.3650,  -23.6322,  -22.8901,\n",
      "         -61.7479,  -19.4230,  -18.5431,  -23.5720,  -65.2450,  -50.3076,\n",
      "         -20.2291,  -19.3643,  -33.6706,  -19.9591,  -21.8420,  -20.5394,\n",
      "         -21.1504,  -20.0416,  -19.1363,  -19.3136,  -19.8821,  -19.8840,\n",
      "        -100.1040,  -20.6295,  -18.7770,  -79.2638,  -19.9295,  -21.8248,\n",
      "         -79.2522,  -18.9858,  -19.7025,  -20.5512,  -21.2874,  -23.7799,\n",
      "         -19.6794, -124.0889,  -18.6172,  -29.9285,  -21.4831,  -22.1311,\n",
      "        -105.3369,  -57.6419,  -19.3407,  -19.0562,  -93.5720,  -18.6889,\n",
      "         -29.2605,  -22.4493,  -20.0039,  -19.9988,  -30.6426,  -19.8171,\n",
      "         -22.9230,  -24.5204,  -84.5682,  -26.4387,  -20.9861,  -20.8488,\n",
      "         -22.8738,  -67.9618,  -18.8878,  -74.8182,  -21.2178,  -21.2227,\n",
      "         -21.8432,  -19.6545,  -20.3217,  -18.7368,  -19.6635,  -43.8030,\n",
      "         -20.2648,  -71.4950,  -29.5239,  -19.5141,  -18.5564,  -20.2567,\n",
      "         -19.8363,  -27.7025,  -21.5547,  -22.7108,  -90.9966,  -23.2573,\n",
      "         -21.1487,  -19.2624,  -20.5020,  -24.1606,  -23.8704,  -21.7391,\n",
      "         -22.8796,  -19.9347,  -27.3295,  -19.6422,  -32.0034,  -21.7683,\n",
      "         -20.5955,  -22.5851, -100.2142,  -20.1048,  -21.4335,  -19.6899,\n",
      "         -26.3690,  -19.1404,  -19.4960,  -20.9787,  -21.0598,  -20.2065,\n",
      "         -23.3001,  -20.6055,  -20.6717,  -21.1678,  -19.1808,  -26.8916,\n",
      "         -19.4304,  -33.8861,  -19.2533,  -26.3318,  -24.4244,  -21.8342,\n",
      "         -19.9154,  -19.3707,  -50.5478,  -25.5064,  -25.2268,  -31.0989,\n",
      "         -19.8550,  -19.3909,  -19.3702,  -19.1915,  -22.1049,  -20.0388,\n",
      "         -21.5488,  -21.6323,  -26.7810,  -25.1750,  -20.8081,  -25.6223,\n",
      "         -19.5488,  -28.8275,  -19.8619,  -20.5824,  -19.2147,  -22.0174,\n",
      "         -24.8686,  -19.6749,  -19.3492,  -18.6322,  -20.4319,  -19.6094,\n",
      "         -25.8646,  -19.1245,  -44.3025,  -23.6926,  -25.0516,  -20.0448,\n",
      "         -31.9614,  -24.3019,  -19.2002,  -25.2427,  -19.7157,  -22.6720,\n",
      "         -20.7451,  -19.6150,  -18.9602,  -19.5355,  -20.6641,  -22.1541,\n",
      "         -18.9665,  -24.7238,  -21.2436,  -20.8667,  -19.0796,  -36.6830,\n",
      "         -19.2196,  -26.5899,  -21.5549,  -24.5240,  -18.9371,  -20.2792,\n",
      "         -20.8862,  -20.2029, -110.3211,  -20.1197,  -20.0058,  -19.0902,\n",
      "         -29.0307,  -23.2830,  -20.0935,  -19.2534,  -77.5392,  -20.6947,\n",
      "         -55.0655,  -27.0639,  -19.1252,  -31.8228,  -19.3186,  -20.1581,\n",
      "         -20.1138,  -23.0932,  -34.2595,  -20.7984,  -25.3143,  -28.6947,\n",
      "         -20.6699,  -19.6462,  -20.9370,  -24.7379,  -56.4518,  -24.0745,\n",
      "         -29.9522,  -23.6923,  -21.0275,  -29.2221,  -20.8330,  -25.5742,\n",
      "         -23.0880,  -20.0551,  -20.6269,  -23.0150,  -20.3759,  -47.5848,\n",
      "         -25.5522,  -35.3615,  -19.1989,  -27.7253,  -30.3220, -100.4251,\n",
      "         -20.0684,  -20.7170,  -18.7796,  -63.9280,  -20.6464,  -20.4460,\n",
      "         -19.3685,  -32.2129,  -48.6292,  -19.3531,  -22.6365,  -20.8554,\n",
      "         -22.6606,  -22.7001,  -23.4918,  -24.0005,  -19.9748,  -34.5417,\n",
      "         -27.4059,  -22.6505,  -29.0109,  -19.2592,  -19.2254,  -23.7508,\n",
      "         -21.8049,  -20.4541,  -20.5621,  -21.1172,  -43.0880,  -20.7075,\n",
      "         -32.9212,  -47.1898,  -27.9349,  -32.4733,  -20.5657, -150.7991,\n",
      "        -177.6544,  -22.1103,  -19.8163,  -27.2720,  -25.8673,  -19.3109,\n",
      "         -21.8787,  -20.2611, -173.3418,  -22.5402,  -47.7663, -105.5753,\n",
      "         -24.7884,  -23.5512,  -53.1665,  -23.4227,  -20.4348,  -21.6816,\n",
      "        -147.4458,  -21.1500,  -56.8006,  -25.0982,  -96.9035,  -45.7759,\n",
      "         -36.7592,  -28.7184,  -28.7493,  -27.7074, -142.6692,  -23.0632,\n",
      "         -23.6737,  -26.0452,  -22.7778,  -33.7844,  -70.0660,  -61.7687,\n",
      "         -24.1469,  -47.1891,  -34.1575,  -88.5120,  -26.4850,  -39.2295,\n",
      "         -28.2925,  -22.9172,  -27.7749,  -22.9994,  -20.5695,  -19.5117,\n",
      "         -22.9299,  -20.0080,  -22.3717,  -21.4684,  -20.5860,  -25.9155,\n",
      "        -117.4950,  -23.0753,  -24.5695,  -21.4863,  -20.5019,  -21.9095,\n",
      "         -26.9933,  -23.7353,  -25.4560,  -88.7407,  -20.7221,  -19.2405,\n",
      "         -26.4567, -133.5262,  -22.5182, -132.6391,  -26.1326,  -32.9338,\n",
      "        -135.4561,  -19.3625,  -27.8552,  -19.2002,  -23.5107,  -20.4158,\n",
      "         -18.9308,  -20.5024,  -19.5395,  -61.2509,  -23.4687,  -59.8234,\n",
      "         -19.2319,  -22.4854,  -18.3957,  -20.4045,  -21.4111,  -21.6996,\n",
      "         -19.5542, -158.9691,  -21.1250,  -21.4460,  -18.1705,  -19.8782,\n",
      "         -22.1814,  -18.7623,  -22.3977,  -22.8532,  -19.8482,  -23.2461,\n",
      "         -19.5080,  -51.5208,  -24.5356,  -19.3260,  -19.2247,  -20.6893,\n",
      "         -20.0903,  -22.5602,  -27.6742,  -21.1893,  -19.8290,  -25.3265,\n",
      "         -20.5312,  -22.3452, -130.1146,  -22.6051,  -20.3074, -118.0746,\n",
      "         -20.5545,  -27.6738,  -28.2540,  -27.8538,  -19.9581,  -71.8145,\n",
      "         -19.1209,  -26.0527,  -18.8703,  -19.3946,  -21.4629,  -20.7645,\n",
      "         -22.8929,  -25.8538,  -27.3318,  -26.9840,  -20.2939,  -20.3969,\n",
      "         -22.3552,  -19.5937,  -32.5772,  -21.4186,  -19.6881,  -28.1471,\n",
      "         -21.4772,  -22.4043,  -23.4304,  -20.2863,  -20.0285,  -26.2287,\n",
      "         -25.6381,  -23.9102,  -30.4444,  -21.6643,  -20.8172,  -23.1015,\n",
      "         -21.6852,  -23.2223,  -18.6362,  -20.3433,  -20.8750,  -22.4431,\n",
      "         -19.8977,  -19.0840,  -19.8322,  -25.6864,  -20.9430,  -19.4420,\n",
      "         -19.3723,  -18.6371,  -31.7492,  -19.6065,  -33.6169,  -20.9368,\n",
      "         -27.4011,  -23.5168,  -34.7106,  -23.5263,  -19.4745,  -20.3963,\n",
      "         -24.3833,  -22.6508,  -37.7234,  -28.8254,  -19.0331,  -35.8546,\n",
      "         -26.4959,  -24.3565,  -25.6695,  -18.8584,  -20.1694,  -36.3049,\n",
      "         -22.2135,  -23.6865,  -25.7010,  -18.9705,  -22.3326,  -23.6006,\n",
      "         -19.1583,  -28.7937,  -25.1308,  -18.9103,  -20.3820,  -21.5805,\n",
      "         -33.4995,  -26.0047,  -19.0049,  -73.8571,  -20.4539,  -19.7083,\n",
      "         -18.8137,  -37.6929,  -20.6327,  -31.2748,  -24.2649,  -18.8782,\n",
      "         -20.3532,  -22.5784,  -19.0778, -106.7783,  -21.7124,  -78.3845,\n",
      "         -19.3080,  -18.6156,  -19.0027,  -30.2259,  -22.3596,  -23.9341,\n",
      "         -21.2840,  -21.4707,  -20.7055,  -58.1467,  -26.7243,  -23.9760,\n",
      "         -20.1364,  -29.9677,  -19.3554,  -25.0782,  -19.0969,  -47.5363,\n",
      "         -21.9655,  -18.8773,  -37.5815,  -19.1910,  -29.3883,  -22.1029,\n",
      "         -19.2804,  -24.1651,  -29.9723,  -18.9133,  -35.2882,  -25.0136,\n",
      "         -60.1976,  -40.7069,  -19.7322,  -26.2083,  -18.6417,  -24.8730,\n",
      "         -71.5359,  -34.3404,  -32.9034,  -72.5350,  -28.4264,  -22.0358,\n",
      "         -42.2456,  -19.9802,  -19.3209,  -44.4664,  -35.4270,  -24.9134,\n",
      "         -46.8244,  -25.9879,  -47.1771,  -31.7062,  -23.0423,  -19.5644,\n",
      "        -144.9007,  -46.5208,  -25.0698,  -21.2947,  -18.7362,  -21.7190,\n",
      "         -20.6646,  -77.3677,  -22.3960,  -20.1287,  -19.2847,  -21.1548,\n",
      "         -21.3519, -105.2573,  -22.7309,  -20.6682,  -23.4689,  -22.4076,\n",
      "         -48.9489,  -22.8679,  -41.8102,  -20.7043,  -19.7094, -160.9704,\n",
      "         -19.6863,  -34.6286,  -99.3291,  -30.2446,  -19.7455,  -21.6387,\n",
      "         -97.7727,  -20.2158,  -20.0050,  -23.7054,  -19.4618,  -33.2144,\n",
      "        -166.5142,  -22.0006,  -21.9047,  -20.4912,  -22.3215,  -34.3706,\n",
      "         -18.6636,  -19.3367,  -24.4439,  -20.1943,  -19.3940,  -21.5110,\n",
      "         -52.1894,  -19.8719,  -19.2955,  -24.7982,  -28.4031,  -22.4026,\n",
      "         -18.4898, -102.4750,  -19.5232,  -18.1807,  -20.6197,  -22.2858,\n",
      "         -19.2009, -102.4071,  -25.9188,  -19.0760,  -28.7592,  -22.2978,\n",
      "         -23.7518,  -64.5097,  -21.4909,  -20.4812,  -23.5865,  -28.2515,\n",
      "         -20.9072,  -21.0648,  -23.4333,  -62.8976,  -21.5280, -107.8305,\n",
      "         -20.8551,  -39.2215,  -42.4450,  -41.7510,  -29.6043,  -32.7103,\n",
      "         -27.1308,  -38.5494,  -72.5328,  -34.8541,  -21.2766,  -21.0614,\n",
      "         -37.3911,  -52.8630,  -18.9464,  -45.5369,  -27.0893,  -25.5824,\n",
      "         -35.4638,  -91.1895,  -33.3327,  -24.8682,  -30.3533,  -19.0657,\n",
      "         -41.8854,  -18.7319,  -62.1798,  -42.9343,  -92.0734,  -95.8922,\n",
      "         -66.3311,  -23.0337,  -34.7834,  -43.2817,  -20.1981,  -22.0356,\n",
      "         -32.3426,  -20.3254,  -19.6031,  -21.1564,  -24.3483,  -29.1062,\n",
      "         -21.3380,  -20.5113, -128.4669,  -21.4778,  -21.9742,  -20.8499,\n",
      "         -56.6850,  -21.9455,  -24.7891,  -22.1920,  -25.4988,  -20.5459,\n",
      "         -22.6968,  -29.6095,  -22.6256,  -22.3545,  -18.9204,  -24.6860,\n",
      "         -19.8144,  -19.6626,  -22.3875,  -27.3314,  -18.9997,  -19.4362,\n",
      "         -19.0681,  -21.6894,  -29.7653,  -19.9965,  -19.5593,  -25.0004,\n",
      "         -19.5694,  -34.0332,  -20.6532,  -18.1706,  -21.4292,  -22.8714,\n",
      "         -19.4498,  -23.2541,  -19.0092,  -18.4749,  -20.0785,  -22.2382,\n",
      "         -20.9857,  -21.8589,  -89.2060,  -18.5665,  -27.1721,  -28.0999,\n",
      "         -22.9052,  -22.9931,  -28.5288,  -19.1872,  -22.0497,  -24.3493,\n",
      "         -21.5408,  -19.2013,  -21.4135,  -21.9285,  -61.4512,  -20.6732,\n",
      "         -27.2155,  -25.1290,  -21.7824,  -23.3783,  -20.9292,  -22.9658,\n",
      "         -21.5140,  -18.5036,  -47.5587,  -19.7775,  -19.2361,  -20.2177,\n",
      "         -28.7414,  -21.0428,  -36.2871,  -21.2583,  -22.7938,  -61.1969,\n",
      "         -23.1726,  -19.1263,  -73.5095,  -24.3751,  -99.8702,  -21.8588,\n",
      "         -62.1580,  -20.2542,  -21.8940,  -21.9791,  -31.4995,  -18.9218,\n",
      "         -21.6294,  -39.9286,  -19.9816,  -26.8223,  -27.4263,  -21.6425,\n",
      "         -21.4361,  -20.5654,  -48.5854,  -49.2085,  -40.3530, -149.3153,\n",
      "         -26.5058,  -18.7618,  -30.1031,  -20.1248,  -25.1713,  -56.0394,\n",
      "         -29.5675,  -23.1494,  -24.4683,  -19.9287,  -22.3584,  -28.6302,\n",
      "         -22.8480,  -31.4352,  -19.4178,  -29.2448,  -19.4079,  -91.6068,\n",
      "         -20.4068,  -22.3180,  -22.4306,  -38.5483,  -27.1302,  -24.0459,\n",
      "         -32.2378,  -21.2608,  -26.8884,  -21.3853,  -24.3320, -120.0141,\n",
      "         -21.3305,  -26.0504,  -21.2586,  -21.5987,  -24.6539,  -19.9524,\n",
      "         -25.8918,  -21.7887,  -28.8893,  -32.8157,  -36.0866,  -26.6553,\n",
      "         -35.4890,  -29.2743,  -21.3699,  -25.4588,  -35.9381,  -28.5861,\n",
      "         -25.9547,  -19.3674,  -45.8889,  -49.8593,  -25.8649,  -21.0503,\n",
      "         -39.9135,  -20.1390,  -21.5538,  -19.8827,  -31.0785,  -31.4273,\n",
      "         -22.6210,  -22.5073,  -20.2384,  -32.5250,  -21.1083,  -24.7765,\n",
      "         -22.5422,  -23.1711,  -20.4415,  -29.4717,  -21.1165,  -26.3294,\n",
      "         -21.8704,  -38.4073,  -23.8122,  -20.1374,  -24.8622,  -19.8619,\n",
      "         -23.4712,  -21.4889,  -21.8202,  -19.5874,  -25.2176,  -20.6463,\n",
      "         -46.7210,  -20.6349,  -23.9372,  -20.1235,  -18.9677,  -25.9395,\n",
      "         -22.3779,  -24.9209,  -20.0544,  -33.0989,  -20.7414,  -20.5748,\n",
      "         -31.2838,  -20.5461,  -20.7462,  -18.9461,  -26.6628,  -20.0427,\n",
      "         -31.1427,  -19.4602,  -37.2060,  -22.3562,  -19.2934,  -19.9707,\n",
      "         -20.5651,  -20.0152,  -19.2379,  -25.1543,  -26.0144,  -25.5213,\n",
      "         -19.8976,  -24.1754,  -20.6994,  -19.3553,  -20.8620,  -24.3595,\n",
      "         -19.1253,  -23.5364,  -19.8596,  -25.0783,  -33.4451,  -25.5529,\n",
      "         -23.3399,  -22.4866,  -23.7638,  -27.4027,  -19.9883,  -23.5041,\n",
      "         -20.0103,  -33.2404,  -29.5881,  -20.4863,  -21.2392,  -19.8925,\n",
      "         -19.5399,  -23.3942,  -19.7417,  -20.6884,  -29.3528,  -32.1912,\n",
      "         -24.9702,  -19.9106,  -25.1046,  -25.4311,  -20.7684,  -19.9251,\n",
      "         -24.1852,  -19.3651,  -19.6909,  -22.8092,  -25.3293,  -19.6175,\n",
      "         -24.7868,  -33.0051,  -19.1727,  -22.6338,  -27.3473,  -30.5826,\n",
      "         -20.0109,  -24.7451,  -24.8875,  -20.7189,  -20.8867,  -28.9896,\n",
      "         -19.6724,  -19.7175,  -23.9249,  -28.1020,  -19.9576,  -22.8727,\n",
      "         -27.8806,  -25.5770,  -20.7288,  -37.8893,  -22.4489,  -18.8011,\n",
      "         -30.2831,  -22.4976,  -19.2601,  -22.3963,  -19.7918,  -26.2973,\n",
      "         -19.4260,  -23.5476,  -20.4693,  -33.1779,  -19.7952,  -30.8230,\n",
      "         -31.3483,  -31.0339,  -20.4624,  -19.5306,  -19.7422,  -19.0787,\n",
      "         -34.6229,  -30.1307,  -27.2344,  -20.7050], device='cuda:0')\n",
      "tensor([ -23.6617,  -23.6267,  -22.5177,  -33.1925,  -25.0918,  -26.7532,\n",
      "         -99.9706,  -19.5697,  -18.6488,  -31.7530,  -28.5833,  -25.0305,\n",
      "         -18.9235,  -18.7050,  -20.3754,  -21.3653,  -30.0880,  -19.7090,\n",
      "         -18.5089,  -39.3682,  -44.6020,  -21.0883,  -22.2438,  -27.3119,\n",
      "         -20.4917,  -25.5050,  -22.8318,  -19.2953,  -78.0846,  -18.3058,\n",
      "         -19.1220,  -18.5211,  -20.0647,  -25.3886, -152.0304,  -22.4774,\n",
      "         -74.1126,  -21.1556,  -22.2331,  -19.9208,  -20.1489,  -20.1993,\n",
      "         -66.3311,  -20.4439,  -19.4253,  -20.9245,  -65.1016,  -52.8021,\n",
      "         -21.1099,  -19.9338,  -18.8551,  -21.1466,  -19.4071,  -20.1160,\n",
      "         -20.4870,  -24.7635,  -22.2186,  -19.2334,  -18.8161,  -21.5981,\n",
      "        -101.1431,  -23.4071,  -19.1459,  -90.2644,  -21.1465,  -19.4726,\n",
      "         -76.1016,  -20.5754,  -19.7015,  -21.3362,  -25.2364,  -24.2098,\n",
      "         -30.1724, -125.3487,  -18.9447,  -24.2334,  -20.0529,  -20.0076,\n",
      "        -115.1927,  -62.2197,  -19.2990,  -18.8754,  -93.2854,  -23.6043,\n",
      "         -21.4852,  -19.9174,  -19.5985,  -19.6331,  -22.5805,  -18.3079,\n",
      "         -20.0370,  -22.3931,  -84.8365,  -25.0060,  -21.1129,  -29.2085,\n",
      "         -20.9770,  -60.7777,  -33.4626,  -84.7097,  -19.8651,  -23.1239,\n",
      "         -21.9192,  -20.1096,  -23.1301,  -18.8302,  -25.7748,  -41.7233,\n",
      "         -21.8903,  -65.1396,  -24.2272,  -23.5274,  -19.4591,  -20.7767,\n",
      "         -21.7236,  -19.5390,  -19.3329,  -19.0712,  -88.4745,  -25.6048,\n",
      "         -27.7099,  -19.7699,  -24.6596,  -37.2836,  -19.8927,  -25.1271,\n",
      "         -22.0712,  -20.3408,  -22.9126,  -19.5136,  -20.2711,  -31.3126,\n",
      "         -21.6201,  -19.5657, -102.4333,  -23.8541,  -22.1250,  -25.2034,\n",
      "         -20.1133,  -19.4349,  -20.8384,  -20.9027,  -22.6732,  -19.0043,\n",
      "         -25.5874,  -21.4407,  -22.5472,  -21.6197,  -18.6231,  -19.6277,\n",
      "         -23.4740,  -39.9220,  -19.2744,  -20.4737,  -20.8943,  -22.2643,\n",
      "         -21.7910,  -26.1568,  -50.8788,  -20.1402,  -18.7860,  -20.0185,\n",
      "         -20.8437,  -19.7602,  -19.0324,  -19.4782,  -20.4162,  -21.2952,\n",
      "         -23.9058,  -19.5127,  -21.5546,  -19.4129,  -22.1105,  -20.5260,\n",
      "         -19.3302,  -19.2576,  -20.3699,  -19.3691,  -20.0771,  -21.1232,\n",
      "         -27.4698,  -24.0604,  -18.8404,  -23.8248,  -27.7879,  -22.0714,\n",
      "         -21.7227,  -18.6195,  -45.7390,  -20.8825,  -19.2886,  -21.0279,\n",
      "         -19.7615,  -18.9187,  -21.9871,  -25.9088,  -21.3843,  -19.7511,\n",
      "         -29.8779,  -27.5542,  -20.5014,  -19.2213,  -20.1046,  -20.2773,\n",
      "         -20.0816,  -20.4777,  -24.8724,  -20.3485,  -22.6367,  -21.3283,\n",
      "         -29.6039,  -23.2275,  -18.3446,  -23.6054,  -22.3041,  -19.3177,\n",
      "         -20.4672,  -25.4033, -108.0671,  -19.7593,  -20.9186,  -18.8389,\n",
      "         -19.3987,  -29.4248,  -20.9853,  -19.9204,  -76.2980,  -28.2067,\n",
      "         -49.0057,  -27.9342,  -20.1549,  -25.4625,  -18.9926,  -21.0944,\n",
      "         -19.7044,  -19.7725,  -38.0061,  -23.6651,  -20.0573,  -31.9709,\n",
      "         -21.8177,  -22.9749,  -19.2147,  -27.1824,  -61.7067,  -32.7288,\n",
      "         -19.1775,  -25.7527,  -19.8232,  -29.4339,  -20.5505,  -32.5051,\n",
      "         -22.5471,  -19.4938,  -21.2187,  -19.3161,  -21.0845,  -47.0256,\n",
      "         -18.6238,  -19.9357,  -22.7431,  -19.9672,  -20.7594,  -74.8038,\n",
      "         -19.3110,  -19.9195,  -18.8619,  -62.9158,  -23.2049,  -22.4846,\n",
      "         -20.5653,  -31.6775,  -50.3187,  -19.2371,  -36.6750,  -21.0549,\n",
      "         -21.8520,  -23.7271,  -20.8391,  -24.5185,  -20.2096,  -34.8786,\n",
      "         -26.1127,  -23.3544,  -23.6987,  -20.0929,  -19.6693,  -23.5972,\n",
      "         -19.1953,  -20.3729,  -21.0852,  -19.8484,  -42.9189,  -22.0945,\n",
      "         -19.6357,  -50.5280,  -27.0392,  -24.4006,  -21.0669, -153.0099,\n",
      "        -173.9529,  -18.6904,  -22.3021,  -33.0030,  -26.9945,  -19.3000,\n",
      "         -21.5063,  -20.9433, -172.4281,  -22.4632,  -50.9458, -104.8695,\n",
      "         -23.3522,  -20.2047,  -61.0576,  -20.5174,  -21.2548,  -21.7679,\n",
      "        -146.8368,  -18.6499,  -60.7611,  -23.6713, -105.2136,  -35.4749,\n",
      "         -34.9561,  -30.3373,  -27.0328,  -28.3885, -148.3626,  -27.2097,\n",
      "         -22.9941,  -26.5715,  -19.5504,  -27.8418,  -72.3304,  -46.0842,\n",
      "         -23.6255,  -34.5320,  -21.6241,  -89.5178,  -21.0268,  -29.0395,\n",
      "         -20.2868,  -19.1576,  -20.5007,  -24.2616,  -27.3447,  -22.2817,\n",
      "         -20.7060,  -19.8885,  -21.8674,  -26.3453,  -25.7759,  -20.5342,\n",
      "        -113.1258,  -21.9598,  -24.0527,  -25.7757,  -20.0185,  -21.4678,\n",
      "         -25.7877,  -20.7697,  -20.0825,  -93.9195,  -21.5535,  -18.9359,\n",
      "         -19.5016, -141.6764,  -19.4472, -131.3671,  -28.2423,  -18.8261,\n",
      "        -133.9985,  -20.0161,  -19.7908,  -21.5648,  -22.3273,  -20.9871,\n",
      "         -23.4582,  -20.8242,  -22.1190,  -60.5429,  -21.4391,  -60.0080,\n",
      "         -18.9377,  -27.2681,  -26.3296,  -20.6938,  -22.0672,  -18.5260,\n",
      "         -20.7760, -154.3091,  -21.0391,  -18.8472,  -18.4976,  -23.1321,\n",
      "         -27.1856,  -19.2110,  -19.5896,  -20.4850,  -20.2504,  -21.9827,\n",
      "         -21.7796,  -48.0665,  -22.3608,  -24.1825,  -20.7064,  -19.8299,\n",
      "         -19.3693,  -20.0450,  -19.3538,  -21.3052,  -25.3428,  -23.0092,\n",
      "         -23.3576,  -22.7121, -130.4617,  -20.6401,  -18.7659, -111.0888,\n",
      "         -21.8328,  -19.6498,  -19.6766,  -19.7420,  -25.8348,  -69.7702,\n",
      "         -26.6102,  -20.9017,  -18.9423,  -19.2736,  -20.8584,  -20.0333,\n",
      "         -24.3942,  -20.8561,  -25.1864,  -23.3417,  -26.4986,  -20.7432,\n",
      "         -22.5103,  -18.4850,  -31.0140,  -23.7821,  -21.7736,  -33.7977,\n",
      "         -21.0124,  -22.1560,  -21.2084,  -37.2017,  -21.0728,  -27.6393,\n",
      "         -21.8865,  -20.4964,  -30.2727,  -19.3164,  -21.2686,  -23.0475,\n",
      "         -19.3157,  -22.1060,  -23.0970,  -27.1497,  -19.4995,  -18.9183,\n",
      "         -20.2847,  -20.7208,  -20.4273,  -21.7270,  -21.0388,  -24.6930,\n",
      "         -19.4206,  -19.1921,  -19.8244,  -19.7697,  -22.0709,  -21.6196,\n",
      "         -28.3744,  -19.0944,  -27.8148,  -20.8440,  -19.4018,  -20.3137,\n",
      "         -20.1935,  -23.7999,  -25.7112,  -28.5255,  -22.9766,  -34.9923,\n",
      "         -29.2539,  -28.9114,  -31.1734,  -20.4762,  -21.3532,  -30.4742,\n",
      "         -20.6691,  -22.5967,  -20.2551,  -23.5001,  -21.1811,  -20.0120,\n",
      "         -18.9954,  -27.3737,  -25.4328,  -20.1228,  -19.1324,  -20.4895,\n",
      "         -34.0065,  -24.8548,  -20.2432,  -73.9904,  -20.5596,  -20.0155,\n",
      "         -19.1776,  -38.8615,  -29.9044,  -27.5584,  -20.2717,  -18.9790,\n",
      "         -21.5548,  -19.9511,  -20.5064,  -98.8896,  -21.1515,  -84.6434,\n",
      "         -23.0628,  -19.0438,  -19.2474,  -23.6431,  -20.8458,  -20.5645,\n",
      "         -21.0317,  -18.6361,  -18.9594,  -41.0707,  -19.1981,  -30.2781,\n",
      "         -20.4635,  -22.3372,  -20.2075,  -29.9826,  -18.2015,  -36.3286,\n",
      "         -22.3961,  -20.8309,  -31.2489,  -19.7547,  -21.8332,  -21.1513,\n",
      "         -19.3657,  -42.4544,  -32.0591,  -19.1207,  -37.4401,  -30.0152,\n",
      "         -35.6633,  -37.6604,  -23.3950,  -26.9786,  -33.5802,  -25.5361,\n",
      "         -57.5188,  -33.5644,  -32.7458,  -48.6322,  -31.4443,  -20.4803,\n",
      "         -37.8077,  -19.9177,  -22.4259,  -38.0962,  -37.1537,  -27.8500,\n",
      "         -41.0931,  -22.6935,  -46.0084,  -42.4899,  -24.1129,  -19.3155,\n",
      "        -144.3237,  -45.5880,  -22.8365,  -21.9223,  -22.2168,  -19.3607,\n",
      "         -19.6001,  -93.9430,  -23.7935,  -20.1074,  -19.7482,  -20.8950,\n",
      "         -22.3721, -106.3577,  -25.3026,  -21.4764,  -21.6918,  -20.3660,\n",
      "         -46.7526,  -22.1548,  -36.4302,  -22.5278,  -21.4110, -161.6980,\n",
      "         -19.6756,  -20.6433, -107.4479,  -28.3248,  -20.0314,  -19.7502,\n",
      "         -96.5148,  -20.6651,  -25.9288,  -24.1845,  -27.1271,  -24.7664,\n",
      "        -161.6291,  -24.9041,  -20.2539,  -20.4965,  -22.3752,  -18.5888,\n",
      "         -18.6053,  -22.6145,  -21.8396,  -20.4801,  -19.3159,  -20.9749,\n",
      "         -50.0413,  -19.6867,  -18.5068,  -20.0943,  -19.7622,  -23.0728,\n",
      "         -33.6974, -101.9916,  -21.1104,  -21.7118,  -39.5317,  -19.4172,\n",
      "         -18.4914,  -95.0781,  -18.6312,  -18.7386,  -24.1389,  -21.7880,\n",
      "         -19.0971,  -61.5117,  -22.5043,  -19.2210,  -24.2058,  -19.5891,\n",
      "         -21.4628,  -25.3450,  -23.7960,  -65.6573,  -24.7033, -108.2297,\n",
      "         -20.5514,  -37.9733,  -41.7735,  -38.8710,  -43.5146,  -33.3822,\n",
      "         -22.3877,  -37.4258,  -67.3673,  -38.9941,  -19.6917,  -20.5825,\n",
      "         -35.6819,  -59.2373,  -19.0113,  -45.6065,  -22.5954,  -24.3995,\n",
      "         -36.1527,  -91.1610,  -32.3478,  -26.7502,  -28.4178,  -22.7721,\n",
      "         -39.3471,  -21.4096,  -61.5673,  -35.2086,  -97.9155,  -99.6626,\n",
      "         -71.4755,  -29.4750,  -39.7579,  -41.9304,  -24.3882,  -26.9820,\n",
      "         -23.5885,  -21.3334,  -27.6548,  -20.3712,  -23.9050,  -20.1837,\n",
      "         -24.5480,  -20.9440, -125.5977,  -19.6461,  -21.9506,  -19.5599,\n",
      "         -60.2864,  -22.6635,  -19.2634,  -19.7362,  -28.3583,  -29.9874,\n",
      "         -25.5238,  -23.1652,  -19.7834,  -20.6773,  -20.5981,  -21.3318,\n",
      "         -27.4571,  -19.6475,  -20.2680,  -19.2026,  -19.5384,  -22.6644,\n",
      "         -19.1498,  -18.6350,  -20.9251,  -21.1816,  -21.0724,  -21.4502,\n",
      "         -19.0899,  -23.3261,  -21.0371,  -20.8732,  -21.8001,  -19.3439,\n",
      "         -22.0878,  -20.9587,  -18.9329,  -23.5851,  -27.2261,  -31.9445,\n",
      "         -18.6287,  -19.4997,  -60.9691,  -23.7200,  -19.4391,  -20.7722,\n",
      "         -20.3361,  -19.8308,  -24.4314,  -20.2318,  -23.5817,  -21.0781,\n",
      "         -21.3694,  -21.0052,  -23.7775,  -20.6415,  -61.5868,  -18.7542,\n",
      "         -28.2000,  -32.5886,  -20.0220,  -20.7068,  -19.7247,  -19.9822,\n",
      "         -20.5910,  -22.3588,  -49.4445,  -25.1881,  -22.7738,  -22.8665,\n",
      "         -35.9133,  -20.2446,  -35.6399,  -18.1328,  -20.6779,  -59.9771,\n",
      "         -19.7350,  -21.6621,  -75.3045,  -21.6593, -102.5893,  -20.1960,\n",
      "         -56.3906,  -22.9583,  -21.6757,  -24.4050,  -31.6277,  -21.7953,\n",
      "         -20.7454,  -35.8226,  -21.7961,  -30.4701,  -24.8009,  -26.6273,\n",
      "         -22.9999,  -20.8844,  -42.4941,  -50.2193,  -39.9918, -156.3743,\n",
      "         -22.1194,  -24.2492,  -38.9438,  -21.1543,  -22.4935,  -58.3449,\n",
      "         -32.4570,  -24.3046,  -33.8058,  -19.0568,  -25.4397,  -21.0135,\n",
      "         -21.5009,  -31.6273,  -22.1749,  -19.0655,  -26.0003,  -90.1889,\n",
      "         -19.3277,  -23.3717,  -21.3951,  -29.9248,  -22.9668,  -19.6392,\n",
      "         -30.3544,  -19.9933,  -26.0730,  -21.3852,  -30.5254, -121.4856,\n",
      "         -22.7821,  -19.9123,  -20.1211,  -23.5634,  -32.3901,  -21.1782,\n",
      "         -24.1554,  -20.7810,  -33.1163,  -24.9723,  -34.7599,  -26.7013,\n",
      "         -26.2931,  -28.4892,  -22.2599,  -32.0861,  -22.3342,  -31.1300,\n",
      "         -24.0389,  -19.8151,  -38.7818,  -51.7688,  -21.4694,  -22.9875,\n",
      "         -32.5683,  -20.1299,  -21.6342,  -26.1500,  -48.2246,  -31.6249,\n",
      "         -23.4188,  -21.7313,  -20.3434,  -36.7843,  -20.7625,  -22.8181,\n",
      "         -23.2086,  -21.1492,  -21.1918,  -19.4805,  -21.7257,  -25.7965,\n",
      "         -20.4574,  -39.0477,  -23.8820,  -18.9065,  -26.1310,  -20.3331,\n",
      "         -22.6744,  -23.4641,  -19.9539,  -21.6962,  -19.5675,  -20.6411,\n",
      "         -46.4216,  -19.7218,  -20.1154,  -22.5966,  -20.7477,  -25.3555,\n",
      "         -21.3358,  -21.1165,  -22.4780,  -31.0600,  -19.5151,  -20.8469,\n",
      "         -33.3634,  -23.9306,  -24.9793,  -23.6427,  -25.5954,  -22.6192,\n",
      "         -32.7876,  -19.1451,  -36.0659,  -22.8690,  -19.9222,  -19.4436,\n",
      "         -21.4421,  -21.6523,  -19.5382,  -19.3795,  -26.4063,  -19.0165,\n",
      "         -18.9907,  -24.9749,  -19.2739,  -19.6944,  -24.8781,  -27.5330,\n",
      "         -19.2849,  -19.2733,  -19.8027,  -19.6064,  -34.1142,  -21.7892,\n",
      "         -25.7108,  -22.0070,  -21.2980,  -21.8168,  -18.9569,  -20.3810,\n",
      "         -20.0210,  -41.2302,  -30.6911,  -22.3948,  -20.7308,  -24.8609,\n",
      "         -20.0745,  -18.9600,  -27.3534,  -27.4244,  -27.0869,  -19.2682,\n",
      "         -19.6364,  -25.1685,  -19.1900,  -25.5448,  -19.9579,  -20.9166,\n",
      "         -20.0812,  -23.0769,  -20.0780,  -25.3433,  -24.2349,  -20.6356,\n",
      "         -21.4315,  -28.3071,  -22.4895,  -22.2278,  -26.6042,  -28.8949,\n",
      "         -20.7559,  -19.2531,  -20.1169,  -21.4282,  -21.4615,  -28.3820,\n",
      "         -22.9518,  -21.3364,  -22.3144,  -27.5570,  -21.2026,  -24.5828,\n",
      "         -29.7939,  -26.0937,  -19.6727,  -33.0331,  -19.4690,  -20.9796,\n",
      "         -29.4332,  -24.9470,  -19.4484,  -21.9900,  -19.1793,  -23.4588,\n",
      "         -20.0866,  -23.5629,  -20.9786,  -37.0034,  -23.8204,  -30.6482,\n",
      "         -31.2245,  -19.4596,  -20.5473,  -24.8734,  -20.4892,  -19.5173,\n",
      "         -31.4803,  -23.3340,  -27.0112,  -20.8458], device='cuda:0')\n",
      "tensor([ -25.0718,  -24.1509,  -27.0341,  -33.4332,  -21.2494,  -32.6708,\n",
      "        -111.4345,  -20.3228,  -19.8297,  -31.3154,  -28.7569,  -22.6797,\n",
      "         -21.7710,  -26.1732,  -24.0840,  -24.8641,  -34.2390,  -20.0019,\n",
      "         -26.2425,  -46.6708,  -42.4287,  -19.9156,  -19.2896,  -31.8049,\n",
      "         -21.0901,  -21.0646,  -23.2639,  -21.1639,  -95.9125,  -23.3611,\n",
      "         -20.8517,  -18.3541,  -20.3158,  -20.9152, -149.7415,  -20.3810,\n",
      "         -80.0688,  -19.2084,  -18.8380,  -20.5095,  -20.0444,  -20.1289,\n",
      "         -69.0652,  -20.2553,  -20.4711,  -19.0835,  -65.6187,  -54.2884,\n",
      "         -23.2835,  -27.9149,  -22.8214,  -21.0555,  -27.1559,  -20.4814,\n",
      "         -24.6497,  -24.4076,  -20.9038,  -19.3833,  -18.8874,  -22.8193,\n",
      "        -108.3900,  -26.3106,  -20.6169,  -81.8372,  -20.3012,  -33.8524,\n",
      "         -76.2107,  -18.5122,  -20.0609,  -18.9173,  -20.5527,  -19.8824,\n",
      "         -19.3084, -125.0346,  -19.1407,  -25.1795,  -25.5432,  -20.0560,\n",
      "        -107.7544,  -64.4908,  -22.1289,  -19.8721, -101.6549,  -21.1029,\n",
      "         -21.7729,  -26.4567,  -20.3584,  -35.0366,  -18.9525,  -19.5122,\n",
      "         -24.0746,  -22.5226,  -88.3823,  -27.7299,  -20.8812,  -20.4374,\n",
      "         -30.5714,  -62.3456,  -18.5498,  -76.2094,  -22.1968,  -24.3023,\n",
      "         -18.8866,  -23.1637,  -33.6621,  -19.7092,  -20.1179,  -41.0773,\n",
      "         -19.5892,  -63.7320,  -21.3031,  -19.7833,  -24.3823,  -19.4113,\n",
      "         -19.6484,  -40.5761,  -20.6392,  -34.7096,  -90.9443,  -22.4937,\n",
      "         -19.5938,  -21.8959,  -31.9463,  -19.7633,  -18.6108,  -24.9169,\n",
      "         -20.8682,  -24.3761,  -23.8117,  -22.2083,  -21.8556,  -19.7956,\n",
      "         -21.7382,  -19.4068,  -99.5994,  -19.7858,  -22.5890,  -20.8118,\n",
      "         -19.1922,  -19.4406,  -20.8348,  -19.7115,  -22.6131,  -20.3274,\n",
      "         -19.4752,  -19.3151,  -21.1513,  -21.6571,  -20.8793,  -19.0184,\n",
      "         -18.7996,  -34.6934,  -24.9675,  -31.5510,  -28.8149,  -20.8638,\n",
      "         -20.1272,  -20.9801,  -46.8117,  -19.7552,  -19.3306,  -19.4015,\n",
      "         -18.5333,  -19.5068,  -19.6875,  -19.0165,  -19.6720,  -20.3299,\n",
      "         -21.6143,  -20.2718,  -19.4853,  -19.5318,  -19.4009,  -19.7453,\n",
      "         -19.7815,  -18.9655,  -21.4337,  -18.5513,  -19.5357,  -20.1850,\n",
      "         -25.6224,  -20.7135,  -22.1924,  -22.2312,  -21.8487,  -19.8542,\n",
      "         -18.8528,  -19.3420,  -47.6556,  -19.5482,  -39.4521,  -19.9563,\n",
      "         -20.4458,  -19.6596,  -18.0030,  -21.6832,  -19.5629,  -20.8665,\n",
      "         -25.8806,  -30.6055,  -21.1743,  -20.8127,  -22.0630,  -20.9133,\n",
      "         -23.8260,  -26.4697,  -26.8443,  -23.4938,  -19.3791,  -24.2403,\n",
      "         -21.3405,  -28.6665,  -23.6968,  -20.6961,  -22.0647,  -18.9094,\n",
      "         -22.4982,  -19.6874,  -98.8139,  -19.7241,  -26.0940,  -33.1409,\n",
      "         -27.2423,  -21.0367,  -22.0827,  -20.5983,  -71.6960,  -21.0198,\n",
      "         -46.0242,  -28.4066,  -19.2133,  -19.0160,  -23.4182,  -20.0542,\n",
      "         -20.7561,  -18.4922,  -35.5843,  -19.8079,  -30.2742,  -29.0675,\n",
      "         -23.0530,  -17.9718,  -19.6464,  -26.0604,  -56.7423,  -18.9111,\n",
      "         -19.7127,  -25.2322,  -20.2725,  -26.3289,  -23.6776,  -25.0037,\n",
      "         -19.8654,  -20.8832,  -20.6815,  -19.4483,  -20.5858,  -52.2124,\n",
      "         -18.9592,  -28.4374,  -19.3559,  -23.0988,  -20.5201,  -79.5877,\n",
      "         -18.2371,  -22.2896,  -29.4660,  -62.0472,  -22.9875,  -20.0941,\n",
      "         -20.6984,  -39.9519,  -58.2901,  -22.1179,  -23.5779,  -20.8568,\n",
      "         -23.5520,  -20.6886,  -23.7236,  -25.3483,  -21.9061,  -36.1963,\n",
      "         -26.3343,  -19.7139,  -21.2207,  -19.4786,  -19.2712,  -21.2576,\n",
      "         -19.4897,  -31.4463,  -20.5321,  -25.6796,  -43.3314,  -20.3790,\n",
      "         -21.7473,  -46.9358,  -26.7093,  -26.6224,  -19.8181, -154.9958,\n",
      "        -176.1104,  -21.7633,  -23.1623,  -28.8636,  -24.5748,  -19.0588,\n",
      "         -21.5898,  -20.2913, -179.1333,  -24.5881,  -47.6798, -112.1276,\n",
      "         -23.1335,  -21.3855,  -52.9661,  -20.9089,  -22.8672,  -21.9048,\n",
      "        -147.9484,  -19.1122,  -61.5121,  -19.8858,  -99.0406,  -42.8705,\n",
      "         -40.4767,  -26.4998,  -25.8426,  -26.5182, -145.2735,  -21.8852,\n",
      "         -26.2469,  -26.8852,  -19.4372,  -27.0915,  -72.1847,  -43.7230,\n",
      "         -26.5015,  -30.8531,  -27.2953,  -88.3478,  -21.0010,  -31.6305,\n",
      "         -20.1248,  -19.8148,  -21.2526,  -26.3352,  -20.4767,  -19.8273,\n",
      "         -21.3288,  -21.5341,  -22.3218,  -21.2794,  -32.1293,  -20.4562,\n",
      "        -113.4112,  -21.2407,  -23.1062,  -21.6297,  -20.7802,  -23.4433,\n",
      "         -36.1478,  -26.0685,  -21.8020,  -87.5327,  -20.1975,  -20.8932,\n",
      "         -21.0530, -132.0739,  -20.0758, -131.8528,  -25.4307,  -19.4778,\n",
      "        -134.7209,  -19.4186,  -19.5058,  -18.9497,  -19.7446,  -20.0060,\n",
      "         -25.4028,  -19.9029,  -20.3534,  -64.5011,  -22.6336,  -60.9753,\n",
      "         -22.2803,  -19.5529,  -18.4814,  -19.6421,  -24.6490,  -19.3674,\n",
      "         -19.9745, -154.4126,  -23.6364,  -19.0261,  -20.8314,  -20.4629,\n",
      "         -23.2147,  -19.7193,  -23.0888,  -21.4934,  -21.6239,  -23.0525,\n",
      "         -29.7412,  -46.8137,  -20.4667,  -19.3739,  -28.1534,  -21.3977,\n",
      "         -19.3506,  -20.3600,  -21.8268,  -22.5389,  -22.8797,  -27.9887,\n",
      "         -33.4037,  -21.4593, -129.9966,  -19.5798,  -19.5685,  -98.7635,\n",
      "         -19.8321,  -37.4397,  -21.0378,  -19.7422,  -21.0453,  -71.3587,\n",
      "         -20.3931,  -18.8327,  -18.7901,  -20.0931,  -20.7646,  -23.0793,\n",
      "         -21.4027,  -20.0767,  -19.2411,  -25.1436,  -20.0724,  -19.9121,\n",
      "         -19.1878,  -17.6665,  -32.2205,  -23.4199,  -20.2927,  -29.7176,\n",
      "         -20.8540,  -21.2084,  -22.6309,  -21.4027,  -19.7431,  -27.3851,\n",
      "         -19.8966,  -19.8595,  -30.8518,  -19.2260,  -23.3158,  -22.8841,\n",
      "         -23.7305,  -18.6401,  -25.1828,  -19.7736,  -19.7725,  -19.3500,\n",
      "         -19.3616,  -20.7218,  -19.3660,  -29.3217,  -22.6434,  -24.5613,\n",
      "         -26.3621,  -18.0611,  -19.5888,  -19.3577,  -18.5209,  -21.5543,\n",
      "         -21.6631,  -18.5191,  -21.4805,  -19.6174,  -21.5686,  -25.6934,\n",
      "         -19.9318,  -20.5234,  -22.1131,  -29.6374,  -19.1033,  -30.5601,\n",
      "         -25.9480,  -26.8014,  -22.5353,  -19.9613,  -26.5331,  -29.2502,\n",
      "         -21.6669,  -22.4479,  -20.7708,  -32.3898,  -18.9775,  -24.4940,\n",
      "         -20.5786,  -38.1902,  -26.3184,  -19.8515,  -19.7949,  -18.8283,\n",
      "         -29.5080,  -25.3916,  -20.7917,  -72.4624,  -21.2808,  -20.8562,\n",
      "         -19.1610,  -36.5472,  -21.1266,  -25.2206,  -20.2568,  -19.6849,\n",
      "         -23.1357,  -19.9104,  -19.6397,  -98.7555,  -33.0492,  -82.4142,\n",
      "         -22.2999,  -19.7704,  -19.8273,  -19.6159,  -22.6654,  -26.7493,\n",
      "         -30.0955,  -19.1983,  -19.8209,  -38.5083,  -22.5176,  -33.7574,\n",
      "         -20.3905,  -22.4807,  -22.8074,  -20.9979,  -22.2043,  -36.4462,\n",
      "         -19.9882,  -27.8218,  -31.2158,  -22.4470,  -29.3734,  -21.8464,\n",
      "         -19.0927,  -22.2390,  -30.4719,  -22.0756,  -39.4888,  -25.0214,\n",
      "         -60.1308,  -41.2731,  -23.0564,  -25.3811,  -43.4838,  -18.6189,\n",
      "         -57.1856,  -42.5406,  -38.3700,  -47.4298,  -27.5284,  -22.1945,\n",
      "         -54.3620,  -19.2940,  -20.0894,  -40.1211,  -36.2630,  -25.0424,\n",
      "         -42.2238,  -25.8699,  -47.6990,  -27.9005,  -23.8697,  -20.1782,\n",
      "        -142.9225,  -49.9547,  -19.9535,  -19.9126,  -27.4989,  -19.4353,\n",
      "         -24.3402,  -77.4635,  -21.3297,  -19.2612,  -21.3891,  -21.2644,\n",
      "         -23.2048, -108.7313,  -24.2473,  -27.0915,  -22.0519,  -20.7212,\n",
      "         -46.6182,  -20.7414,  -39.1693,  -21.2547,  -19.9264, -156.4031,\n",
      "         -19.3538,  -29.3522,  -97.2645,  -32.7287,  -20.3586,  -20.1994,\n",
      "         -97.0275,  -22.2727,  -20.8688,  -24.7627,  -18.8447,  -19.1074,\n",
      "        -160.6818,  -21.1469,  -21.9047,  -18.9964,  -25.6758,  -30.3526,\n",
      "         -20.5435,  -19.6022,  -18.5997,  -20.1260,  -30.5311,  -19.9668,\n",
      "         -56.0902,  -20.6005,  -26.3751,  -39.1175,  -20.6290,  -24.2600,\n",
      "         -19.2468, -101.2361,  -25.0602,  -21.0642,  -20.2801,  -19.4106,\n",
      "         -19.6794, -100.6284,  -19.1630,  -18.6870,  -19.8061,  -19.2505,\n",
      "         -19.7264,  -63.0236,  -26.2527,  -20.8785,  -23.4543,  -27.9148,\n",
      "         -23.1315,  -20.5415,  -24.5155,  -60.7655,  -23.3462, -117.0057,\n",
      "         -19.7594,  -40.6576,  -41.6550,  -38.8166,  -29.5756,  -31.1199,\n",
      "         -23.3021,  -37.6831,  -66.9366,  -36.9243,  -26.1056,  -25.5543,\n",
      "         -37.5309,  -49.6380,  -20.1341,  -47.2988,  -27.0589,  -25.9901,\n",
      "         -35.3037, -102.9277,  -40.1467,  -31.4834,  -25.2122,  -21.3598,\n",
      "         -42.1117,  -19.6152,  -61.1733,  -43.8813,  -93.4402,  -97.2572,\n",
      "         -67.9716,  -21.0530,  -38.2801,  -45.9913,  -20.0556,  -22.6673,\n",
      "         -30.8551,  -20.3225,  -19.5441,  -21.9318,  -27.2804,  -22.5165,\n",
      "         -20.8721,  -19.6082, -125.1944,  -20.3075,  -34.3115,  -19.1152,\n",
      "         -56.4425,  -28.7404,  -18.9805,  -20.2399,  -21.4695,  -20.4944,\n",
      "         -24.4012,  -22.2133,  -19.6468,  -20.0431,  -25.4358,  -24.1611,\n",
      "         -19.9651,  -21.1871,  -21.8857,  -19.8752,  -20.7486,  -22.6973,\n",
      "         -20.0983,  -19.2115,  -30.9936,  -21.6058,  -20.2669,  -20.3854,\n",
      "         -26.5510,  -22.9251,  -20.8703,  -23.8436,  -25.3963,  -20.5629,\n",
      "         -19.9282,  -24.4834,  -20.9018,  -20.8944,  -21.3212,  -19.4440,\n",
      "         -18.9110,  -21.0535,  -65.6063,  -19.9564,  -27.0499,  -23.6527,\n",
      "         -19.5675,  -20.1860,  -20.3349,  -23.7412,  -22.0366,  -19.9825,\n",
      "         -19.9239,  -43.3310,  -23.9811,  -26.0774,  -62.5251,  -19.7011,\n",
      "         -30.5318,  -20.2102,  -20.0769,  -23.6307,  -21.3787,  -20.0456,\n",
      "         -20.8726,  -18.6884,  -47.9682,  -28.6614,  -19.8860,  -19.8859,\n",
      "         -23.6515,  -24.7886,  -35.7912,  -20.9657,  -19.9869,  -62.7752,\n",
      "         -20.0059,  -22.6934,  -65.7144,  -20.5790, -103.0515,  -21.4188,\n",
      "         -56.2000,  -21.0535,  -23.2426,  -21.7982,  -47.4798,  -18.7294,\n",
      "         -25.9192,  -35.9894,  -19.9168,  -28.7575,  -24.7809,  -23.6751,\n",
      "         -23.1932,  -20.1246,  -42.5983,  -49.4044,  -39.7364, -149.4648,\n",
      "         -23.3086,  -22.3038,  -30.0069,  -21.1815,  -25.4245,  -56.6770,\n",
      "         -31.5545,  -23.1308,  -23.3821,  -19.2999,  -25.5416,  -24.2680,\n",
      "         -21.1463,  -32.5214,  -22.2012,  -21.0589,  -28.7564,  -89.8961,\n",
      "         -20.4971,  -20.1231,  -21.7520,  -30.6207,  -18.6335,  -19.2406,\n",
      "         -31.2417,  -22.8940,  -29.6509,  -19.8530,  -21.5804, -119.7943,\n",
      "         -21.2094,  -20.2272,  -20.0648,  -20.3120,  -25.3576,  -20.8310,\n",
      "         -21.9976,  -20.5915,  -30.1489,  -41.6680,  -33.6030,  -28.2013,\n",
      "         -31.4281,  -32.1319,  -21.4023,  -25.7191,  -30.4413,  -36.6952,\n",
      "         -26.6884,  -27.8271,  -35.0408,  -58.0461,  -23.4083,  -22.4608,\n",
      "         -32.6195,  -25.8869,  -20.5493,  -25.1926,  -32.2121,  -46.2356,\n",
      "         -22.3187,  -22.3770,  -20.4132,  -32.9794,  -24.8227,  -21.6102,\n",
      "         -23.1720,  -21.1041,  -20.9711,  -20.1490,  -21.6350,  -25.9072,\n",
      "         -26.3869,  -37.9697,  -25.2337,  -20.0167,  -25.6654,  -20.3933,\n",
      "         -20.8546,  -21.7712,  -20.6438,  -20.4819,  -20.2801,  -20.8167,\n",
      "         -46.7990,  -24.4504,  -24.2575,  -23.3399,  -19.1425,  -24.9823,\n",
      "         -24.2896,  -19.9433,  -21.0044,  -31.6993,  -20.4411,  -21.2192,\n",
      "         -32.8048,  -20.2189,  -21.4665,  -19.0047,  -35.9239,  -22.3064,\n",
      "         -30.9956,  -21.1034,  -36.2621,  -23.0094,  -18.8703,  -19.2020,\n",
      "         -20.3337,  -19.7320,  -20.7848,  -23.1954,  -32.8107,  -20.2764,\n",
      "         -19.3245,  -28.6463,  -19.4514,  -18.9229,  -21.2193,  -25.8458,\n",
      "         -22.0883,  -19.0648,  -19.8701,  -20.5629,  -35.8371,  -24.7504,\n",
      "         -21.3984,  -19.4584,  -19.4126,  -23.4433,  -19.8146,  -26.9250,\n",
      "         -21.7149,  -34.5446,  -31.5335,  -19.9110,  -21.0185,  -21.0649,\n",
      "         -20.9692,  -19.0946,  -19.1754,  -23.0730,  -29.6765,  -20.7102,\n",
      "         -19.2215,  -19.5817,  -20.6183,  -25.5218,  -25.4852,  -19.5942,\n",
      "         -21.2845,  -30.0415,  -20.6770,  -22.6147,  -28.5071,  -19.4074,\n",
      "         -24.5218,  -26.7139,  -19.8325,  -21.2553,  -27.0663,  -34.1946,\n",
      "         -22.2673,  -18.8670,  -23.2501,  -19.7393,  -25.2424,  -34.1278,\n",
      "         -23.8677,  -19.9761,  -20.8384,  -35.9982,  -20.1679,  -21.4255,\n",
      "         -30.8258,  -26.2371,  -19.8159,  -29.8991,  -22.3712,  -23.0338,\n",
      "         -28.5274,  -26.4214,  -20.2853,  -26.1891,  -20.6157,  -24.3540,\n",
      "         -20.5464,  -23.2408,  -24.2065,  -35.5651,  -19.5774,  -30.5352,\n",
      "         -28.6292,  -20.2633,  -25.5621,  -25.1657,  -20.1078,  -19.7605,\n",
      "         -33.3564,  -22.4254,  -26.8121,  -24.0197], device='cuda:0')\n",
      "tensor([ -30.8834,  -22.7177,  -23.5410,  -40.6107,  -19.0052,  -30.1891,\n",
      "        -104.2884,  -19.6973,  -18.5519,  -27.1759,  -35.1887,  -20.2566,\n",
      "         -22.8752,  -19.6187,  -19.9105,  -22.3059,  -33.7071,  -23.2871,\n",
      "         -18.4239,  -36.5632,  -54.5076,  -21.4278,  -22.7967,  -19.9897,\n",
      "         -25.2001,  -27.7787,  -24.7726,  -19.3797,  -71.9443,  -30.3645,\n",
      "         -22.1463,  -22.3583,  -19.8652,  -22.8488, -151.6905,  -19.2058,\n",
      "         -80.0677,  -18.9801,  -19.6986,  -20.4578,  -26.0672,  -22.8697,\n",
      "         -62.6153,  -26.8844,  -21.9708,  -18.8271,  -64.4893,  -57.0439,\n",
      "         -25.7209,  -22.1112,  -19.4221,  -29.1495,  -33.0035,  -20.0487,\n",
      "         -26.4132,  -19.1246,  -22.3768,  -19.3609,  -25.9437,  -20.0508,\n",
      "        -113.9250,  -21.6384,  -21.9120,  -76.8945,  -25.0385,  -19.2359,\n",
      "         -78.0646,  -29.8159,  -27.4161,  -24.0989,  -18.9630,  -20.2431,\n",
      "         -19.1313, -124.5251,  -21.3999,  -24.1677,  -20.6081,  -21.6066,\n",
      "        -105.9454,  -59.3126,  -32.2759,  -19.4731,  -95.6021,  -18.9552,\n",
      "         -29.5560,  -22.1251,  -19.4716,  -20.6070,  -28.5021,  -18.5932,\n",
      "         -19.5874,  -22.9663,  -84.4137,  -25.4213,  -22.9908,  -20.3964,\n",
      "         -22.3682,  -61.4003,  -19.1334,  -76.0641,  -21.5586,  -22.7688,\n",
      "         -19.1409,  -18.8003,  -19.9145,  -22.6599,  -20.1101,  -47.1726,\n",
      "         -22.2048,  -69.7557,  -20.1314,  -18.9073,  -22.0368,  -23.3307,\n",
      "         -20.5247,  -21.0053,  -24.4744,  -23.7284,  -90.4701,  -21.3853,\n",
      "         -20.2065,  -24.5504,  -20.0679,  -19.8527,  -18.9670,  -21.4487,\n",
      "         -26.6629,  -24.9775,  -22.6697,  -21.1741,  -24.2500,  -20.1659,\n",
      "         -22.1658,  -19.1093, -107.8687,  -21.5497,  -21.3266,  -20.8025,\n",
      "         -20.0065,  -20.2511,  -20.7115,  -19.9312,  -23.7018,  -23.9325,\n",
      "         -20.4484,  -19.1907,  -21.0245,  -19.2076,  -22.3174,  -18.7644,\n",
      "         -21.3201,  -37.8754,  -18.8444,  -23.9943,  -24.4970,  -28.2599,\n",
      "         -25.1516,  -31.8410,  -50.8107,  -21.3784,  -19.7673,  -18.9245,\n",
      "         -20.4051,  -20.7134,  -26.3892,  -20.1381,  -19.2118,  -21.2783,\n",
      "         -18.6007,  -25.0682,  -18.7577,  -21.1051,  -19.5160,  -19.5182,\n",
      "         -19.0557,  -19.1211,  -19.4245,  -19.4088,  -21.5064,  -20.3810,\n",
      "         -26.3368,  -19.6071,  -19.5179,  -21.2325,  -27.3661,  -19.1674,\n",
      "         -18.8406,  -34.2057,  -43.6670,  -18.6182,  -19.6115,  -24.5941,\n",
      "         -19.1647,  -21.7037,  -19.5632,  -20.9867,  -27.7544,  -19.6637,\n",
      "         -22.4769,  -20.9792,  -20.8897,  -19.8026,  -26.3074,  -22.0036,\n",
      "         -19.5007,  -19.4572,  -20.6450,  -23.6235,  -19.4070,  -22.4653,\n",
      "         -21.5978,  -32.9556,  -19.0096,  -19.3537,  -19.8735,  -18.7398,\n",
      "         -21.7127,  -21.6950,  -98.6421,  -21.1981,  -19.6037,  -22.4976,\n",
      "         -26.6722,  -20.3898,  -25.1184,  -19.6972,  -69.9966,  -21.1679,\n",
      "         -53.8457,  -26.7077,  -32.6222,  -26.4962,  -20.2171,  -19.0538,\n",
      "         -18.8443,  -23.9141,  -37.1169,  -21.7326,  -20.8239,  -29.2120,\n",
      "         -19.4843,  -18.6580,  -19.8022,  -25.6359,  -57.2032,  -20.3567,\n",
      "         -19.8408,  -28.9702,  -20.6668,  -25.0749,  -22.0304,  -25.1979,\n",
      "         -23.2891,  -19.8980,  -20.1494,  -29.1912,  -26.8799,  -49.9441,\n",
      "         -20.6476,  -20.8294,  -26.9139,  -23.3782,  -21.4128,  -81.6136,\n",
      "         -30.0427,  -22.2269,  -18.9490,  -61.6028,  -20.9643,  -18.9789,\n",
      "         -21.0601,  -31.0539,  -48.2807,  -19.2255,  -21.1897,  -28.7749,\n",
      "         -25.4538,  -20.5176,  -23.0544,  -21.1311,  -20.6909,  -34.8653,\n",
      "         -32.8265,  -21.4483,  -20.8690,  -19.0647,  -19.2151,  -22.5969,\n",
      "         -18.8307,  -20.4106,  -20.5072,  -21.0525,  -43.0062,  -22.0513,\n",
      "         -19.9011,  -54.6760,  -31.7990,  -22.7005,  -19.9990, -150.4968,\n",
      "        -176.4477,  -21.6840,  -25.3669,  -33.9661,  -30.5766,  -18.5837,\n",
      "         -23.6818,  -23.1302, -175.8363,  -27.0588,  -48.9092, -101.6422,\n",
      "         -23.0328,  -20.8049,  -54.8102,  -20.7838,  -22.7884,  -23.5399,\n",
      "        -148.7613,  -19.7930,  -56.1013,  -19.3857,  -97.2043,  -35.4019,\n",
      "         -34.7354,  -28.8916,  -25.8273,  -27.9372, -144.4025,  -22.5860,\n",
      "         -22.6567,  -26.0031,  -19.8975,  -25.5573,  -71.5511,  -45.5630,\n",
      "         -25.7831,  -31.5953,  -21.9902,  -91.7107,  -21.6414,  -29.1697,\n",
      "         -19.7804,  -18.8699,  -25.7200,  -22.6470,  -26.2207,  -20.8363,\n",
      "         -32.8983,  -20.0509,  -22.7083,  -26.1883,  -20.0630,  -20.6127,\n",
      "        -113.6779,  -30.6039,  -22.9536,  -22.2230,  -20.3813,  -23.5582,\n",
      "         -29.5954,  -20.2350,  -19.1198,  -97.2389,  -26.9884,  -20.7072,\n",
      "         -18.6049, -134.0954,  -19.5684, -135.5897,  -25.1425,  -18.8509,\n",
      "        -139.1361,  -19.2877,  -19.2911,  -19.0450,  -22.3664,  -20.8646,\n",
      "         -25.6976,  -20.8663,  -20.1685,  -61.0111,  -20.9325,  -60.2857,\n",
      "         -31.2378,  -19.8481,  -18.8722,  -19.6028,  -19.4568,  -19.1671,\n",
      "         -23.2957, -154.2455,  -21.9358,  -19.4279,  -23.5526,  -19.8776,\n",
      "         -21.6151,  -19.1566,  -20.3362,  -20.3123,  -24.8399,  -25.5878,\n",
      "         -19.7288,  -48.1212,  -22.6631,  -19.0277,  -19.8511,  -24.1221,\n",
      "         -20.0662,  -20.6710,  -19.1255,  -21.9940,  -20.7120,  -26.6284,\n",
      "         -20.8349,  -19.4282, -130.8243,  -30.2964,  -18.6498,  -99.1192,\n",
      "         -20.3968,  -33.2124,  -19.1473,  -20.5033,  -21.0368,  -72.3025,\n",
      "         -22.5068,  -19.0998,  -21.5364,  -19.1729,  -23.3130,  -27.8047,\n",
      "         -20.9533,  -19.3136,  -18.4524,  -25.8395,  -25.0567,  -19.9247,\n",
      "         -26.8169,  -18.6557,  -30.2081,  -24.5265,  -19.2988,  -28.8687,\n",
      "         -19.7921,  -25.5911,  -22.9565,  -20.4433,  -20.1156,  -26.6767,\n",
      "         -21.1205,  -20.4652,  -28.5457,  -18.6454,  -19.2847,  -24.2148,\n",
      "         -18.6821,  -19.0535,  -20.2311,  -20.2219,  -24.4269,  -19.3511,\n",
      "         -20.5339,  -26.7724,  -20.4325,  -22.5319,  -18.9493,  -22.0791,\n",
      "         -19.9301,  -22.7224,  -23.2380,  -22.9329,  -19.0372,  -19.2315,\n",
      "         -20.2132,  -20.0881,  -22.8722,  -19.7836,  -22.6192,  -21.7788,\n",
      "         -18.5575,  -18.8981,  -25.2050,  -29.4602,  -23.8594,  -36.7760,\n",
      "         -26.7388,  -23.9563,  -23.1345,  -30.1204,  -19.7894,  -30.4891,\n",
      "         -20.9436,  -25.8050,  -20.0443,  -29.4822,  -19.0472,  -20.3157,\n",
      "         -22.1323,  -26.7807,  -29.7541,  -19.7978,  -19.7023,  -23.4741,\n",
      "         -29.8078,  -25.3678,  -28.4876,  -71.8698,  -23.9675,  -19.2503,\n",
      "         -26.3285,  -37.5668,  -20.3117,  -22.4966,  -21.5484,  -19.0271,\n",
      "         -28.1281,  -20.2097,  -19.7261, -106.9296,  -22.5095,  -78.5021,\n",
      "         -29.1629,  -18.7941,  -27.8394,  -18.6095,  -20.1201,  -21.6662,\n",
      "         -21.4870,  -22.4385,  -20.5110,  -39.6111,  -19.3857,  -22.4724,\n",
      "         -20.5591,  -18.7160,  -24.4053,  -19.2251,  -19.1525,  -37.1029,\n",
      "         -20.3742,  -19.0929,  -32.8510,  -22.7054,  -22.8707,  -20.9646,\n",
      "         -21.0847,  -21.9505,  -34.7703,  -25.0941,  -36.9947,  -31.0311,\n",
      "         -33.8265,  -43.9839,  -19.6541,  -31.5966,  -19.2084,  -22.6421,\n",
      "         -57.5916,  -34.8290,  -34.5791,  -45.0102,  -29.8260,  -20.7594,\n",
      "         -41.4461,  -21.9685,  -20.5128,  -34.7167,  -34.1420,  -24.1462,\n",
      "         -41.3443,  -19.1913,  -52.4465,  -28.4268,  -23.3491,  -20.8807,\n",
      "        -142.5678,  -46.6664,  -22.1877,  -26.2069,  -20.4930,  -19.4643,\n",
      "         -20.0380,  -85.7870,  -21.2224,  -18.3404,  -18.9576,  -21.0796,\n",
      "         -23.0334, -108.4107,  -22.6288,  -20.2691,  -24.8558,  -22.6207,\n",
      "         -47.3866,  -22.9284,  -46.1308,  -21.1001,  -20.4725, -157.1122,\n",
      "         -19.4856,  -21.3438, -101.9209,  -38.2707,  -28.2753,  -20.3228,\n",
      "        -102.1884,  -23.2894,  -21.3726,  -24.5325,  -19.3874,  -19.3686,\n",
      "        -166.8316,  -18.9120,  -21.1222,  -32.9948,  -19.4293,  -21.7873,\n",
      "         -19.2026,  -19.0105,  -18.2314,  -20.3813,  -19.3041,  -21.6929,\n",
      "         -56.5646,  -21.6799,  -21.2257,  -19.5528,  -21.1176,  -19.3682,\n",
      "         -27.8472, -100.5029,  -19.5731,  -18.4800,  -23.7920,  -19.1573,\n",
      "         -18.4656,  -95.9261,  -18.6935,  -19.2681,  -19.7891,  -28.1142,\n",
      "         -19.9442,  -62.7377,  -21.7353,  -20.7744,  -22.9847,  -20.0482,\n",
      "         -21.0903,  -22.9725,  -23.0436,  -61.1915,  -23.3193, -108.1934,\n",
      "         -19.9825,  -38.3592,  -43.0163,  -29.4813,  -42.3726,  -30.2733,\n",
      "         -23.0692,  -38.5128,  -73.4298,  -35.5475,  -20.5424,  -21.7099,\n",
      "         -60.2393,  -45.2613,  -18.9476,  -51.2482,  -26.2638,  -31.8175,\n",
      "         -36.4315,  -90.9605,  -34.8558,  -26.1223,  -23.8390,  -21.5001,\n",
      "         -52.3767,  -20.2247,  -62.0335,  -37.4920, -101.6029,  -95.5115,\n",
      "         -70.8178,  -20.3172,  -35.8225,  -46.7330,  -20.5042,  -22.8581,\n",
      "         -24.6957,  -20.6356,  -21.4157,  -26.1705,  -27.0153,  -20.5257,\n",
      "         -24.7407,  -26.4160, -124.0862,  -19.7577,  -27.9270,  -19.5449,\n",
      "         -57.4756,  -21.3361,  -19.2917,  -25.1979,  -22.5575,  -20.2193,\n",
      "         -24.7383,  -21.7309,  -23.6611,  -23.9098,  -19.1912,  -25.7573,\n",
      "         -19.6615,  -21.0190,  -19.8388,  -30.1948,  -19.8343,  -20.0174,\n",
      "         -22.6223,  -21.9015,  -23.2494,  -28.3983,  -19.7610,  -20.3074,\n",
      "         -20.6496,  -19.8480,  -22.8893,  -24.1728,  -20.6497,  -18.9743,\n",
      "         -20.1887,  -20.7899,  -20.6689,  -20.7453,  -25.5950,  -19.9642,\n",
      "         -26.2980,  -19.9655,  -60.9030,  -27.6823,  -19.6984,  -20.6520,\n",
      "         -19.3810,  -22.4076,  -24.2184,  -22.7169,  -20.8400,  -23.9454,\n",
      "         -20.6441,  -19.2673,  -20.3978,  -28.3679,  -72.4844,  -25.6348,\n",
      "         -21.5406,  -19.6891,  -20.2890,  -22.7763,  -31.5498,  -19.5007,\n",
      "         -21.9266,  -21.1070,  -49.5362,  -19.8377,  -22.3343,  -20.6416,\n",
      "         -21.1806,  -20.3508,  -35.3625,  -19.4778,  -19.9684,  -63.3122,\n",
      "         -21.2365,  -19.0668,  -69.2343,  -20.1550,  -97.2376,  -24.4224,\n",
      "         -57.0036,  -20.9033,  -23.0109,  -29.8442,  -33.6773,  -21.8109,\n",
      "         -18.7268,  -37.1202,  -25.6489,  -27.9683,  -27.4872,  -21.5593,\n",
      "         -22.9346,  -26.3832,  -44.7603,  -53.7572,  -48.9726, -149.9486,\n",
      "         -23.0014,  -21.3150,  -25.7127,  -22.3646,  -27.7255,  -56.2191,\n",
      "         -41.6787,  -24.0389,  -24.0411,  -20.1130,  -30.4064,  -20.6736,\n",
      "         -21.7017,  -31.5749,  -20.6819,  -39.8326,  -23.3404,  -97.4205,\n",
      "         -20.2124,  -19.8056,  -22.9894,  -37.8335,  -22.6814,  -20.7396,\n",
      "         -31.5219,  -25.8713,  -26.8193,  -19.6067,  -22.9614, -124.7538,\n",
      "         -22.3230,  -30.2849,  -33.7049,  -19.2681,  -27.2969,  -19.5052,\n",
      "         -21.8005,  -19.1426,  -29.9032,  -26.8065,  -32.7168,  -28.9691,\n",
      "         -29.0990,  -28.3009,  -23.7798,  -31.2234,  -27.7131,  -32.9120,\n",
      "         -31.0296,  -21.6723,  -35.2743,  -51.5798,  -23.6228,  -21.6908,\n",
      "         -32.9710,  -22.5426,  -24.8123,  -26.0207,  -32.5498,  -31.9508,\n",
      "         -19.9636,  -20.1344,  -24.4239,  -31.9894,  -22.3494,  -24.2570,\n",
      "         -23.0745,  -21.3842,  -25.4316,  -26.5225,  -23.4903,  -25.5792,\n",
      "         -25.5890,  -40.1459,  -25.1188,  -19.0866,  -26.2448,  -20.9108,\n",
      "         -23.6929,  -22.2675,  -21.1383,  -20.0532,  -20.9799,  -22.1039,\n",
      "         -53.9877,  -24.3713,  -20.9170,  -22.6591,  -31.1630,  -30.7996,\n",
      "         -19.1747,  -21.4765,  -19.3312,  -32.6485,  -19.8564,  -27.3192,\n",
      "         -30.7120,  -24.9409,  -18.8190,  -25.0038,  -25.3078,  -22.3509,\n",
      "         -33.8246,  -19.3963,  -35.2445,  -20.8801,  -19.1451,  -21.7983,\n",
      "         -22.7967,  -19.1683,  -21.5716,  -19.5058,  -25.2718,  -22.4565,\n",
      "         -28.5158,  -24.7695,  -20.7470,  -19.2842,  -22.3522,  -24.8737,\n",
      "         -18.7054,  -18.5900,  -18.3201,  -19.4443,  -33.9646,  -24.3830,\n",
      "         -19.8442,  -27.4210,  -20.5909,  -23.7229,  -19.4066,  -18.4746,\n",
      "         -21.9019,  -41.5306,  -35.5829,  -19.1661,  -25.2817,  -19.3214,\n",
      "         -21.0970,  -21.9132,  -20.8167,  -19.2744,  -24.8526,  -20.5899,\n",
      "         -20.8986,  -19.7406,  -24.7712,  -33.2954,  -22.2997,  -18.8433,\n",
      "         -20.5417,  -20.5055,  -19.2948,  -22.8727,  -30.4497,  -19.2633,\n",
      "         -22.7906,  -25.9304,  -19.1718,  -25.4625,  -26.6169,  -29.0915,\n",
      "         -22.1553,  -20.9594,  -20.4216,  -24.8768,  -21.4721,  -29.0916,\n",
      "         -20.8751,  -19.8563,  -21.7876,  -27.8312,  -22.7556,  -19.5130,\n",
      "         -25.7806,  -27.0705,  -20.6631,  -30.5004,  -21.8934,  -21.5589,\n",
      "         -30.8053,  -23.4294,  -19.9594,  -22.8758,  -20.1049,  -23.2924,\n",
      "         -19.4669,  -23.5768,  -19.7082,  -42.7234,  -19.7986,  -36.8981,\n",
      "         -28.4581,  -21.3461,  -21.0443,  -19.2205,  -21.6390,  -19.4868,\n",
      "         -31.8963,  -22.5724,  -26.9898,  -23.8280], device='cuda:0')\n",
      "tensor([ -23.0839,  -22.3802,  -33.2423,  -41.5360,  -19.6986,  -23.4133,\n",
      "        -102.0039,  -26.3291,  -18.7227,  -35.7908,  -25.7187,  -21.1061,\n",
      "         -22.0607,  -19.4686,  -20.7375,  -26.3779,  -60.8223,  -22.8366,\n",
      "         -19.7734,  -35.0949,  -32.6948,  -19.6926,  -20.8885,  -20.6049,\n",
      "         -22.2688,  -32.0197,  -24.2631,  -22.1329,  -70.9598,  -19.7942,\n",
      "         -20.2701,  -18.9845,  -28.3741,  -23.4974, -151.6404,  -20.6012,\n",
      "         -73.1920,  -20.1430,  -19.4001,  -23.0434,  -21.4985,  -20.8570,\n",
      "         -61.3668,  -21.7402,  -18.7648,  -19.2441,  -64.8610,  -56.5989,\n",
      "         -20.6796,  -22.7313,  -18.7159,  -21.2089,  -19.3152,  -26.1119,\n",
      "         -24.0867,  -26.7625,  -21.4200,  -19.3175,  -25.7024,  -22.5322,\n",
      "         -96.8280,  -19.7741,  -19.2422,  -77.8171,  -23.9621,  -20.5509,\n",
      "         -88.3834,  -21.9050,  -21.9483,  -21.4374,  -20.1154,  -18.8403,\n",
      "         -26.4946, -126.0672,  -19.2535,  -23.7941,  -23.4007,  -20.0082,\n",
      "        -104.9084,  -69.2845,  -21.0001,  -19.4013,  -94.1949,  -18.7509,\n",
      "         -30.2358,  -19.9503,  -21.1154,  -24.6627,  -18.5505,  -20.2625,\n",
      "         -24.4243,  -20.1792,  -85.1881,  -24.8749,  -21.3156,  -20.4964,\n",
      "         -19.2904,  -64.6536,  -19.2493,  -76.4241,  -19.6753,  -19.6572,\n",
      "         -20.3664,  -21.2096,  -21.5179,  -19.4816,  -20.7694,  -44.5767,\n",
      "         -23.7305,  -64.6157,  -21.8442,  -18.7051,  -26.8136,  -23.3060,\n",
      "         -19.2681,  -19.8491,  -27.5750,  -21.5294,  -88.1540,  -22.0233,\n",
      "         -24.2072,  -25.5521,  -34.8436,  -20.3606,  -20.2093,  -20.2321,\n",
      "         -23.3587,  -23.3342,  -37.5769,  -21.2962,  -20.1037,  -20.0676,\n",
      "         -21.0860,  -19.9823, -100.7388,  -20.5005,  -21.1778,  -22.3437,\n",
      "         -19.7471,  -19.5029,  -22.0710,  -20.9093,  -20.5781,  -20.2122,\n",
      "         -20.5809,  -19.7718,  -20.3983,  -19.7031,  -18.8504,  -19.1892,\n",
      "         -19.7090,  -33.8258,  -19.1715,  -20.0576,  -22.8245,  -20.1009,\n",
      "         -19.7157,  -19.8533,  -52.9501,  -19.5131,  -21.6188,  -19.7923,\n",
      "         -19.1310,  -19.3666,  -19.9441,  -21.6910,  -23.5605,  -21.2082,\n",
      "         -19.1712,  -23.4049,  -19.5876,  -27.3970,  -20.8194,  -19.3506,\n",
      "         -20.8818,  -20.1116,  -19.2550,  -19.3542,  -18.9585,  -19.9908,\n",
      "         -23.1991,  -29.4082,  -19.8186,  -21.5185,  -21.2120,  -19.8599,\n",
      "         -18.5178,  -18.5145,  -44.5658,  -21.1907,  -20.0870,  -19.2221,\n",
      "         -20.9487,  -18.8615,  -25.0691,  -23.5718,  -19.6174,  -20.6362,\n",
      "         -19.2055,  -22.6097,  -18.8435,  -19.9120,  -19.4325,  -19.4615,\n",
      "         -18.8477,  -19.8669,  -20.4787,  -22.2876,  -19.2378,  -20.5591,\n",
      "         -20.4856,  -22.9050,  -23.5577,  -26.9237,  -19.4783,  -19.4542,\n",
      "         -21.4377,  -21.2143, -100.0802,  -24.1026,  -25.7986,  -19.8234,\n",
      "         -22.2719,  -23.2019,  -20.7607,  -20.1487,  -70.6975,  -27.3276,\n",
      "         -47.9532,  -29.4707,  -19.3472,  -19.4593,  -21.7008,  -18.7984,\n",
      "         -19.3836,  -26.1740,  -35.1691,  -19.5015,  -22.9149,  -26.0029,\n",
      "         -20.9751,  -22.1389,  -21.2434,  -25.0632,  -57.0229,  -19.9871,\n",
      "         -23.4009,  -23.8017,  -20.1411,  -21.2866,  -21.1446,  -23.6512,\n",
      "         -30.7605,  -19.7897,  -22.2531,  -23.4615,  -26.2543,  -48.0796,\n",
      "         -26.8833,  -24.2459,  -18.8691,  -19.8643,  -21.0222,  -74.6526,\n",
      "         -22.1788,  -24.3863,  -18.9300,  -63.3778,  -19.7623,  -19.3779,\n",
      "         -21.0682,  -32.2895,  -51.7131,  -26.4152,  -20.2716,  -20.3814,\n",
      "         -21.7370,  -19.9104,  -21.4765,  -22.9996,  -18.5470,  -35.6116,\n",
      "         -26.8915,  -21.3128,  -20.6184,  -19.8156,  -21.7860,  -21.9608,\n",
      "         -19.3585,  -20.1634,  -20.5978,  -20.5082,  -44.6014,  -21.0335,\n",
      "         -21.2617,  -47.9017,  -29.8129,  -22.4695,  -23.9071, -150.0388,\n",
      "        -177.0264,  -19.0509,  -20.0326,  -39.1979,  -25.0828,  -19.0108,\n",
      "         -21.3487,  -19.4302, -175.5501,  -22.5047,  -56.7785, -104.0855,\n",
      "         -22.5081,  -21.6355,  -53.4234,  -20.4676,  -24.1159,  -21.7290,\n",
      "        -146.7060,  -20.9610,  -58.0334,  -21.8219,  -96.8322,  -35.4972,\n",
      "         -45.6526,  -28.5482,  -31.0534,  -30.5243, -148.7171,  -21.1707,\n",
      "         -24.0159,  -29.7101,  -20.3667,  -33.9458,  -70.0431,  -44.9789,\n",
      "         -27.2113,  -30.3456,  -25.1901,  -91.0928,  -21.1358,  -27.8356,\n",
      "         -23.9292,  -20.4640,  -19.6864,  -22.8784,  -19.9887,  -29.5544,\n",
      "         -22.1236,  -19.9547,  -22.0227,  -23.7446,  -19.9396,  -20.4267,\n",
      "        -117.5670,  -23.6701,  -26.6697,  -25.9496,  -19.9212,  -21.8155,\n",
      "         -25.2010,  -21.1759,  -20.8728,  -96.3714,  -21.2588,  -18.6561,\n",
      "         -18.8345, -131.5420,  -18.7438, -134.8812,  -27.3807,  -19.3568,\n",
      "        -132.6067,  -19.7104,  -21.3851,  -19.5096,  -22.3271,  -19.3390,\n",
      "         -26.4400,  -26.9208,  -19.6057,  -61.9733,  -21.3005,  -60.2151,\n",
      "         -20.0339,  -25.7199,  -26.0592,  -22.4776,  -21.7500,  -25.9060,\n",
      "         -21.1802, -154.6928,  -21.4417,  -20.6419,  -18.1017,  -21.1675,\n",
      "         -21.1969,  -21.4982,  -19.4798,  -20.5088,  -19.3035,  -24.5147,\n",
      "         -23.4024,  -50.8565,  -34.7369,  -19.6927,  -21.7725,  -23.1945,\n",
      "         -29.4196,  -19.6298,  -19.3425,  -22.2302,  -19.2253,  -19.2751,\n",
      "         -20.5511,  -25.6917, -129.9409,  -24.8619,  -19.1779,  -97.8543,\n",
      "         -25.6629,  -18.8952,  -19.4998,  -18.1431,  -20.8599,  -70.2878,\n",
      "         -18.2769,  -22.2913,  -20.9086,  -23.0899,  -21.8330,  -21.1963,\n",
      "         -23.2605,  -19.7181,  -18.4736,  -24.0579,  -24.2431,  -19.7995,\n",
      "         -18.7754,  -19.3081,  -30.8418,  -20.8441,  -19.0267,  -28.7857,\n",
      "         -27.1346,  -21.9823,  -23.9907,  -23.0438,  -20.0457,  -26.5741,\n",
      "         -22.3147,  -19.4173,  -29.6733,  -23.7338,  -24.7454,  -24.6326,\n",
      "         -22.6132,  -22.4892,  -25.8895,  -20.2673,  -21.0566,  -24.0789,\n",
      "         -27.1285,  -22.1383,  -18.9256,  -20.3285,  -19.1548,  -20.2694,\n",
      "         -19.5936,  -26.6245,  -20.9464,  -19.2676,  -19.1928,  -20.0634,\n",
      "         -27.9792,  -19.3370,  -20.9666,  -19.5690,  -22.3746,  -26.0265,\n",
      "         -23.8477,  -23.5748,  -24.0052,  -30.4383,  -35.7590,  -31.6974,\n",
      "         -26.1658,  -24.3172,  -24.2121,  -27.6740,  -19.4466,  -34.0037,\n",
      "         -22.0048,  -21.8339,  -28.6456,  -19.5433,  -18.6681,  -21.3262,\n",
      "         -20.3188,  -32.5898,  -25.6608,  -19.4945,  -22.8551,  -20.1136,\n",
      "         -29.5632,  -35.7882,  -19.5047,  -71.9647,  -19.6395,  -31.9901,\n",
      "         -19.0139,  -36.6249,  -20.8243,  -20.6193,  -22.1653,  -19.2683,\n",
      "         -19.8970,  -20.0592,  -19.8733,  -96.6991,  -32.7297,  -78.2607,\n",
      "         -30.8355,  -19.1312,  -22.2399,  -18.5666,  -19.9690,  -20.4444,\n",
      "         -22.4971,  -18.9403,  -19.6661,  -38.1520,  -19.3976,  -20.1067,\n",
      "         -20.5009,  -18.9808,  -27.8906,  -25.0068,  -18.7642,  -36.2544,\n",
      "         -19.6379,  -20.6771,  -31.0852,  -19.3106,  -22.4613,  -28.7058,\n",
      "         -29.8802,  -19.1357,  -35.2939,  -20.5689,  -34.8904,  -22.7877,\n",
      "         -34.9678,  -52.9155,  -24.0167,  -24.2446,  -19.1558,  -19.4798,\n",
      "         -55.0368,  -45.5338,  -33.8834,  -44.7670,  -32.9758,  -20.1039,\n",
      "         -39.4953,  -20.8426,  -27.2970,  -38.0708,  -31.2619,  -28.2903,\n",
      "         -41.6848,  -25.6413,  -45.9069,  -36.7334,  -24.4102,  -28.4021,\n",
      "        -143.3237,  -45.4988,  -20.6953,  -20.0820,  -18.6032,  -19.4523,\n",
      "         -20.8721,  -75.8877,  -23.3568,  -22.4077,  -18.7685,  -21.3441,\n",
      "         -20.9690, -110.1955,  -22.3503,  -20.0027,  -20.1895,  -20.2692,\n",
      "         -50.7194,  -20.2342,  -38.2293,  -23.0287,  -22.4799, -155.0106,\n",
      "         -18.9552,  -21.3936,  -95.2190,  -39.4547,  -20.1891,  -20.1569,\n",
      "         -99.3045,  -35.0040,  -27.0267,  -28.4033,  -21.1635,  -20.3539,\n",
      "        -160.0010,  -19.4736,  -20.3065,  -19.0929,  -21.3176,  -23.8925,\n",
      "         -19.1063,  -19.6645,  -18.2377,  -20.3784,  -19.2836,  -20.3767,\n",
      "         -49.7540,  -19.7664,  -18.4897,  -19.1703,  -20.2318,  -19.2962,\n",
      "         -20.7068, -100.0179,  -20.0671,  -19.3411,  -19.9415,  -24.7234,\n",
      "         -18.7716, -105.6895,  -19.5095,  -24.4182,  -20.3979,  -19.0730,\n",
      "         -21.1883,  -73.5685,  -21.7554,  -22.2299,  -22.9169,  -27.5648,\n",
      "         -23.8859,  -20.8665,  -23.4319,  -58.8005,  -22.1117, -111.2082,\n",
      "         -19.6616,  -38.8688,  -42.6767,  -32.5634,  -28.6370,  -31.2958,\n",
      "         -22.8390,  -37.4297,  -77.1828,  -36.0811,  -20.2403,  -22.4284,\n",
      "         -38.7890,  -46.0156,  -20.9263,  -43.7327,  -22.7165,  -24.4667,\n",
      "         -36.1929, -103.3736,  -37.8737,  -25.9557,  -24.2471,  -20.1718,\n",
      "         -42.6327,  -19.2698,  -62.2850,  -38.4572,  -98.1155,  -97.2424,\n",
      "         -75.0684,  -24.9812,  -54.8843,  -43.6101,  -27.4536,  -26.6168,\n",
      "         -26.4109,  -29.5221,  -29.9318,  -21.2323,  -24.1100,  -20.2171,\n",
      "         -23.4242,  -21.4453, -125.9042,  -18.9976,  -25.7096,  -23.7454,\n",
      "         -57.9400,  -22.5661,  -19.3713,  -22.0490,  -24.2593,  -22.0676,\n",
      "         -25.2867,  -26.7187,  -19.9843,  -20.9971,  -19.2632,  -22.2478,\n",
      "         -23.8813,  -22.2234,  -22.5366,  -19.3438,  -19.1588,  -19.4734,\n",
      "         -19.3862,  -19.1212,  -19.8748,  -22.4387,  -20.0629,  -22.1033,\n",
      "         -25.7456,  -21.9921,  -19.5241,  -19.1050,  -24.2151,  -19.0220,\n",
      "         -24.5778,  -20.3661,  -19.9703,  -19.3180,  -18.8077,  -22.2671,\n",
      "         -20.9643,  -19.5135,  -70.3201,  -24.1471,  -19.6434,  -21.2244,\n",
      "         -21.2067,  -28.8131,  -21.0828,  -29.2643,  -30.2605,  -20.3428,\n",
      "         -19.6490,  -19.5119,  -21.1173,  -21.3345,  -61.8487,  -27.8546,\n",
      "         -20.6587,  -19.7848,  -28.8008,  -20.4683,  -21.1415,  -30.8379,\n",
      "         -20.6597,  -19.1471,  -54.9790,  -22.5446,  -20.4017,  -23.4472,\n",
      "         -24.3867,  -20.4744,  -39.9693,  -24.3845,  -19.5991,  -60.9508,\n",
      "         -24.5404,  -20.1668,  -66.0745,  -20.0317, -101.1645,  -20.1503,\n",
      "         -58.6152,  -23.0262,  -24.4508,  -22.9104,  -30.6539,  -19.7045,\n",
      "         -21.8319,  -35.5232,  -22.1153,  -30.1719,  -31.9039,  -21.9857,\n",
      "         -24.6290,  -22.3043,  -44.0511,  -49.5189,  -42.2733, -149.6454,\n",
      "         -22.1924,  -21.3285,  -25.9678,  -34.3864,  -25.4260,  -56.7128,\n",
      "         -29.6635,  -24.4705,  -26.6207,  -22.3641,  -30.0908,  -20.6020,\n",
      "         -20.4830,  -31.3439,  -18.5525,  -21.0432,  -27.5832, -103.4897,\n",
      "         -21.3359,  -20.5927,  -22.1575,  -29.9992,  -18.8563,  -20.5155,\n",
      "         -30.9112,  -21.1591,  -26.5689,  -23.2577,  -21.9409, -131.5099,\n",
      "         -21.0343,  -21.1054,  -20.1042,  -25.4454,  -29.1906,  -19.9487,\n",
      "         -21.4697,  -19.6782,  -29.1631,  -25.4738,  -39.3898,  -27.6754,\n",
      "         -26.4739,  -32.0233,  -22.1301,  -25.9526,  -29.0764,  -29.4853,\n",
      "         -26.3159,  -22.4066,  -36.6667,  -50.9281,  -23.0887,  -23.0861,\n",
      "         -36.2190,  -21.9430,  -22.5786,  -25.5115,  -31.9113,  -33.1111,\n",
      "         -20.0492,  -25.0353,  -22.6340,  -32.3921,  -20.9329,  -27.7372,\n",
      "         -23.7720,  -20.8309,  -20.9506,  -22.2000,  -28.1096,  -29.2433,\n",
      "         -19.8442,  -37.9001,  -24.9366,  -21.0923,  -34.9704,  -20.8806,\n",
      "         -19.8328,  -21.8533,  -24.4510,  -19.7331,  -22.1421,  -20.2132,\n",
      "         -46.2331,  -22.3179,  -21.8949,  -21.0040,  -19.5424,  -26.6163,\n",
      "         -19.7189,  -19.1005,  -19.4605,  -31.4406,  -21.7125,  -20.3826,\n",
      "         -33.1256,  -21.2655,  -19.6343,  -19.4119,  -27.0570,  -20.8173,\n",
      "         -33.0561,  -20.9274,  -36.0364,  -21.0140,  -22.5544,  -23.0418,\n",
      "         -21.5269,  -21.1157,  -19.3869,  -19.2885,  -26.1475,  -21.2809,\n",
      "         -18.9984,  -24.9380,  -23.4871,  -19.2861,  -19.7378,  -24.7237,\n",
      "         -21.5131,  -23.3123,  -19.8778,  -22.3297,  -41.4282,  -21.7122,\n",
      "         -19.4408,  -19.5177,  -20.8920,  -23.2163,  -24.8521,  -22.9320,\n",
      "         -20.1925,  -36.4061,  -33.8238,  -20.0465,  -22.4574,  -19.0115,\n",
      "         -19.4024,  -19.5642,  -19.6089,  -19.0975,  -27.4181,  -30.0920,\n",
      "         -20.1513,  -20.3428,  -20.2967,  -25.9852,  -19.6625,  -19.0835,\n",
      "         -22.3081,  -19.5464,  -20.0294,  -23.6655,  -24.8482,  -24.7773,\n",
      "         -19.2806,  -26.8797,  -18.8267,  -20.2661,  -24.9641,  -29.9863,\n",
      "         -21.9041,  -26.1097,  -23.7759,  -20.8704,  -23.3509,  -30.8487,\n",
      "         -19.7607,  -21.2051,  -20.6637,  -32.0748,  -21.0762,  -22.5283,\n",
      "         -26.7486,  -25.5981,  -21.0200,  -33.3017,  -20.3234,  -21.9720,\n",
      "         -29.5324,  -24.6581,  -22.1255,  -22.7711,  -23.1699,  -22.7811,\n",
      "         -20.3893,  -23.2245,  -21.3983,  -33.6494,  -21.0995,  -30.8981,\n",
      "         -27.6409,  -20.0791,  -20.4061,  -20.2019,  -21.0010,  -21.4301,\n",
      "         -31.7576,  -24.6840,  -27.5843,  -20.4450], device='cuda:0')\n",
      "tensor([ -22.8894,  -24.5231,  -22.2298,  -30.4838,  -19.9278,  -32.2334,\n",
      "        -102.0515,  -18.9575,  -18.1959,  -28.8217,  -27.8968,  -21.7975,\n",
      "         -26.0457,  -18.6579,  -22.1663,  -20.1538,  -31.5050,  -20.4265,\n",
      "         -23.1885,  -36.6949,  -36.3684,  -27.0533,  -22.9226,  -28.3975,\n",
      "         -20.4476,  -19.5305,  -22.3685,  -19.5501,  -71.2864,  -27.6232,\n",
      "         -19.2748,  -18.5537,  -28.2232,  -20.8359, -155.6332,  -23.0689,\n",
      "         -73.6189,  -22.7042,  -26.7090,  -20.5853,  -18.6251,  -21.1010,\n",
      "         -63.8604,  -21.9197,  -18.3958,  -19.9951,  -64.6999,  -55.0761,\n",
      "         -20.7668,  -19.8491,  -22.5944,  -20.9342,  -20.5223,  -33.6092,\n",
      "         -19.9898,  -19.3655,  -18.7049,  -21.0647,  -30.3848,  -20.4990,\n",
      "         -99.2108,  -22.3894,  -22.1276,  -77.2421,  -22.9899,  -21.0855,\n",
      "        -102.3788,  -20.1832,  -19.7060,  -22.2675,  -19.4710,  -20.0747,\n",
      "         -27.4477, -125.2877,  -18.6404,  -24.7575,  -22.2236,  -19.2326,\n",
      "        -106.4655,  -60.4571,  -21.7864,  -21.6717,  -96.2023,  -18.5976,\n",
      "         -25.8400,  -25.1181,  -19.6460,  -21.0316,  -19.6337,  -19.1785,\n",
      "         -23.4808,  -22.7782,  -85.4877,  -24.8968,  -21.1232,  -21.3252,\n",
      "         -19.1406,  -67.6707,  -19.3523,  -79.2810,  -20.6308,  -21.3009,\n",
      "         -23.4400,  -19.1158,  -21.0129,  -44.7000,  -23.7363,  -41.9937,\n",
      "         -20.0702,  -63.2829,  -22.5790,  -19.3054,  -19.5095,  -19.6746,\n",
      "         -21.3742,  -31.1873,  -19.9527,  -19.4647,  -88.5372,  -22.0657,\n",
      "         -35.6451,  -21.0085,  -22.1017,  -21.2233,  -23.6586,  -21.8939,\n",
      "         -28.9504,  -20.6504,  -23.1426,  -19.5381,  -25.1056,  -37.8980,\n",
      "         -21.2003,  -19.7393, -104.3181,  -24.5014,  -21.9225,  -30.6914,\n",
      "         -19.5995,  -27.2430,  -24.6018,  -25.4234,  -18.6775,  -19.9878,\n",
      "         -19.2704,  -21.5204,  -21.9763,  -18.5904,  -19.1990,  -22.0928,\n",
      "         -19.4513,  -39.6244,  -23.9969,  -20.6747,  -18.8164,  -21.3564,\n",
      "         -19.7068,  -19.7689,  -49.5065,  -23.5877,  -20.1935,  -19.2664,\n",
      "         -19.3718,  -27.0820,  -19.2872,  -25.4658,  -27.1746,  -21.6593,\n",
      "         -20.5951,  -19.8440,  -29.0377,  -18.9947,  -19.3007,  -21.7265,\n",
      "         -20.7502,  -27.5526,  -21.0629,  -18.5606,  -19.0687,  -19.7261,\n",
      "         -22.8898,  -20.8843,  -19.3769,  -19.2894,  -29.6009,  -19.8614,\n",
      "         -21.7671,  -18.6485,  -45.4029,  -20.6074,  -19.5665,  -20.7920,\n",
      "         -22.7368,  -24.4509,  -26.0364,  -24.5371,  -22.0550,  -19.8927,\n",
      "         -18.5564,  -18.9093,  -22.6264,  -19.3164,  -19.9661,  -22.5307,\n",
      "         -20.0059,  -22.4055,  -29.6877,  -22.7340,  -21.8653,  -20.8112,\n",
      "         -25.3768,  -27.7313,  -20.5010,  -19.3259,  -21.9429,  -18.8402,\n",
      "         -22.0550,  -22.5083, -102.0034,  -19.4914,  -28.2384,  -20.5896,\n",
      "         -21.9299,  -19.7937,  -21.1854,  -21.1932,  -69.8584,  -20.0287,\n",
      "         -51.0601,  -27.2108,  -18.6881,  -18.9600,  -19.3111,  -18.8436,\n",
      "         -18.7457,  -18.3279,  -37.9136,  -18.8961,  -24.7602,  -26.6503,\n",
      "         -19.9747,  -20.7333,  -18.6556,  -26.5852,  -60.4895,  -21.8056,\n",
      "         -19.9091,  -24.8528,  -20.6936,  -26.3709,  -29.4781,  -31.8245,\n",
      "         -18.8776,  -25.7655,  -22.0178,  -20.8639,  -19.9139,  -49.3360,\n",
      "         -19.3364,  -22.5825,  -26.6596,  -20.7572,  -21.3291,  -74.0036,\n",
      "         -19.0117,  -19.4251,  -19.4099,  -70.7671,  -20.9019,  -20.1966,\n",
      "         -21.4750,  -39.9657,  -48.8316,  -22.0174,  -21.0642,  -21.4920,\n",
      "         -23.2916,  -19.9397,  -23.2212,  -26.4776,  -19.3809,  -35.3608,\n",
      "         -28.5348,  -23.0585,  -26.5935,  -20.8939,  -23.0239,  -22.6408,\n",
      "         -19.4890,  -19.9179,  -20.4369,  -25.5191,  -49.9077,  -20.2080,\n",
      "         -23.1360,  -48.8055,  -30.1488,  -24.0188,  -19.8926, -151.5567,\n",
      "        -174.6257,  -26.9733,  -20.0509,  -27.2733,  -25.3390,  -21.9734,\n",
      "         -22.0668,  -19.4315, -174.7113,  -22.4259,  -52.5111, -102.2103,\n",
      "         -30.5053,  -20.8079,  -52.9934,  -21.0184,  -20.8474,  -23.7155,\n",
      "        -147.2294,  -19.2534,  -60.3877,  -18.9425,  -97.1332,  -34.0980,\n",
      "         -43.5542,  -25.3747,  -27.0078,  -28.4756, -145.0786,  -21.2566,\n",
      "         -22.9586,  -27.4771,  -24.5389,  -26.9603,  -70.9755,  -44.7293,\n",
      "         -24.1109,  -30.8530,  -22.1680,  -88.5506,  -21.7144,  -31.8955,\n",
      "         -19.4361,  -23.5583,  -20.6608,  -31.1034,  -19.2132,  -21.2433,\n",
      "         -19.1907,  -23.4635,  -21.9682,  -23.6297,  -19.5290,  -20.2324,\n",
      "        -116.9007,  -23.5831,  -23.6914,  -21.7501,  -19.9273,  -21.4776,\n",
      "         -27.5270,  -20.9616,  -20.7834,  -88.0828,  -21.7225,  -19.5050,\n",
      "         -18.9108, -135.1988,  -20.1935, -133.5542,  -34.0503,  -18.4726,\n",
      "        -132.1747,  -25.9893,  -22.7735,  -22.2118,  -20.3625,  -19.4014,\n",
      "         -21.5412,  -19.6852,  -20.5033,  -60.6280,  -22.4214,  -60.4101,\n",
      "         -19.3403,  -19.9068,  -19.8536,  -20.0504,  -26.1922,  -18.7057,\n",
      "         -20.4230, -178.2376,  -23.8237,  -18.7659,  -33.0993,  -27.5115,\n",
      "         -20.1914,  -19.5725,  -20.9374,  -25.0198,  -20.7995,  -22.5073,\n",
      "         -19.7582,  -46.9611,  -34.9744,  -19.0514,  -36.3696,  -28.4692,\n",
      "         -19.3273,  -19.9123,  -20.2439,  -21.7330,  -20.3552,  -19.3633,\n",
      "         -26.0380,  -19.9235, -131.1174,  -23.8428,  -18.7751,  -98.6147,\n",
      "         -20.0653,  -19.6355,  -28.1484,  -18.8192,  -23.9280,  -72.0891,\n",
      "         -19.7057,  -21.4116,  -25.7120,  -22.6899,  -22.1392,  -20.8372,\n",
      "         -23.0033,  -21.1306,  -18.5964,  -22.5833,  -20.9809,  -29.2510,\n",
      "         -19.5913,  -19.6817,  -34.0045,  -19.7314,  -32.9137,  -29.3714,\n",
      "         -20.9198,  -22.4936,  -20.3515,  -20.2774,  -20.5847,  -27.7502,\n",
      "         -30.5355,  -24.6097,  -28.8458,  -20.0584,  -19.6813,  -25.7816,\n",
      "         -18.6670,  -22.9110,  -18.7920,  -23.7170,  -19.5671,  -19.2777,\n",
      "         -26.1153,  -21.8601,  -22.2585,  -27.4256,  -19.5137,  -19.9159,\n",
      "         -19.7271,  -18.2795,  -28.2329,  -27.3585,  -27.2306,  -19.8807,\n",
      "         -19.2188,  -27.2506,  -20.4360,  -26.0617,  -22.2972,  -20.0427,\n",
      "         -27.2426,  -25.7828,  -22.5529,  -29.7259,  -19.2514,  -31.8273,\n",
      "         -27.5187,  -23.1293,  -23.2910,  -18.4282,  -19.1764,  -30.9895,\n",
      "         -21.8047,  -22.5996,  -25.5280,  -22.1968,  -22.0182,  -20.4325,\n",
      "         -23.0670,  -26.1475,  -25.4545,  -19.0385,  -20.1442,  -19.8611,\n",
      "         -29.7684,  -33.7501,  -19.1882,  -73.3488,  -22.3087,  -19.8337,\n",
      "         -23.8231,  -36.9530,  -20.3552,  -26.0211,  -20.0002,  -21.7371,\n",
      "         -20.3778,  -21.8658,  -19.9810,  -96.8233,  -23.4003,  -77.7184,\n",
      "         -19.8348,  -18.9760,  -18.7747,  -17.8300,  -20.7679,  -20.3645,\n",
      "         -19.5389,  -19.2068,  -22.3741,  -43.0135,  -19.8366,  -19.7111,\n",
      "         -20.7912,  -18.9372,  -30.1622,  -18.9255,  -18.7292,  -48.0205,\n",
      "         -20.2142,  -18.5667,  -33.6143,  -22.9422,  -20.2215,  -19.9953,\n",
      "         -18.7772,  -32.6594,  -29.6178,  -19.4022,  -35.6951,  -23.7874,\n",
      "         -34.7967,  -41.3558,  -32.5928,  -24.1473,  -19.2746,  -24.1323,\n",
      "         -54.8083,  -36.8676,  -32.0669,  -45.9074,  -32.9076,  -21.5197,\n",
      "         -44.0216,  -19.7545,  -19.1643,  -42.0209,  -30.4858,  -25.2476,\n",
      "         -42.5860,  -19.0675,  -46.9690,  -32.2812,  -26.8210,  -19.3050,\n",
      "        -145.0777,  -47.5110,  -31.2995,  -19.5657,  -26.1476,  -19.7969,\n",
      "         -20.3580,  -90.9465,  -22.9565,  -20.2884,  -26.2029,  -20.9809,\n",
      "         -20.6881, -105.2828,  -29.7889,  -20.3112,  -21.3644,  -20.9846,\n",
      "         -47.7610,  -23.0320,  -49.1879,  -38.3858,  -23.0349, -154.6362,\n",
      "         -20.4989,  -28.3320,  -97.5371,  -49.4882,  -19.3843,  -23.4703,\n",
      "         -99.6312,  -30.3124,  -31.7561,  -30.0434,  -18.6596,  -19.5130,\n",
      "        -163.8239,  -19.3671,  -19.4754,  -22.4066,  -22.9379,  -18.5586,\n",
      "         -20.3580,  -36.3018,  -18.6541,  -19.9639,  -20.0884,  -23.0975,\n",
      "         -52.8473,  -19.9414,  -21.4095,  -19.4779,  -20.2161,  -19.6229,\n",
      "         -20.0241,  -98.8273,  -25.2776,  -19.7425,  -19.4573,  -18.5079,\n",
      "         -19.0657,  -95.7292,  -18.3447,  -19.0073,  -22.2569,  -19.0597,\n",
      "         -21.3469,  -62.1530,  -21.5383,  -21.0782,  -23.1429,  -19.7756,\n",
      "         -21.0085,  -20.9789,  -23.5350,  -74.7886,  -21.9274, -124.5083,\n",
      "         -28.9677,  -39.9123,  -41.7577,  -29.6374,  -35.3988,  -30.1847,\n",
      "         -29.1263,  -37.1876,  -73.7034,  -36.9738,  -19.6757,  -21.5100,\n",
      "         -54.4197,  -48.8052,  -19.4586,  -44.5526,  -23.4641,  -24.8179,\n",
      "         -35.4417,  -96.4219,  -41.9050,  -32.9228,  -26.2034,  -22.6407,\n",
      "         -44.5273,  -19.5518,  -64.4165,  -43.1052,  -93.3673,  -98.0990,\n",
      "         -71.9626,  -20.1028,  -45.8817,  -55.6482,  -27.6347,  -22.5768,\n",
      "         -23.3683,  -20.2265,  -19.5864,  -20.4918,  -26.7899,  -20.5647,\n",
      "         -23.6683,  -20.1088, -130.2146,  -20.3815,  -22.6553,  -19.5430,\n",
      "         -61.3084,  -22.5929,  -19.9411,  -26.3010,  -23.6158,  -20.3777,\n",
      "         -37.1132,  -28.7191,  -20.2250,  -21.6520,  -22.2444,  -22.6542,\n",
      "         -27.1742,  -27.3071,  -21.3103,  -19.4638,  -19.2180,  -24.8118,\n",
      "         -19.7528,  -18.8624,  -20.1148,  -19.9233,  -20.6689,  -20.9728,\n",
      "         -42.9248,  -21.8020,  -19.7833,  -21.5647,  -20.9115,  -17.9796,\n",
      "         -19.6227,  -19.9727,  -21.6732,  -19.5710,  -19.1820,  -19.3237,\n",
      "         -18.2146,  -21.2925,  -61.1005,  -19.3012,  -22.2041,  -19.8163,\n",
      "         -21.1560,  -19.2926,  -23.4453,  -23.0567,  -18.6004,  -20.5452,\n",
      "         -21.2739,  -19.9263,  -20.3051,  -23.0355,  -60.7644,  -23.2104,\n",
      "         -21.5307,  -20.3173,  -21.3951,  -20.7742,  -19.8646,  -28.2959,\n",
      "         -21.0369,  -18.7984,  -48.5547,  -24.8771,  -19.1264,  -24.6365,\n",
      "         -20.6584,  -28.3577,  -38.6461,  -23.5957,  -22.0929,  -60.4374,\n",
      "         -36.3362,  -21.9495,  -66.3427,  -20.5399, -104.1394,  -20.9269,\n",
      "         -57.8627,  -24.8127,  -30.7979,  -23.7111,  -31.5884,  -19.4100,\n",
      "         -19.3054,  -46.3772,  -19.2219,  -28.9770,  -36.2358,  -21.4810,\n",
      "         -22.9126,  -19.7130,  -44.7771,  -51.3599,  -41.7886, -147.6471,\n",
      "         -24.2908,  -19.1431,  -27.3314,  -22.0904,  -22.5136,  -59.5820,\n",
      "         -30.5050,  -24.2102,  -24.1423,  -19.6656,  -23.3975,  -20.6420,\n",
      "         -20.3901,  -31.3515,  -19.4057,  -42.3493,  -20.2854,  -91.7247,\n",
      "         -21.1799,  -19.7472,  -23.6333,  -41.2244,  -19.1300,  -20.3211,\n",
      "         -30.3377,  -23.4381,  -26.0253,  -22.6388,  -22.6523, -119.1886,\n",
      "         -20.8876,  -20.7934,  -22.3930,  -18.3965,  -24.0604,  -20.0622,\n",
      "         -22.2563,  -20.6206,  -30.2093,  -30.3521,  -37.8096,  -26.5536,\n",
      "         -26.8638,  -28.8412,  -24.0012,  -33.1056,  -24.5460,  -38.5698,\n",
      "         -25.7785,  -21.0617,  -39.4321,  -50.1156,  -23.1419,  -21.2045,\n",
      "         -34.5075,  -23.6692,  -20.7628,  -20.2633,  -32.6490,  -32.9081,\n",
      "         -20.0001,  -20.3845,  -20.6772,  -34.8463,  -24.4191,  -22.0191,\n",
      "         -24.5394,  -20.8214,  -21.3375,  -19.4953,  -28.8614,  -25.4876,\n",
      "         -19.4606,  -39.4691,  -24.0357,  -19.3694,  -26.0882,  -19.9533,\n",
      "         -28.3835,  -24.7380,  -19.5881,  -21.6439,  -21.7694,  -20.1896,\n",
      "         -47.2142,  -19.0696,  -22.4763,  -21.4107,  -23.0180,  -26.1658,\n",
      "         -21.9529,  -19.4243,  -20.3622,  -33.9589,  -20.8704,  -20.5819,\n",
      "         -30.0354,  -20.9016,  -23.3261,  -18.7583,  -27.4598,  -22.2178,\n",
      "         -33.1917,  -20.1406,  -43.2667,  -22.0580,  -19.1477,  -24.6135,\n",
      "         -19.1769,  -24.2038,  -18.9471,  -23.4886,  -25.9648,  -19.2716,\n",
      "         -26.1340,  -25.0583,  -19.8557,  -18.8652,  -29.7463,  -24.1827,\n",
      "         -19.1018,  -19.3639,  -18.6106,  -26.8371,  -34.5578,  -27.0239,\n",
      "         -19.1784,  -21.5239,  -21.2265,  -20.4465,  -24.7835,  -21.4405,\n",
      "         -20.5711,  -34.1269,  -30.6714,  -24.1700,  -20.6739,  -18.8229,\n",
      "         -19.6287,  -22.4752,  -18.8827,  -25.4400,  -28.8253,  -26.8638,\n",
      "         -21.4314,  -19.1632,  -18.8192,  -30.6215,  -20.6947,  -18.8990,\n",
      "         -21.6539,  -20.3837,  -21.2617,  -23.5136,  -24.8028,  -21.8393,\n",
      "         -30.8918,  -26.9218,  -18.8470,  -21.4856,  -25.4542,  -28.9647,\n",
      "         -23.6802,  -21.1009,  -19.3983,  -24.9202,  -26.1689,  -29.0657,\n",
      "         -20.9031,  -20.3654,  -20.9618,  -28.8058,  -20.2582,  -19.3314,\n",
      "         -36.9536,  -27.3583,  -21.8856,  -34.1223,  -19.4424,  -24.9169,\n",
      "         -32.7261,  -22.6564,  -20.5389,  -25.2304,  -19.4204,  -24.8624,\n",
      "         -27.2542,  -22.6664,  -21.0897,  -34.3337,  -20.3714,  -34.9555,\n",
      "         -28.7980,  -21.6730,  -21.5968,  -24.9835,  -20.2082,  -19.1002,\n",
      "         -32.3552,  -24.8137,  -26.7162,  -20.4372], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# source distribution is an isotropic gaussian\n",
    "gaussian_log_density = Independent(Normal(torch.zeros(dimension, device=device), torch.ones(dimension, device=device)), 1).log_prob\n",
    "\n",
    "# compute log likelihood with unbiased hutchinson estimator, average over num_acc\n",
    "num_acc = 10\n",
    "log_p_acc = 0\n",
    "\n",
    "for i in range(num_acc):\n",
    "    _, log_p = solver.compute_likelihood(x_1=x_1, method='midpoint', step_size=step_size, exact_divergence=False, log_p0=gaussian_log_density)\n",
    "    log_p_acc += log_p\n",
    "    print(log_p)\n",
    "\n",
    "log_p_acc /= num_acc\n",
    "\n",
    "# compute with exact divergence\n",
    "# _, exact_log_p = solver.compute_likelihood(x_1=x_1, method='midpoint', step_size=step_size, exact_divergence=True, log_p0=gaussian_log_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-29.8493, device='cuda:0'), tensor(0, device='cuda:0'))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(log_p_acc>log_p_acc.min()+10000)\n",
    "mask=log_p_acc>log_p_acc.min()\n",
    "zx=log_p_acc*mask \n",
    "zx.mean(),torch.sum(x_1>1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-22.3732, device='cuda:0') tensor(-30.0256, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(log_p_acc.median(),log_p_acc.mean())  #    queueu=-14 pareto A117.81\n",
    "#-3725 rms\n",
    "# -99 rms\n",
    "#-14 rms\n",
    "#-63 adam\n",
    "#-59.8   or(-45058.3555, d -693.8184, tensor(-50.9519, device='cuda:0') -36 best with decreaseing linear sampling tensor(0.2530, device='cuda:0') -6.1681"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0792, 0.0092, 0.0418, 0.0363],\n",
       "        [0.1032, 0.0152, 0.0585, 0.0519],\n",
       "        [0.1340, 0.0249, 0.0816, 0.0739],\n",
       "        [0.1732, 0.0408, 0.1131, 0.1045],\n",
       "        [0.2224, 0.0663, 0.1552, 0.1465],\n",
       "        [0.2824, 0.1057, 0.2097, 0.2021],\n",
       "        [0.3523, 0.1627, 0.2763, 0.2716],\n",
       "        [0.4275, 0.2365, 0.3510, 0.3513],\n",
       "        [0.4997, 0.3185, 0.4259, 0.4321],\n",
       "        [0.5602, 0.3944, 0.4916, 0.5028]], device='cuda:0',\n",
       "       grad_fn=<SoftplusBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from extreme_transforms import softplus\n",
    "TT = torch.linspace(0,1,10) \n",
    "softplus(Tail_paramNet(TT.unsqueeze(1).to(device))[:,0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0792, 0.0092, 0.0418, 0.0363],\n",
       "        [0.1032, 0.0152, 0.0585, 0.0519],\n",
       "        [0.1340, 0.0249, 0.0816, 0.0739],\n",
       "        [0.1732, 0.0408, 0.1131, 0.1045],\n",
       "        [0.2224, 0.0663, 0.1552, 0.1465],\n",
       "        [0.2824, 0.1057, 0.2097, 0.2021],\n",
       "        [0.3523, 0.1627, 0.2763, 0.2716],\n",
       "        [0.4275, 0.2365, 0.3510, 0.3513],\n",
       "        [0.4997, 0.3185, 0.4259, 0.4321],\n",
       "        [0.5602, 0.3944, 0.4916, 0.5028]], device='cuda:0',\n",
       "       grad_fn=<SoftplusBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from extreme_transforms import softplus\n",
    "TT = torch.linspace(0,1,10) \n",
    "softplus(Tail_paramNet(TT.unsqueeze(1).to(device))[:,0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Given data\n",
    "data = [[0.4248, 0.4167, 0.4777, 0.4127],\n",
    "        [0.4290, 0.4229, 0.4841, 0.4221],\n",
    "        [0.4331, 0.4286, 0.4902, 0.4310],\n",
    "        [0.4369, 0.4340, 0.4960, 0.4394],\n",
    "        [0.4405, 0.4390, 0.5015, 0.4472],\n",
    "        [0.4439, 0.4434, 0.5066, 0.4545],\n",
    "        [0.4470, 0.4474, 0.5114, 0.4611],\n",
    "        [0.4498, 0.4509, 0.5158, 0.4672],\n",
    "        [0.4524, 0.4540, 0.5199, 0.4726],\n",
    "        [0.4548, 0.4565, 0.5236, 0.4775]]\n",
    "\n",
    "# Extract first and second columns\n",
    "first_column = [row[0] for row in data]\n",
    "second_column = [row[2] for row in data]\n",
    "\n",
    "# Plot\n",
    "plt.plot(first_column, marker='o', linestyle='-', color='b', label=\"Positive\")\n",
    "plt.plot(second_column, marker='s', linestyle='--', color='r', label=\"Negative\")\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"time steps\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Plot of Positve and Negative Tail Parameter Values\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "def plot_wasserstein_distances(generate_data: np.ndarray, test_data: np.ndarray):\n",
    "    \"\"\"\n",
    "    Computes and plots Wasserstein distances for each feature between generated and test data.\n",
    "\n",
    "    Parameters:\n",
    "    - generate_data: np.ndarray of shape (N, D)\n",
    "    - test_data: np.ndarray of shape (N, D)\n",
    "    \"\"\"\n",
    "    assert generate_data.shape[1] == test_data.shape[1], \"Feature dimensions must match\"\n",
    "    num_features = generate_data.shape[1]\n",
    "    \n",
    "    distances = [\n",
    "        wasserstein_distance(test_data[:, i], generate_data[:, i])\n",
    "        for i in range(num_features)\n",
    "    ]\n",
    "    \n",
    "    # Plot bar chart\n",
    "    # plt.figure(figsize=(12, 6))\n",
    "    # plt.bar(range(num_features), distances, color='skyblue')\n",
    "    # plt.xlabel('Feature Index')\n",
    "    # plt.ylabel('Wasserstein Distance')\n",
    "    # plt.title('Wasserstein Distance per Feature Dimension')\n",
    "    # plt.xticks(range(num_features))\n",
    "    # plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "    \n",
    "    return distances  # Optional: return the distances for further use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03594038157567836, 0.0649943223741129, 0.04113135200471907, 0.03926961585812628, 0.05350949938149812, 0.0606498080671999, 0.07702487710690785, 0.08278395296567954, 0.08921701771607589, 0.11903163462167513, 0.15891403543696037, 0.16020915905016603, 0.20013716985221974, 0.17918225811634597, 0.13795907556784295, 0.1286994584082583, 0.1321298011887158, 0.14986009469862874, 0.14564999921305968, 0.1617608054151143]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11090271593094925"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wasdist_list=plot_wasserstein_distances(generated_data,full_data_test)\n",
    "print(wasdist_list)\n",
    "np.mean(wasdist_list)   #7.623988290672775  dof1A1-1.116690311340978  dof2A1-9.119758828227486 dof2A2 -7.23 ParetoA1-0.077 ParetoA2  checjk 0.54withchecker\n",
    "\n",
    "#full pareto A1-0.02346\n",
    "#cone A1-0.18 A2-0.24\n",
    "# #hrrr Wd-0.111 KR-0.9512 SR-0.8589   vs base WD-0.09747168757370553 KR tensor(0.9948) SR 0.9616\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16752, 20]), torch.Size([16752, 20]), torch.Size([8348, 20]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data_val.shape,full_data_train.shape,full_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(Dataset+'_TTFgen.npy', generated_data)\n",
    "np.save(Dataset+'_TTFtest.npy', full_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy import stats\n",
    "\n",
    "def compute_kurtosis_ratio(\n",
    "    generated_data: torch.Tensor, \n",
    "    test_data: torch.Tensor,\n",
    "    eps: float = 1e-8\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes the Kurtosis Ratio (KR) using SciPy.\n",
    "    Converts tensors to NumPy arrays for calculation.\n",
    "\n",
    "    Args:\n",
    "        generated_data (torch.Tensor): The data generated by the model.\n",
    "        test_data (torch.Tensor): The underlying real data.\n",
    "        eps (float): A small value for numerical stability.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A scalar tensor containing the Kurtosis Ratio.\n",
    "    \"\"\"\n",
    "    # 1. Flatten tensors and convert to NumPy arrays.\n",
    "    # .cpu() is used in case the tensors are on a GPU.\n",
    "    generated_np = generated_data.flatten().cpu().numpy()\n",
    "    test_data_np = test_data.flatten().cpu().numpy()\n",
    "\n",
    "    # 2. Compute empirical kurtosis (k_sim and k_data) using SciPy.\n",
    "    # fisher=True computes excess kurtosis (kurtosis - 3), which is standard.\n",
    "    # bias=True computes the biased estimator, consistent with moment calculations.\n",
    "    k_sim = stats.kurtosis(generated_np, fisher=True, bias=True)\n",
    "    k_data = stats.kurtosis(test_data_np, fisher=True, bias=True)\n",
    "\n",
    "    # 3. Compute the Kurtosis Ratio.\n",
    "    kr = abs(1 - (k_sim / (k_data + eps)))\n",
    "    \n",
    "    # 4. Convert the final result back to a PyTorch tensor.\n",
    "    return torch.tensor(kr, dtype=torch.float32)\n",
    "\n",
    "def compute_skewness_ratio(\n",
    "    generated_data: torch.Tensor, \n",
    "    test_data: torch.Tensor,\n",
    "    eps: float = 1e-8\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes the Skewness Ratio (SR) using SciPy.\n",
    "    Converts tensors to NumPy arrays for calculation.\n",
    "\n",
    "    Args:\n",
    "        generated_data (torch.Tensor): The data generated by the model.\n",
    "        test_data (torch.Tensor): The underlying real data.\n",
    "        eps (float): A small value for numerical stability.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A scalar tensor containing the Skewness Ratio.\n",
    "    \"\"\"\n",
    "    # 1. Flatten tensors and convert to NumPy arrays.\n",
    "    generated_np = generated_data.flatten().cpu().numpy()\n",
    "    test_data_np = test_data.flatten().cpu().numpy()\n",
    "\n",
    "    # 2. Compute empirical skewness (s_sim and s_data) using SciPy.\n",
    "    # bias=True computes the biased estimator.\n",
    "    s_sim = stats.skew(generated_np, bias=True)\n",
    "    s_data = stats.skew(test_data_np, bias=True)\n",
    "\n",
    "    # 3. Compute the Skewness Ratio.\n",
    "    sr = abs(1 - (s_sim / (s_data + eps)))\n",
    "\n",
    "    # 4. Convert the final result back to a PyTorch tensor.\n",
    "    return torch.tensor(sr, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9512)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_kurtosis_ratio(torch.tensor(generated_data),full_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8589)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_skewness_ratio(torch.tensor(generated_data),full_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5.])\n",
      "x tensor([[1., 3.],\n",
      "        [1., 3.],\n",
      "        [1., 3.],\n",
      "        [1., 3.],\n",
      "        [1., 3.],\n",
      "        [1., 3.]])\n",
      "torch.Size([6, 2]) torch.Size([6, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_22116\\1880281314.py:27: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  t=torch.asarray(list(torch.range(0,5)))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import Callable\n",
    "from torch import nn, Tensor\n",
    "\n",
    "def jvp(f,x, v) -> tuple[Tensor, ...]:\n",
    "    return torch.autograd.functional.jvp(\n",
    "        f, x, v, \n",
    "        create_graph=torch.is_grad_enabled()\n",
    "    )\n",
    "\n",
    "\n",
    "def t_dir(f, t) -> tuple[Tensor, ...]:\n",
    "    return jvp(f, t, torch.ones_like(t))\n",
    "\n",
    "\n",
    "def get_t_dir( x: Tensor, t: Tensor) -> tuple[tuple[Tensor, Tensor], tuple[Tensor, Tensor]]:\n",
    "    def flow(a,b):\n",
    "        return(b.unsqueeze(1)**a)\n",
    "    def f(x_in):\n",
    "        def f_(t_in):\n",
    "            return flow(x_in, t_in)\n",
    "        return f_\n",
    "\n",
    "    return t_dir(f(x), t)\n",
    "\n",
    "\n",
    "t=torch.asarray(list(torch.range(0,5)))\n",
    "x=torch.zeros(6,2)+1\n",
    "x[:,1]=3\n",
    "print(t)\n",
    "print(\"x\",x)\n",
    "l=get_t_dir(x,t)\n",
    "print(l[0].shape,l[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv=torch.randn(2,3,2,2)\n",
    "qq=torch.randn(2,12,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5698, -0.1481],\n",
       "         [-1.4746,  0.3824]],\n",
       "\n",
       "        [[ 1.1922,  0.1211],\n",
       "         [-0.2369, -0.9054]]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vv[0,0:2,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.5698, -0.1481, -1.4746,  0.3824,  1.1922,  0.1211, -0.2369, -0.9054])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vv.reshape(2,-1)[0,0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3954,  1.5060],\n",
       "         [ 0.0699, -0.9118]],\n",
       "\n",
       "        [[ 1.5530,  0.2826],\n",
       "         [ 2.1351, -2.6039]],\n",
       "\n",
       "        [[ 0.1707,  1.7325],\n",
       "         [-1.8028, -0.6949]],\n",
       "\n",
       "        [[ 0.1610, -0.6672],\n",
       "         [ 0.5538,  1.1528]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qq[0,4:8,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5875, -0.1929,  0.1053,  0.0048,  0.1111,  0.1662, -0.7200,  0.9059,\n",
       "         0.4293, -0.6689, -0.7486,  1.5633])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vv.reshape(2,-1)[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0294, -1.7511,  0.6996,  0.5532,  0.3954,  1.5530,  0.1707,  0.1610,\n",
       "        -0.1261, -0.3003, -0.8313,  0.8988])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qq.permute(0,2,3,1).reshape(2,-1)[0,0:12]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
